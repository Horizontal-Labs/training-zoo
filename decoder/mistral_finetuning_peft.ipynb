{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Horizontal-Labs/training-zoo/blob/main/decoder/mistral_finetuning_peft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eimmnld_Nhu3",
        "outputId": "b1b5f847-1f24-4c88-9926-62eaaf3fe4a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'apt' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'apt' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "collab_env = hasattr(__builtins__, 'colab')\n",
        "if collab_env:\n",
        "    os.system('apt update')\n",
        "    os.system('apt install -y libmariadb-dev')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rnwq69pOOYTP",
        "outputId": "b42f4c5b-f34e-4da7-9b58-d3ded99e5d22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mysql-connector-python\n",
            "  Using cached mysql_connector_python-9.3.0-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
            "Collecting sqlalchemy\n",
            "  Downloading sqlalchemy-2.0.41-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
            "Collecting mariadb\n",
            "  Downloading mariadb-1.1.12-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
            "Collecting greenlet>=1 (from sqlalchemy)\n",
            "  Downloading greenlet-3.2.2-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
            "Collecting typing-extensions>=4.6.0 (from sqlalchemy)\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging in c:\\users\\joost\\workspace\\training-zoo\\venv\\lib\\site-packages (from mariadb) (25.0)\n",
            "Downloading mysql_connector_python-9.3.0-cp312-cp312-win_amd64.whl (16.4 MB)\n",
            "   ---------------------------------------- 0.0/16.4 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.1/16.4 MB 3.2 MB/s eta 0:00:06\n",
            "   - -------------------------------------- 0.5/16.4 MB 5.6 MB/s eta 0:00:03\n",
            "   - -------------------------------------- 0.8/16.4 MB 6.4 MB/s eta 0:00:03\n",
            "   -- ------------------------------------- 1.2/16.4 MB 7.5 MB/s eta 0:00:03\n",
            "   ---- ----------------------------------- 1.7/16.4 MB 8.2 MB/s eta 0:00:02\n",
            "   ----- ---------------------------------- 2.3/16.4 MB 9.0 MB/s eta 0:00:02\n",
            "   ------ --------------------------------- 2.7/16.4 MB 9.1 MB/s eta 0:00:02\n",
            "   ------- -------------------------------- 3.2/16.4 MB 9.3 MB/s eta 0:00:02\n",
            "   --------- ------------------------------ 3.7/16.4 MB 9.4 MB/s eta 0:00:02\n",
            "   ---------- ----------------------------- 4.4/16.4 MB 9.9 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 5.3/16.4 MB 11.0 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 6.1/16.4 MB 11.5 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 7.4/16.4 MB 12.7 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 8.8/16.4 MB 14.0 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 10.3/16.4 MB 15.6 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 11.8/16.4 MB 19.9 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 13.3/16.4 MB 24.2 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 14.9/16.4 MB 28.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  16.4/16.4 MB 31.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 16.4/16.4 MB 29.8 MB/s eta 0:00:00\n",
            "Downloading sqlalchemy-2.0.41-cp312-cp312-win_amd64.whl (2.1 MB)\n",
            "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "   --------------------------- ------------ 1.5/2.1 MB 30.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.1/2.1 MB 33.4 MB/s eta 0:00:00\n",
            "Downloading mariadb-1.1.12-cp312-cp312-win_amd64.whl (201 kB)\n",
            "   ---------------------------------------- 0.0/201.3 kB ? eta -:--:--\n",
            "   --------------------------------------- 201.3/201.3 kB 12.7 MB/s eta 0:00:00\n",
            "Downloading greenlet-3.2.2-cp312-cp312-win_amd64.whl (296 kB)\n",
            "   ---------------------------------------- 0.0/296.2 kB ? eta -:--:--\n",
            "   --------------------------------------- 296.2/296.2 kB 19.1 MB/s eta 0:00:00\n",
            "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Installing collected packages: typing-extensions, mysql-connector-python, mariadb, greenlet, sqlalchemy\n",
            "Successfully installed greenlet-3.2.2 mariadb-1.1.12 mysql-connector-python-9.3.0 sqlalchemy-2.0.41 typing-extensions-4.13.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install mysql-connector-python sqlalchemy mariadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WBKP7blOb8J"
      },
      "outputs": [],
      "source": [
        "if collab_env:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDXPfzTCOea1",
        "outputId": "5408729c-fb44-41a9-ec83-4ee3a4c832aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'Argument-Mining'...\n",
            "Downloading data/args-me-1.0-cleaned.json (888 MB)\n",
            "Error downloading object: data/args-me-1.0-cleaned.json (6588d8b): Smudge error: Error downloading data/args-me-1.0-cleaned.json (6588d8bdc2cef0a631768d3a884d06cb18f25901c36886ac11c0acb3e7691530): batch response: This repository exceeded its LFS budget. The account responsible for the budget should increase it to restore access.\n",
            "\n",
            "Errors logged to 'C:\\Users\\Joost\\workspace\\training-zoo\\Argument-Mining\\.git\\lfs\\logs\\20250517T170058.9305234.log'.\n",
            "Use `git lfs logs last` to view the log.\n",
            "error: external filter 'git-lfs filter-process' failed\n",
            "fatal: data/args-me-1.0-cleaned.json: smudge filter lfs failed\n",
            "warning: Clone succeeded, but checkout failed.\n",
            "You can inspect what was checked out with 'git status'\n",
            "and retry with 'git restore --source=HEAD :/'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if collab_env:\n",
        "    !git clone https://github.com/Horizontal-Labs/ArgumentMining.git\n",
        "else:\n",
        "    !git clone https://github.com/Horizontal-Labs/ArgumentMining.git --directory-name ../db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm2hF8K_OhqC"
      },
      "outputs": [],
      "source": [
        "# change direcotry\n",
        "import sys\n",
        "sys.path.append('/content/ArgumentMining')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zdgh4cZeb8M",
        "outputId": "be2e99db-7c04-4752-fcb5-96057e95fb07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 3] The system cannot find the path specified: '/content/Argument-Mining/'\n",
            "c:\\Users\\Joost\\workspace\\training-zoo\n",
            "Updating 3da3f48..2f70fdb\n",
            "Fast-forward\n",
            " Finetuning_PEFT_decoder.ipynb | 3226 +++++++++++++++++++++++++++++++++++++++++\n",
            " 1 file changed, 3226 insertions(+)\n",
            " create mode 100644 Finetuning_PEFT_decoder.ipynb\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "From https://github.com/Horizontal-Labs/training-zoo\n",
            " * branch            main       -> FETCH_HEAD\n"
          ]
        }
      ],
      "source": [
        "%cd /content/ArgumentMining/\n",
        "!git pull origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7shxXWjfPQX"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "cache_dir = Path('/content/ArgumentMining/.cache')\n",
        "cache_dir.mkdir(exist_ok=True, parents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7s4Ag0eO8Wu",
        "outputId": "211e8128-49aa-4711-8dbc-d1c54a89f83d"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'db'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqueries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_training_data, get_test_data\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load training data\u001b[39;00m\n\u001b[32m      4\u001b[39m claims_train, premises_train, relationships_train = get_training_data()\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'db'"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "if hasattr(__builtins__, 'colab'):\n",
        "    from db.queries import get_training_data, get_test_data\n",
        "else:\n",
        "    from ArgumentMining.db.queries import get_training_data, get_test_data\n",
        "\n",
        "# Load training data\n",
        "claims_train, premises_train, relationships_train = get_training_data()\n",
        "\n",
        "# Load test data\n",
        "claims_test, premises_test, relationships_test = get_test_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPcFuqLEd7X6",
        "outputId": "e4692c29-92f0-4ef7-e1f1-06fa256a21aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Claims: 40923\n",
            "Train Premises: 40923\n",
            "Train Relationships: 40923\n",
            "Test Claims: 10395\n",
            "Test Premises: 10395\n",
            "Test Relationships: 10395\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Claims:\", len(claims_train))\n",
        "print(\"Train Premises:\", len(premises_train))\n",
        "print(\"Train Relationships:\", len(relationships_train))\n",
        "\n",
        "print(\"Test Claims:\", len(claims_test))\n",
        "print(\"Test Premises:\", len(claims_test))\n",
        "print(\"Test Relationships:\", len(claims_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n0E2b0sPmBe",
        "outputId": "0b4d3dfc-8ef2-4710-c78b-4502195b3031"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7c2b1f54deb0>, 'text': 'This house believes that the sale of violent video games to minors should be banned', 'type': 'claim', 'id': 3, 'domain_id': 2}\n",
            "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7c2b0343bb30>, 'text': 'video game violence is not related to serious aggressive behavior in real life', 'type': 'premise', 'id': 5, 'domain_id': 2}\n"
          ]
        }
      ],
      "source": [
        "# Check attributes available in one of the ADU objects\n",
        "print(vars(claims_train[0]))  # Check first claim object\n",
        "print(vars(premises_train[0]))  # Check first premise object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8C2oP90QvRC",
        "outputId": "aefbb796-3289-413b-b0f5-8809f090d9a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Claims Train has 0 None values.\n",
            "Premises Train has 0 None values.\n",
            "Relationship Train has 0 None values.\n"
          ]
        }
      ],
      "source": [
        "# Check if any ADU is None\n",
        "print(f\"Claims Train has {sum(x is None for x in claims_train)} None values.\")\n",
        "print(f\"Premises Train has {sum(x is None for x in premises_train)} None values.\")\n",
        "print(f\"Relationship Train has {sum(x is None for x in relationships_train)} None values.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rPUHo5kPU-M",
        "outputId": "7d70ec14-f9de-4d59-a9d2-124db011bdfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               claim  \\\n",
            "0  This house believes that the sale of violent v...   \n",
            "1  This house supports the one-child policy of th...   \n",
            "2  This house would permit the use of performance...   \n",
            "3  This house would make physical education compu...   \n",
            "4  This house believes in the use of affirmative ...   \n",
            "\n",
            "                                             premise      stance  \n",
            "0  video game violence is not related to serious ...  stance_con  \n",
            "1         The policy had proved remarkably effective  stance_pro  \n",
            "2  The use of drugs to enhance performance is con...  stance_con  \n",
            "3  Frequent and regular physical exercise boosts ...  stance_pro  \n",
            "4  In some countries which have laws on racial eq...  stance_con  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create pairs of claims and premises\n",
        "debate_pairs = []\n",
        "\n",
        "for i in range(len(claims_train)):\n",
        "    debate_pairs.append({\n",
        "        \"claim\": claims_train[i].text,\n",
        "        \"premise\": premises_train[i].text,\n",
        "        \"stance\": relationships_train[i],\n",
        "    })\n",
        "\n",
        "# Create final DataFrame\n",
        "train_data = pd.DataFrame(debate_pairs)\n",
        "\n",
        "print(train_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrI2x4RzZV_f",
        "outputId": "81cbb5bc-1c74-4644-860b-a09b495a8cda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               claim  \\\n",
            "0  This house believes that the sale of violent v...   \n",
            "1  This house supports the one-child policy of th...   \n",
            "2  This house would permit the use of performance...   \n",
            "3  This house would make physical education compu...   \n",
            "4  This house believes in the use of affirmative ...   \n",
            "\n",
            "                                             premise stance  \n",
            "0  video game violence is not related to serious ...    con  \n",
            "1         The policy had proved remarkably effective    pro  \n",
            "2  The use of drugs to enhance performance is con...    con  \n",
            "3  Frequent and regular physical exercise boosts ...    pro  \n",
            "4  In some countries which have laws on racial eq...    con  \n"
          ]
        }
      ],
      "source": [
        "# Remove 'stance_' prefix for simplicity\n",
        "train_data['stance'] = train_data['stance'].str.replace('stance_', '')\n",
        "\n",
        "print(train_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQhMttPkXHFe"
      },
      "source": [
        "# **Finetuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkwghAjsX_fq",
        "outputId": "7640d978-f01a-4da4-8f19-d9a086986641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.6.0)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl) (3.6.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.51.3)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.31.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (0.21.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.19.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.13.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI8_bXS8qXng",
        "outputId": "e1960763-53d3-4909-f748-94e1f5cba107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMT2F6jdryPR",
        "outputId": "dc8d1537-edf2-4770-8e83-864a8939d20b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgDK0aSWQmpT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch # for model training and tensor operations\n",
        "from datasets import Dataset # interface for working with datasets\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,      # loads a pre-trained CLM\n",
        "    AutoTokenizer,             # loads corresponding tokenizer for a model\n",
        "    BitsAndBytesConfig,        # configuration for quantization techniques\n",
        "    TrainingArguments          # holds arguments for training\n",
        ")\n",
        "\n",
        "# PEFT (Parameter-Efficient Fine-Tuning)\n",
        "from peft import (\n",
        "    get_peft_model,               # wraps the base model with PEFT capabilities\n",
        "    LoraConfig,                   # configuration for LoRA (Low-Rank Adaptation)\n",
        "    TaskType,                     # specifies the type of task (e.g. CLM)\n",
        "    prepare_model_for_kbit_training,  # prepares a quantized model\n",
        "    PeftModel                     # class for loading and managing PEFT models\n",
        ")\n",
        "\n",
        "from trl import SFTTrainer          # Trainer for supervised fine-tuning of language models.\n",
        "import evaluate # HF library to compute evaluation metrics for ML models\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report # common metrics for classification tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQzEYL4TY6Ti"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, eval_data = train_test_split(train_data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcKqUi4lbSt3"
      },
      "source": [
        "# Data Formatting for Multitask Learning with Instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8tYcdTbabWr"
      },
      "outputs": [],
      "source": [
        "def format_for_argument_mining(df):\n",
        "    formatted_data = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        # Format with instructions for each task\n",
        "\n",
        "        # Task 1: ADU Identification - Extract ADUs from text\n",
        "        # Samples for ADU identification using both claims and premises\n",
        "        claim_adu_sample = {\n",
        "            \"instruction\": \"Identify whether the following text contains an Argumentative Discourse Unit (ADU). An ADU is a span of text that serves as a claim or premise in an argument.\",\n",
        "            \"input\": f\"Text: {row['claim']}\",\n",
        "            \"output\": \"Yes, this text contains an ADU. It functions as a claim in an argument.\"\n",
        "        }\n",
        "\n",
        "        premise_adu_sample = {\n",
        "            \"instruction\": \"Identify whether the following text contains an Argumentative Discourse Unit (ADU). An ADU is a span of text that serves as a claim or premise in an argument.\",\n",
        "            \"input\": f\"Text: {row['premise']}\",\n",
        "            \"output\": \"Yes, this text contains an ADU. It functions as a premise in an argument.\"\n",
        "        }\n",
        "\n",
        "\n",
        "        # Task 2: ADU Classification (determine if claim or premise)\n",
        "        adu_class_sample = {\n",
        "            \"instruction\": \"Classify the following Argumentative Discourse Unit (ADU) as either a claim or premise. A claim is the main point being argued, while a premise provides support or evidence.\",\n",
        "            \"input\": f\"ADU: {row['claim']}\",\n",
        "            \"output\": \"This ADU is a claim.\"\n",
        "        }\n",
        "\n",
        "        adu_class_sample2 = {\n",
        "            \"instruction\": \"Classify the following Argumentative Discourse Unit (ADU) as either a claim or premise. A claim is the main point being argued, while a premise provides support or evidence.\",\n",
        "            \"input\": f\"ADU: {row['premise']}\",\n",
        "            \"output\": \"This ADU is a premise.\"\n",
        "        }\n",
        "\n",
        "        # Task 3: Stance Classification\n",
        "        stance_sample = {\n",
        "            \"instruction\": \"Determine if the premise supports or counters the given claim.\",\n",
        "            \"input\": f\"Claim: {row['claim']}\\nPremise: {row['premise']}\",\n",
        "            \"output\": f\"{row['stance']}\"\n",
        "        }\n",
        "\n",
        "        # Task 4: Relationship identification between ADUs\n",
        "        relationship_sample = {\n",
        "            \"instruction\": \"Identify the relationship between the following claim and premise. Explain how they are connected in the argument structure.\",\n",
        "            \"input\": f\"Claim: {row['claim']}\\nPremise: {row['premise']}\",\n",
        "            \"output\": f\"The premise {'supports' if row['stance'] == 'pro' else 'counters'} the claim. The relationship is {'supportive' if row['stance'] == 'pro' else 'contradictory'}, where the premise provides {'evidence for' if row['stance'] == 'pro' else 'evidence against'} the main argument.\"\n",
        "        }\n",
        "\n",
        "        # Add all tasks to our dataset\n",
        "        formatted_data.extend([\n",
        "            claim_adu_sample,\n",
        "            premise_adu_sample,\n",
        "            adu_class_sample,\n",
        "            adu_class_sample2,\n",
        "            stance_sample,\n",
        "            relationship_sample\n",
        "        ])\n",
        "\n",
        "    return formatted_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVr-vMm40DbK"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(example, tokenizer, max_length=1024):\n",
        "    # Combine instruction and input text as prompt\n",
        "    prompt = example['instruction'] + \"\\n\" + example['input']\n",
        "    target = example['output']\n",
        "\n",
        "    # Tokenize inputs (prompt)\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "    # Tokenize targets (outputs/labels)\n",
        "    targets = tokenizer(\n",
        "        target,\n",
        "        max_length=256,  # output length limit\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "    # Prepare labels, replacing pad token id with -100 (ignore index)\n",
        "    labels = targets[\"input_ids\"].copy()\n",
        "    labels = [l if l != tokenizer.pad_token_id else -100 for l in labels]\n",
        "\n",
        "    # Return dictionary for dataset\n",
        "    return {\n",
        "        \"input_ids\": inputs[\"input_ids\"],\n",
        "        \"attention_mask\": inputs[\"attention_mask\"],\n",
        "        \"labels\": labels\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h34Q4g68bbGz"
      },
      "source": [
        "# Language Model Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbTBoTPzbckP"
      },
      "outputs": [],
      "source": [
        "# Returns both the model and tokenizer, ready for fine-tuning or inference\n",
        "def setup_model(model_id=\"mistralai/Mistral-7B-Instruct-v0.2\"):\n",
        "    try:\n",
        "        # QLoRA configuration - use 4-bit quantization for memory efficiency\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.float16\n",
        "        )\n",
        "\n",
        "        # Load pre-trained model with quantization\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            quantization_config=bnb_config, # see above\n",
        "            device_map=\"auto\", # maps model layers automatically to available CPU/GPUs\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        # Load correspondent tokenizer for the model\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "        tokenizer.padding_side = \"right\" # padding directions for filler tokens\n",
        "\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQB_aM_actYi"
      },
      "source": [
        "# PEFT LoRA configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eF4-YEkGcnb9"
      },
      "outputs": [],
      "source": [
        "def configure_peft(model):\n",
        "    peft_config = LoraConfig(\n",
        "        task_type=TaskType.CAUSAL_LM,\n",
        "        inference_mode=False,\n",
        "        r=8,               # Lower rank for efficiency\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.05, # Lower dropout for more stable training\n",
        "        # Target only key attention modules\n",
        "        target_modules=[\"q_proj\", \"v_proj\"],\n",
        "        bias=\"none\",       # Don't train biases for more stability\n",
        "    )\n",
        "\n",
        "    # Prepare model for training with gradient checkpointing\n",
        "    model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n",
        "    model = get_peft_model(model, peft_config)\n",
        "\n",
        "    # Print trainable parameters info\n",
        "    print_trainable_parameters(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-lfal1ndKAG"
      },
      "outputs": [],
      "source": [
        "def setup_training(model, train_dataset, eval_dataset, output_dir=\"./argument-mining-lora\"):\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=2,  # small batch size for larger context\n",
        "        gradient_accumulation_steps=8,\n",
        "        learning_rate=1e-4,            # Low-ish learning rate for stability\n",
        "        weight_decay=0.05,             # weight decay to combat overfitting\n",
        "        logging_steps=20,\n",
        "        save_strategy=\"epoch\",\n",
        "        warmup_ratio=0.03,\n",
        "        lr_scheduler_type=\"cosine\",\n",
        "        bf16=True,\n",
        "        eval_strategy=\"epoch\",   # Add evaluation during training\n",
        "        save_total_limit=2,            # Save disk space\n",
        "        load_best_model_at_end=True,   # Automatically use best model\n",
        "        remove_unused_columns=False    # Keep all columns for potential use\n",
        "    )\n",
        "\n",
        "    # Set up the trainer\n",
        "    trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset= eval_dataset\n",
        "    )\n",
        "\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDb1ur6qdiK9"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, tokenizer, test_data, task=\"stance\"):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    for item in test_data:\n",
        "        if task == \"stance\":\n",
        "            prompt = f\"Instruction: Determine if the premise supports or counters the given claim.\\nInput: Claim: {item['claim']}\\nPremise: {item['premise']}\\nOutput:\"\n",
        "        elif task == \"adu_identification\":\n",
        "            prompt = f\"Instruction: Identify whether the following text contains an Argumentative Discourse Unit (ADU).\\nInput: Text: {item['text']}\\nOutput:\"\n",
        "        elif task == \"adu_classification\":\n",
        "            prompt = f\"Instruction: Classify the following Argumentative Discourse Unit (ADU) as either a claim or premise.\\nInput: ADU: {item['text']}\\nOutput:\"\n",
        "        elif task == \"relationship\":\n",
        "            prompt = f\"Instruction: Identify the relationship between the following claim and premise.\\nInput: Claim: {item['claim']}\\nPremise: {item['premise']}\\nOutput:\"\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=50,\n",
        "                temperature=0.1,\n",
        "                do_sample=False,\n",
        "                num_beams=1\n",
        "            )\n",
        "\n",
        "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        prediction = generated_text.split(\"Output:\")[-1].strip().lower()\n",
        "\n",
        "        # Extract relevant information based on task\n",
        "        if task == \"stance\":\n",
        "            if \"pro\" in prediction:\n",
        "                predictions.append(\"pro\")\n",
        "            elif \"con\" in prediction:\n",
        "                predictions.append(\"con\")\n",
        "            else:\n",
        "                predictions.append(\"unknown\")\n",
        "\n",
        "            references.append(item['stance'])\n",
        "\n",
        "        elif task == \"adu_identification\":\n",
        "            if \"yes\" in prediction:\n",
        "                predictions.append(\"contains_adu\")\n",
        "            elif \"no\" in prediction:\n",
        "                predictions.append(\"no_adu\")\n",
        "            else:\n",
        "                predictions.append(\"unknown\")\n",
        "\n",
        "            references.append(item['contains_adu'])\n",
        "\n",
        "        elif task == \"adu_classification\":\n",
        "            if \"claim\" in prediction:\n",
        "                predictions.append(\"claim\")\n",
        "            elif \"premise\" in prediction:\n",
        "                predictions.append(\"premise\")\n",
        "            else:\n",
        "                predictions.append(\"unknown\")\n",
        "\n",
        "            references.append(item['adu_type'])\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(references, predictions)\n",
        "\n",
        "    # For binary tasks like ADU identification\n",
        "    if task == \"adu_identification\":\n",
        "        f1 = f1_score(references, predictions, average='binary', pos_label=\"contains_adu\")\n",
        "    # For multi-class tasks\n",
        "    else:\n",
        "        f1 = f1_score(references, predictions, average='weighted')\n",
        "\n",
        "    print(f\"Task: {task}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(classification_report(references, predictions))\n",
        "\n",
        "    return accuracy, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3UuAhuYoL0H"
      },
      "outputs": [],
      "source": [
        "# Training Pipeline\n",
        "\n",
        "def train_argument_mining_model(train_data, model_id=\"mistralai/Mistral-7B-Instruct-v0.2\"):\n",
        "    # Setup model and tokenizer\n",
        "    model, tokenizer = setup_model(model_id)\n",
        "\n",
        "    # Format data for training\n",
        "    formatted_train_data = format_for_argument_mining(train_data)\n",
        "    formatted_eval_data = format_for_argument_mining(eval_data)\n",
        "\n",
        "    # Create HF Dataset from list of dicts\n",
        "    hf_train_dataset = Dataset.from_list(formatted_train_data)\n",
        "    hf_eval_dataset = Dataset.from_list(formatted_eval_data)\n",
        "\n",
        "    # Apply tokenizer function to the train dataset (batched for speed)\n",
        "    train_dataset = hf_train_dataset.map(\n",
        "    lambda x: tokenize_function(x, tokenizer),\n",
        "    batched=False\n",
        "    )\n",
        "\n",
        "    # Apply tokenizer function to the eval dataset (batched for speed)\n",
        "    eval_dataset = hf_eval_dataset.map(\n",
        "    lambda x: tokenize_function(x, tokenizer),\n",
        "    batched=False\n",
        "    )\n",
        "\n",
        "    # Configure PEFT/LoRA\n",
        "    model = configure_peft(model)\n",
        "\n",
        "    # Setup training\n",
        "    trainer = setup_training(model, train_dataset, eval_dataset)\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the model and tokenizer\n",
        "    peft_model_id = f\"argument-mining-{model_id.split('/')[-1]}\"\n",
        "    trainer.model.save_pretrained(peft_model_id)\n",
        "    tokenizer.save_pretrained(peft_model_id)\n",
        "\n",
        "    print(f\"Model saved to {peft_model_id}\")\n",
        "    return model, tokenizer, peft_model_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPykhuy4oomw"
      },
      "outputs": [],
      "source": [
        "def run_inference(model, tokenizer, text, task=\"stance\", claim=None, premise=None):\n",
        "    \"\"\"\n",
        "    Run inference on different argument mining tasks\n",
        "\n",
        "    Args:\n",
        "        model: The fine-tuned model\n",
        "        tokenizer: The tokenizer\n",
        "        text: Text to analyze (for ADU tasks)\n",
        "        task: Which task to perform - \"adu_identification\", \"adu_classification\", \"stance\", or \"relationship\"\n",
        "        claim: The claim text (for stance and relationship tasks)\n",
        "        premise: The premise text (for stance and relationship tasks)\n",
        "\n",
        "    Returns:\n",
        "        Prediction result as a string\n",
        "    \"\"\"\n",
        "    if task == \"stance\":\n",
        "        if not claim or not premise:\n",
        "            return \"Error: Claim and premise required for stance classification\"\n",
        "        prompt = f\"Instruction: Determine if the premise supports or counters the given claim.\\nInput: Claim: {claim}\\nPremise: {premise}\\nOutput:\"\n",
        "\n",
        "    elif task == \"adu_identification\":\n",
        "        prompt = f\"Instruction: Identify whether the following text contains an Argumentative Discourse Unit (ADU). An ADU is a span of text that serves as a claim or premise in an argument.\\nInput: Text: {text}\\nOutput:\"\n",
        "\n",
        "    elif task == \"adu_classification\":\n",
        "        prompt = f\"Instruction: Classify the following Argumentative Discourse Unit (ADU) as either a claim or premise. A claim is the main point being argued, while a premise provides support or evidence.\\nInput: ADU: {text}\\nOutput:\"\n",
        "\n",
        "    elif task == \"relationship\":\n",
        "        if not claim or not premise:\n",
        "            return \"Error: Claim and premise required for relationship identification\"\n",
        "        prompt = f\"Instruction: Identify the relationship between the following claim and premise. Explain how they are connected in the argument structure.\\nInput: Claim: {claim}\\nPremise: {premise}\\nOutput:\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=100,\n",
        "            temperature=0.1,\n",
        "            do_sample=False  # Deterministic generation for evaluation\n",
        "        )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    prediction = generated_text.split(\"Output:\")[-1].strip()\n",
        "\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMPC0_TFoeXU"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "08cbb85a175c4883b4a5afd9a50b1586",
            "a3605851682849c88efdb9ea0debf80d",
            "26cd72fabd8c43ab806a2dcad3f0c6cc",
            "38a7920357e64a82875665933276da75",
            "8d7cb339ed614d12a4d8d36eae9d83a8",
            "e248402daad740d783eaf0c6d9a75132",
            "85f417a1c7124041bf85b51df506f288",
            "be9be6d4e9c54611bda1030107f88985",
            "a3e931b4da664d26a29051e2197f8d00",
            "9983f6e7195e430e808686a46796918a",
            "e345e525cb074b749cb764b80b823f93",
            "32e7b5fb4edc4d50bac339760b66eace",
            "8b57561c006d4b2b895034b3cc71cede",
            "ae27d26be2a84b919a89d56f815c9706",
            "83a72e1ae1964b8080c96e44f39a0292",
            "49f2e9af05cf4479a01cc7457f6881f0",
            "9d809d79979045b683406f99db02e5d5",
            "72d985d7ce7c4c718c42921bdbeff6b0",
            "e48777c9f7f74bc09fda9e5d7c62ec11",
            "2c64c0c867d840b591f0ec1f906a105d",
            "5e5f6872ca44421cbec34aecfcf91b2d",
            "17f2808a0d9443238756e71f5578b6a7",
            "14388c4fd4514edbb17ca0b860bc17b4",
            "3d6fbf30ef424dfbb139c0b534cd30e2",
            "826c753b4305473d8c603a22409ad52b",
            "3a334460f1e2471f9f05f77a76cfc021",
            "1ec06746870440c28e2c4ff0b01354cb",
            "6532513f433a461d983fc99c5d8def5d",
            "e9259966af81448ca26df62e07544fd1",
            "b436b7697eda434ea47aae35e0c351a1",
            "1ac00683d02849b5a27ac038754c1264",
            "69cf356cd9a449b09f2227a0d0e511f5",
            "36791871c0134fa38ea119be318ec8b4"
          ]
        },
        "id": "_zyf2b8woXVx",
        "outputId": "a92816b1-34c4-425c-cd72-5bf5a79703f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training pipeline...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08cbb85a175c4883b4a5afd9a50b1586",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32e7b5fb4edc4d50bac339760b66eace",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/196428 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14388c4fd4514edbb17ca0b860bc17b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/49110 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Load your data\n",
        "\n",
        "    print(\"Starting training pipeline...\")\n",
        "    model, tokenizer, model_id = train_argument_mining_model(train_data)\n",
        "\n",
        "    # Example inference for all tasks\n",
        "    print(\"\\n--- Example Inferences ---\")\n",
        "\n",
        "    # 1. ADU Identification example\n",
        "    example_text = \"The government should invest more in renewable energy.\"\n",
        "    adu_prediction = run_inference(model, tokenizer, example_text, task=\"adu_identification\")\n",
        "    print(f\"ADU Identification: {adu_prediction}\")\n",
        "\n",
        "    # 2. ADU Classification example\n",
        "    example_adu = \"Studies show that renewable energy creates more jobs than fossil fuels.\"\n",
        "    class_prediction = run_inference(model, tokenizer, example_adu, task=\"adu_classification\")\n",
        "    print(f\"ADU Classification: {class_prediction}\")\n",
        "\n",
        "    # 3. Stance Classification example\n",
        "    example_claim = \"This house believes that social media is harmful to society.\"\n",
        "    example_premise = \"Social media has been linked to increased rates of depression in teenagers.\"\n",
        "    stance_prediction = run_inference(model, tokenizer, None, task=\"stance\",\n",
        "                                     claim=example_claim, premise=example_premise)\n",
        "    print(f\"Stance Classification: {stance_prediction}\")\n",
        "\n",
        "    # 4. Relationship Identification example\n",
        "    relationship_prediction = run_inference(model, tokenizer, None, task=\"relationship\",\n",
        "                                           claim=example_claim, premise=example_premise)\n",
        "    print(f\"Relationship Identification: {relationship_prediction}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Awu9HcUEiJWD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08cbb85a175c4883b4a5afd9a50b1586": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3605851682849c88efdb9ea0debf80d",
              "IPY_MODEL_26cd72fabd8c43ab806a2dcad3f0c6cc",
              "IPY_MODEL_38a7920357e64a82875665933276da75"
            ],
            "layout": "IPY_MODEL_8d7cb339ed614d12a4d8d36eae9d83a8"
          }
        },
        "14388c4fd4514edbb17ca0b860bc17b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d6fbf30ef424dfbb139c0b534cd30e2",
              "IPY_MODEL_826c753b4305473d8c603a22409ad52b",
              "IPY_MODEL_3a334460f1e2471f9f05f77a76cfc021"
            ],
            "layout": "IPY_MODEL_1ec06746870440c28e2c4ff0b01354cb"
          }
        },
        "17f2808a0d9443238756e71f5578b6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ac00683d02849b5a27ac038754c1264": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ec06746870440c28e2c4ff0b01354cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26cd72fabd8c43ab806a2dcad3f0c6cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be9be6d4e9c54611bda1030107f88985",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3e931b4da664d26a29051e2197f8d00",
            "value": 3
          }
        },
        "2c64c0c867d840b591f0ec1f906a105d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32e7b5fb4edc4d50bac339760b66eace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b57561c006d4b2b895034b3cc71cede",
              "IPY_MODEL_ae27d26be2a84b919a89d56f815c9706",
              "IPY_MODEL_83a72e1ae1964b8080c96e44f39a0292"
            ],
            "layout": "IPY_MODEL_49f2e9af05cf4479a01cc7457f6881f0"
          }
        },
        "36791871c0134fa38ea119be318ec8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38a7920357e64a82875665933276da75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9983f6e7195e430e808686a46796918a",
            "placeholder": "",
            "style": "IPY_MODEL_e345e525cb074b749cb764b80b823f93",
            "value": "3/3[01:41&lt;00:00,32.17s/it]"
          }
        },
        "3a334460f1e2471f9f05f77a76cfc021": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69cf356cd9a449b09f2227a0d0e511f5",
            "placeholder": "",
            "style": "IPY_MODEL_36791871c0134fa38ea119be318ec8b4",
            "value": "37913/49110[02:01&lt;00:44,252.07examples/s]"
          }
        },
        "3d6fbf30ef424dfbb139c0b534cd30e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6532513f433a461d983fc99c5d8def5d",
            "placeholder": "",
            "style": "IPY_MODEL_e9259966af81448ca26df62e07544fd1",
            "value": "Map:77%"
          }
        },
        "49f2e9af05cf4479a01cc7457f6881f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e5f6872ca44421cbec34aecfcf91b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6532513f433a461d983fc99c5d8def5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69cf356cd9a449b09f2227a0d0e511f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72d985d7ce7c4c718c42921bdbeff6b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "826c753b4305473d8c603a22409ad52b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b436b7697eda434ea47aae35e0c351a1",
            "max": 49110,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ac00683d02849b5a27ac038754c1264",
            "value": 37913
          }
        },
        "83a72e1ae1964b8080c96e44f39a0292": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e5f6872ca44421cbec34aecfcf91b2d",
            "placeholder": "",
            "style": "IPY_MODEL_17f2808a0d9443238756e71f5578b6a7",
            "value": "196428/196428[10:44&lt;00:00,297.46examples/s]"
          }
        },
        "85f417a1c7124041bf85b51df506f288": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b57561c006d4b2b895034b3cc71cede": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d809d79979045b683406f99db02e5d5",
            "placeholder": "",
            "style": "IPY_MODEL_72d985d7ce7c4c718c42921bdbeff6b0",
            "value": "Map:100%"
          }
        },
        "8d7cb339ed614d12a4d8d36eae9d83a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9983f6e7195e430e808686a46796918a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d809d79979045b683406f99db02e5d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3605851682849c88efdb9ea0debf80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e248402daad740d783eaf0c6d9a75132",
            "placeholder": "",
            "style": "IPY_MODEL_85f417a1c7124041bf85b51df506f288",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "a3e931b4da664d26a29051e2197f8d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae27d26be2a84b919a89d56f815c9706": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e48777c9f7f74bc09fda9e5d7c62ec11",
            "max": 196428,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c64c0c867d840b591f0ec1f906a105d",
            "value": 196428
          }
        },
        "b436b7697eda434ea47aae35e0c351a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be9be6d4e9c54611bda1030107f88985": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e248402daad740d783eaf0c6d9a75132": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e345e525cb074b749cb764b80b823f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e48777c9f7f74bc09fda9e5d7c62ec11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9259966af81448ca26df62e07544fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}