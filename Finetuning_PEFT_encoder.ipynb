{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6ks8Mm/JuitFcxWRfqESs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "73653d6dd8a24102931b15c9dd50b6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e01f5cac04843fd90164cb62125b740",
              "IPY_MODEL_4acbf3deadcb4e02bd09408a4495ad96",
              "IPY_MODEL_cd219c5a929e4f55b27c95c434a36b29"
            ],
            "layout": "IPY_MODEL_8328be77eab44e2aa1e0d54121fc5567"
          }
        },
        "4e01f5cac04843fd90164cb62125b740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c331e52447b74e86822bc4c7a73dc795",
            "placeholder": "​",
            "style": "IPY_MODEL_72def41d5414471ba39d212bd7c1bf0d",
            "value": "Map: 100%"
          }
        },
        "4acbf3deadcb4e02bd09408a4495ad96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06e5a7e862ae4cfc85f1eba673e4ea67",
            "max": 52380,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bdcbc54ce0ef488b952d2516ae006703",
            "value": 52380
          }
        },
        "cd219c5a929e4f55b27c95c434a36b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02f153c765c24f7ea6373f44467c911d",
            "placeholder": "​",
            "style": "IPY_MODEL_2b0a495a5e58448fa6ed3390bb57880f",
            "value": " 52380/52380 [01:29&lt;00:00, 555.31 examples/s]"
          }
        },
        "8328be77eab44e2aa1e0d54121fc5567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c331e52447b74e86822bc4c7a73dc795": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72def41d5414471ba39d212bd7c1bf0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06e5a7e862ae4cfc85f1eba673e4ea67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdcbc54ce0ef488b952d2516ae006703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02f153c765c24f7ea6373f44467c911d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b0a495a5e58448fa6ed3390bb57880f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cfe3781df8a4eb28a4c684b6dd5586a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7836f20f2aaf471aa66b37ff2778ec22",
              "IPY_MODEL_46e8b179136b472ba1e0e0a0bc08e0e7",
              "IPY_MODEL_643b6d7295964fc9bd509db2765126f9"
            ],
            "layout": "IPY_MODEL_dbaf790b68a9462e9ca043245b72c11a"
          }
        },
        "7836f20f2aaf471aa66b37ff2778ec22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8071634d43ee4748b7fa1e0264159126",
            "placeholder": "​",
            "style": "IPY_MODEL_6c1639d13785466085adfaa5df0d0d4c",
            "value": "Map: 100%"
          }
        },
        "46e8b179136b472ba1e0e0a0bc08e0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e64d60a00c634ff18646419d84511ffd",
            "max": 13096,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_953f181b479f4906b510163a3035f35b",
            "value": 13096
          }
        },
        "643b6d7295964fc9bd509db2765126f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed6d3cf042734b9e887b4353ef51022c",
            "placeholder": "​",
            "style": "IPY_MODEL_befb9e7c560042d4ad2afb8a98681776",
            "value": " 13096/13096 [00:20&lt;00:00, 679.73 examples/s]"
          }
        },
        "dbaf790b68a9462e9ca043245b72c11a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8071634d43ee4748b7fa1e0264159126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c1639d13785466085adfaa5df0d0d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e64d60a00c634ff18646419d84511ffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "953f181b479f4906b510163a3035f35b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed6d3cf042734b9e887b4353ef51022c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "befb9e7c560042d4ad2afb8a98681776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Horizontal-Labs/training-zoo/blob/main/Finetuning_PEFT_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLazhbMZi7xv",
        "outputId": "2e5e0fbc-3188-4935-9436-ae636d8b34aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,683 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,944 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,363 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,725 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,245 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [77.3 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,934 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,517 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,546 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Fetched 30.6 MB in 3s (10.5 MB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "89 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libaom-dev libarmadillo-dev libarpack2-dev libblosc-dev libcfitsio-dev\n",
            "  libdav1d-dev libde265-dev libfreexl-dev libfyba-dev libgeos-dev\n",
            "  libgeotiff-dev libgif-dev libhdf4-alt-dev libheif-dev libjson-c-dev\n",
            "  libkml-dev libkmlconvenience1 libkmlregionator1 libkmlxsd1 liblz4-dev\n",
            "  libminizip-dev libnetcdf-dev libodbccr2 libogdi-dev libopenjp2-7-dev\n",
            "  libpoppler-dev libpoppler-private-dev libpq-dev libproj-dev libqhull-dev\n",
            "  libqhull8.0 libqhullcpp8.0 librttopo-dev libspatialite-dev libsqlite3-dev\n",
            "  libsuperlu-dev liburiparser-dev libwebp-dev libx265-dev libxerces-c-dev\n",
            "  unixodbc-dev\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  gdal-data gdal-plugins libfreexl-dev libfreexl1 libmariadb3 libproj-dev\n",
            "  libproj25 mariadb-common proj-data\n",
            "Suggested packages:\n",
            "  proj-bin\n",
            "The following packages will be REMOVED:\n",
            "  default-libmysqlclient-dev libgdal-dev libmysqlclient-dev\n",
            "The following NEW packages will be installed:\n",
            "  libmariadb-dev libmariadb3 mariadb-common\n",
            "The following packages will be upgraded:\n",
            "  gdal-data gdal-plugins libfreexl-dev libfreexl1 libproj-dev libproj25\n",
            "  proj-data\n",
            "7 upgraded, 3 newly installed, 3 to remove and 81 not upgraded.\n",
            "Need to get 10.8 MB of archives.\n",
            "After this operation, 8,677 kB disk space will be freed.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 mariadb-common all 1:10.6.21-0ubuntu0.22.04.2 [17.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmariadb3 amd64 1:10.6.21-0ubuntu0.22.04.2 [189 kB]\n",
            "Get:3 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 gdal-data all 3.8.4+dfsg-1~jammy0 [588 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmariadb-dev amd64 1:10.6.21-0ubuntu0.22.04.2 [200 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 gdal-plugins amd64 3.8.4+dfsg-1~jammy0 [351 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 libfreexl-dev amd64 2.0.0-1~jammy0 [47.2 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 libfreexl1 amd64 2.0.0-1~jammy0 [44.1 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 proj-data all 9.3.1-1~jammy0 [7,902 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 libproj-dev amd64 9.3.1-1~jammy0 [121 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 libproj25 amd64 9.3.1-1~jammy0 [1,374 kB]\n",
            "Fetched 10.8 MB in 2s (4,742 kB/s)\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Removing libgdal-dev (3.6.4+dfsg-1~jammy0) ...\n",
            "Removing default-libmysqlclient-dev:amd64 (1.0.8) ...\n",
            "Removing libmysqlclient-dev (8.0.42-0ubuntu0.22.04.1) ...\n",
            "(Reading database ... 125985 files and directories currently installed.)\n",
            "Preparing to unpack .../0-gdal-data_3.8.4+dfsg-1~jammy0_all.deb ...\n",
            "Unpacking gdal-data (3.8.4+dfsg-1~jammy0) over (3.6.4+dfsg-1~jammy0) ...\n",
            "Preparing to unpack .../1-gdal-plugins_3.8.4+dfsg-1~jammy0_amd64.deb ...\n",
            "Unpacking gdal-plugins:amd64 (3.8.4+dfsg-1~jammy0) over (3.6.4+dfsg-1~jammy0) ...\n",
            "Preparing to unpack .../2-libfreexl-dev_2.0.0-1~jammy0_amd64.deb ...\n",
            "Unpacking libfreexl-dev:amd64 (2.0.0-1~jammy0) over (1.0.6-1) ...\n",
            "Preparing to unpack .../3-libfreexl1_2.0.0-1~jammy0_amd64.deb ...\n",
            "Unpacking libfreexl1:amd64 (2.0.0-1~jammy0) over (1.0.6-1) ...\n",
            "Selecting previously unselected package mariadb-common.\n",
            "Preparing to unpack .../4-mariadb-common_1%3a10.6.21-0ubuntu0.22.04.2_all.deb ...\n",
            "Unpacking mariadb-common (1:10.6.21-0ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package libmariadb3:amd64.\n",
            "Preparing to unpack .../5-libmariadb3_1%3a10.6.21-0ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking libmariadb3:amd64 (1:10.6.21-0ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package libmariadb-dev.\n",
            "Preparing to unpack .../6-libmariadb-dev_1%3a10.6.21-0ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking libmariadb-dev (1:10.6.21-0ubuntu0.22.04.2) ...\n",
            "Preparing to unpack .../7-proj-data_9.3.1-1~jammy0_all.deb ...\n",
            "Unpacking proj-data (9.3.1-1~jammy0) over (9.1.1-1~jammy0) ...\n",
            "Preparing to unpack .../8-libproj-dev_9.3.1-1~jammy0_amd64.deb ...\n",
            "Unpacking libproj-dev:amd64 (9.3.1-1~jammy0) over (9.1.1-1~jammy0) ...\n",
            "Preparing to unpack .../9-libproj25_9.3.1-1~jammy0_amd64.deb ...\n",
            "Unpacking libproj25:amd64 (9.3.1-1~jammy0) over (9.1.1-1~jammy0) ...\n",
            "Setting up proj-data (9.3.1-1~jammy0) ...\n",
            "Setting up libproj25:amd64 (9.3.1-1~jammy0) ...\n",
            "Setting up gdal-data (3.8.4+dfsg-1~jammy0) ...\n",
            "Setting up mariadb-common (1:10.6.21-0ubuntu0.22.04.2) ...\n",
            "update-alternatives: using /etc/mysql/mariadb.cnf to provide /etc/mysql/my.cnf (my.cnf) in auto mode\n",
            "Setting up libproj-dev:amd64 (9.3.1-1~jammy0) ...\n",
            "Setting up libmariadb3:amd64 (1:10.6.21-0ubuntu0.22.04.2) ...\n",
            "Setting up libmariadb-dev (1:10.6.21-0ubuntu0.22.04.2) ...\n",
            "Setting up libfreexl1:amd64 (2.0.0-1~jammy0) ...\n",
            "Setting up gdal-plugins:amd64 (3.8.4+dfsg-1~jammy0) ...\n",
            "Setting up libfreexl-dev:amd64 (2.0.0-1~jammy0) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!apt update\n",
        "!apt install -y libmariadb-dev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mysql-connector-python sqlalchemy mariadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSpD-B7djBEZ",
        "outputId": "998d6816-70ad-465b-8429-f6babc87c1fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-9.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.40)\n",
            "Collecting mariadb\n",
            "  Downloading mariadb-1.1.12.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.9/85.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mariadb) (24.2)\n",
            "Downloading mysql_connector_python-9.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (33.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.9/33.9 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mariadb\n",
            "  Building wheel for mariadb (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mariadb: filename=mariadb-1.1.12-cp311-cp311-linux_x86_64.whl size=197910 sha256=bb71394ad0ad4c3f13dbc9a43e01ba76bb56e293fe4219dd8301cc2132c34637\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/f5/77/a6ab26d26cd1865edbab18ed491f6e87d5ba62a016216a4ec8\n",
            "Successfully built mariadb\n",
            "Installing collected packages: mysql-connector-python, mariadb\n",
            "Successfully installed mariadb-1.1.12 mysql-connector-python-9.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xgFsVjWjBYv",
        "outputId": "1e38f6dd-ac4b-4d15-cc05-e7f405369d1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Horizontal-Labs/Argument-Mining.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9ZFohtWjEsX",
        "outputId": "cace240d-ace8-4ae2-de0d-76ea3ba6f1b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Argument-Mining'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 130 (delta 52), reused 92 (delta 27), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (130/130), 218.75 KiB | 1.12 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n",
            "Downloading data/args-me-1.0-cleaned.json (888 MB)\n",
            "Error downloading object: data/args-me-1.0-cleaned.json (6588d8b): Smudge error: Error downloading data/args-me-1.0-cleaned.json (6588d8bdc2cef0a631768d3a884d06cb18f25901c36886ac11c0acb3e7691530): batch response: This repository exceeded its LFS budget. The account responsible for the budget should increase it to restore access.\n",
            "\n",
            "Errors logged to /content/Argument-Mining/.git/lfs/logs/20250518T183401.8303173.log\n",
            "Use `git lfs logs last` to view the log.\n",
            "error: external filter 'git-lfs filter-process' failed\n",
            "fatal: data/args-me-1.0-cleaned.json: smudge filter lfs failed\n",
            "warning: Clone succeeded, but checkout failed.\n",
            "You can inspect what was checked out with 'git status'\n",
            "and retry with 'git restore --source=HEAD :/'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change direcotry\n",
        "import sys\n",
        "sys.path.append('/content/Argument-Mining')"
      ],
      "metadata": {
        "id": "1yKpMMJMjGpS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from db.queries import get_training_data, get_test_data\n",
        "\n",
        "# Load training data\n",
        "claims_train, premises_train, relationships_train = get_training_data()\n",
        "\n",
        "# Load test data\n",
        "claims_test, premises_test, relationships_test = get_test_data()"
      ],
      "metadata": {
        "id": "z9_uEG-LjO7Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create pairs of claims and premises\n",
        "debate_pairs = []\n",
        "\n",
        "for i in range(len(claims_train)):\n",
        "    debate_pairs.append({\n",
        "        \"claim\": claims_train[i].text,\n",
        "        \"premise\": premises_train[i].text,\n",
        "        \"stance\": relationships_train[i],\n",
        "    })\n",
        "\n",
        "# Create final DataFrame\n",
        "train_data = pd.DataFrame(debate_pairs)\n",
        "\n",
        "print(train_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQEsMlpdjRve",
        "outputId": "fb17d3e4-60b0-47fd-e708-cb22ece4372f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               claim  \\\n",
            "0  This house believes that the sale of violent v...   \n",
            "1  This house supports the one-child policy of th...   \n",
            "2  This house would permit the use of performance...   \n",
            "3  This house would make physical education compu...   \n",
            "4  This house believes in the use of affirmative ...   \n",
            "\n",
            "                                             premise      stance  \n",
            "0  video game violence is not related to serious ...  stance_con  \n",
            "1         The policy had proved remarkably effective  stance_pro  \n",
            "2  The use of drugs to enhance performance is con...  stance_con  \n",
            "3  Frequent and regular physical exercise boosts ...  stance_pro  \n",
            "4  In some countries which have laws on racial eq...  stance_con  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove 'stance_' prefix for simplicity\n",
        "train_data['stance'] = train_data['stance'].str.replace('stance_', '')\n",
        "\n",
        "print(train_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuh-pLHJjTd1",
        "outputId": "489a35e4-bdbb-458f-ce66-7dc889541e10"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               claim  \\\n",
            "0  This house believes that the sale of violent v...   \n",
            "1  This house supports the one-child policy of th...   \n",
            "2  This house would permit the use of performance...   \n",
            "3  This house would make physical education compu...   \n",
            "4  This house believes in the use of affirmative ...   \n",
            "\n",
            "                                             premise stance  \n",
            "0  video game violence is not related to serious ...    con  \n",
            "1         The policy had proved remarkably effective    pro  \n",
            "2  The use of drugs to enhance performance is con...    con  \n",
            "3  Frequent and regular physical exercise boosts ...    pro  \n",
            "4  In some countries which have laws on racial eq...    con  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetune RoBERTa"
      ],
      "metadata": {
        "id": "lEa414bzjYSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    RobertaForSequenceClassification,\n",
        "    RobertaTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from peft import (\n",
        "    get_peft_model,\n",
        "    LoraConfig,\n",
        "    TaskType,\n",
        "    PeftModel,\n",
        "    PeftConfig\n",
        ")"
      ],
      "metadata": {
        "id": "fEy6jKGNjZuV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, eval_data = train_test_split(train_data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Z70JSvvTmeni"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task definitions\n",
        "TASKS = {\n",
        "    \"adu_identification\": {\n",
        "        \"num_labels\": 2,  # Yes/No - contains ADU\n",
        "        \"id2label\": {0: \"No\", 1: \"Yes\"},\n",
        "        \"label2id\": {\"No\": 0, \"Yes\": 1}\n",
        "    },\n",
        "    \"adu_classification\": {\n",
        "        \"num_labels\": 2,  # claim or premise\n",
        "        \"id2label\": {0: \"claim\", 1: \"premise\"},\n",
        "        \"label2id\": {\"claim\": 0, \"premise\": 1}\n",
        "    },\n",
        "    \"stance_classification\": {\n",
        "        \"num_labels\": 2,  # pro or con\n",
        "        \"id2label\": {0: \"con\", 1: \"pro\"},\n",
        "        \"label2id\": {\"con\": 0, \"pro\": 1}\n",
        "    },\n",
        "    \"relationship_identification\": {\n",
        "        \"num_labels\": 2,  # supportive or contradictory\n",
        "        \"id2label\": {0: \"contradictory\", 1: \"supportive\"},\n",
        "        \"label2id\": {\"contradictory\": 0, \"supportive\": 1}\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "qBV8M2b-jbRx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Formatting"
      ],
      "metadata": {
        "id": "_JRY61OVjqaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_for_argument_mining_roberta(df):\n",
        "    \"\"\"\n",
        "    Format dataset for RoBERTa fine-tuning, adapting the same tasks\n",
        "    but in a format suitable for sequence classification.\n",
        "    \"\"\"\n",
        "    formatted_data = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        # Task 1: ADU Identification (claim)\n",
        "        claim_adu_sample = {\n",
        "            \"task\": \"adu_identification\",\n",
        "            \"text\": row['claim'],\n",
        "            \"label\": 1  # 1 for contains ADU\n",
        "        }\n",
        "\n",
        "        # Task 1: ADU Identification (premise)\n",
        "        premise_adu_sample = {\n",
        "            \"task\": \"adu_identification\",\n",
        "            \"text\": row['premise'],\n",
        "            \"label\": 1  # 1 for contains ADU\n",
        "        }\n",
        "\n",
        "        # Task 2: ADU Classification (claim)\n",
        "        adu_class_sample_claim = {\n",
        "            \"task\": \"adu_classification\",\n",
        "            \"text\": row['claim'],\n",
        "            \"label\": 0  # 0 for claim\n",
        "        }\n",
        "\n",
        "        # Task 2: ADU Classification (premise)\n",
        "        adu_class_sample_premise = {\n",
        "            \"task\": \"adu_classification\",\n",
        "            \"text\": row['premise'],\n",
        "            \"label\": 1  # 1 for premise\n",
        "        }\n",
        "\n",
        "        # Task 3: Stance Classification\n",
        "        stance_sample = {\n",
        "            \"task\": \"stance_classification\",\n",
        "            \"text\": f\"{row['claim']} </s> {row['premise']}\",  # RoBERTa uses </s> as separator\n",
        "            \"label\": 1 if row['stance'] == 'pro' else 0  # 1 for 'pro', 0 for 'con'\n",
        "        }\n",
        "\n",
        "        # Task 4: Relationship identification\n",
        "        relationship_sample = {\n",
        "            \"task\": \"relationship_identification\",\n",
        "            \"text\": f\"{row['claim']} </s> {row['premise']}\",  # RoBERTa uses </s> as separator\n",
        "            \"label\": 1 if row['stance'] == 'pro' else 0  # 1 for supportive, 0 for contradictory\n",
        "        }\n",
        "\n",
        "        # Add all tasks to our dataset\n",
        "        formatted_data.extend([\n",
        "            claim_adu_sample,\n",
        "            premise_adu_sample,\n",
        "            adu_class_sample_claim,\n",
        "            adu_class_sample_premise,\n",
        "            stance_sample,\n",
        "            relationship_sample\n",
        "        ])\n",
        "\n",
        "    return formatted_data"
      ],
      "metadata": {
        "id": "Xts6os_SjsDz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function_roberta(examples, tokenizer, max_length=512):\n",
        "    \"\"\"\n",
        "    Tokenize inputs for RoBERTa model\n",
        "    \"\"\"\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )"
      ],
      "metadata": {
        "id": "yHoPZL7ejtJc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Model configuration"
      ],
      "metadata": {
        "id": "hiRufvbLl9uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_roberta_model(model_name=\"roberta-base\", num_labels=2):\n",
        "    \"\"\"\n",
        "    Set up RoBERTa model for sequence classification\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load pre-trained RoBERTa model and tokenizer\n",
        "        model = RobertaForSequenceClassification.from_pretrained(\n",
        "            model_name,\n",
        "            num_labels=num_labels,\n",
        "            problem_type=\"single_label_classification\"\n",
        "        )\n",
        "        tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        raise\n"
      ],
      "metadata": {
        "id": "CxnjE2NsmAR4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PEFT LoRa configuration"
      ],
      "metadata": {
        "id": "vvUxZJQ3kBNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def configure_peft_roberta(model):\n",
        "    \"\"\"\n",
        "    Apply LoRA adapter to RoBERTa model\n",
        "    \"\"\"\n",
        "    peft_config = LoraConfig(\n",
        "        task_type=TaskType.SEQ_CLS,\n",
        "        inference_mode=False,\n",
        "        r=8,\n",
        "        lora_alpha=32,\n",
        "        lora_dropout=0.1,\n",
        "        # Target attention modules in RoBERTa\n",
        "        target_modules=[\"query\", \"key\", \"value\"],\n",
        "        bias=\"none\",\n",
        "    )\n",
        "\n",
        "    model = get_peft_model(model, peft_config)\n",
        "\n",
        "    # Print trainable parameters info\n",
        "    print_trainable_parameters(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "\n",
        "    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\")"
      ],
      "metadata": {
        "id": "YqBdqd8zkApO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_training_roberta(model, train_dataset, eval_dataset, output_dir=\"./argument-mining-roberta\"):\n",
        "    \"\"\"\n",
        "    Set up training for RoBERTa model\n",
        "    \"\"\"\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=16,  # RoBERTa can handle larger batches than decoder models\n",
        "        learning_rate=2e-5,  # Standard learning rate for RoBERTa fine-tuning\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=20,\n",
        "        save_strategy=\"epoch\",\n",
        "        warmup_ratio=0.1,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_total_limit=2,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"accuracy\"\n",
        "    )\n",
        "\n",
        "    # Define compute metrics function\n",
        "    def compute_metrics(eval_pred):\n",
        "        logits, labels = eval_pred\n",
        "        predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
        "        accuracy = (predictions == torch.tensor(labels)).float().mean().item()\n",
        "        return {\"accuracy\": accuracy}\n",
        "\n",
        "    # Set up the trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "V18gWDw3j7iD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_argument_mining_roberta(train_data, model_name=\"roberta-base\"):\n",
        "    \"\"\"\n",
        "    Main training pipeline for RoBERTa-based argument mining\n",
        "    \"\"\"\n",
        "    # Split train data for cross-validation\n",
        "    train_df, eval_df = train_test_split(train_data, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Format data for RoBERTa training\n",
        "    formatted_train_data = format_for_argument_mining_roberta(train_df)\n",
        "    formatted_eval_data = format_for_argument_mining_roberta(eval_df)\n",
        "\n",
        "    # Create datasets for each task\n",
        "    task_datasets = {}\n",
        "    eval_task_datasets = {}\n",
        "\n",
        "    for task in [\"adu_identification\", \"adu_classification\", \"stance_classification\", \"relationship_identification\"]:\n",
        "        # Filter data for specific task\n",
        "        task_data = [item for item in formatted_train_data if item[\"task\"] == task]\n",
        "        task_eval_data = [item for item in formatted_eval_data if item[\"task\"] == task]\n",
        "\n",
        "        # Skip if no data for task\n",
        "        if not task_data or not task_eval_data:\n",
        "            continue\n",
        "\n",
        "        # Setup model and tokenizer for this task\n",
        "        num_labels = max([item[\"label\"] for item in task_data]) + 1\n",
        "        model, tokenizer = setup_roberta_model(model_name, num_labels=num_labels)\n",
        "\n",
        "        # Create HF Dataset\n",
        "        hf_train_dataset = Dataset.from_list(task_data)\n",
        "        hf_eval_dataset = Dataset.from_list(task_eval_data)\n",
        "\n",
        "        # Apply tokenizer\n",
        "        train_dataset = hf_train_dataset.map(\n",
        "            lambda x: tokenize_function_roberta(x, tokenizer),\n",
        "            batched=True,\n",
        "            remove_columns=[\"text\", \"task\"]\n",
        "        )\n",
        "\n",
        "        eval_dataset = hf_eval_dataset.map(\n",
        "            lambda x: tokenize_function_roberta(x, tokenizer),\n",
        "            batched=True,\n",
        "            remove_columns=[\"text\", \"task\"]\n",
        "        )\n",
        "\n",
        "        # Configure PEFT/LoRA\n",
        "        model = configure_peft_roberta(model)\n",
        "\n",
        "        # Setup training\n",
        "        trainer = setup_training_roberta(\n",
        "            model,\n",
        "            train_dataset,\n",
        "            eval_dataset,\n",
        "            output_dir=f\"./argument-mining-roberta-{task}\"\n",
        "        )\n",
        "\n",
        "        # Train the model\n",
        "        trainer.train()\n",
        "\n",
        "        # Save the model and tokenizer\n",
        "        peft_model_id = f\"argument-mining-roberta-{task}\"\n",
        "        trainer.model.save_pretrained(peft_model_id)\n",
        "        tokenizer.save_pretrained(peft_model_id)\n",
        "\n",
        "        print(f\"Model for task {task} saved to {peft_model_id}\")\n",
        "\n",
        "        # Store model for inference\n",
        "        task_datasets[task] = {\"model\": model, \"tokenizer\": tokenizer, \"model_id\": peft_model_id}\n",
        "\n",
        "    return task_datasets"
      ],
      "metadata": {
        "id": "OD__zlYCmPwu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_with_roberta_models(text, claim=None, task_datasets=None):\n",
        "    \"\"\"\n",
        "    Inference function to predict using the trained RoBERTa models\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # ADU Identification\n",
        "    if \"adu_identification\" in task_datasets:\n",
        "        model = task_datasets[\"adu_identification\"][\"model\"]\n",
        "        tokenizer = task_datasets[\"adu_identification\"][\"tokenizer\"]\n",
        "\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        outputs = model(**inputs)\n",
        "        prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
        "\n",
        "        results[\"adu_identification\"] = \"Contains ADU\" if prediction == 1 else \"Does not contain ADU\"\n",
        "\n",
        "    # ADU Classification\n",
        "    if \"adu_classification\" in task_datasets and results.get(\"adu_identification\") == \"Contains ADU\":\n",
        "        model = task_datasets[\"adu_classification\"][\"model\"]\n",
        "        tokenizer = task_datasets[\"adu_classification\"][\"tokenizer\"]\n",
        "\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        outputs = model(**inputs)\n",
        "        prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
        "\n",
        "        results[\"adu_classification\"] = \"Claim\" if prediction == 0 else \"Premise\"\n",
        "\n",
        "    # Stance Classification & Relationship (only if claim is provided)\n",
        "    if claim and text and \"stance_classification\" in task_datasets:\n",
        "        model = task_datasets[\"stance_classification\"][\"model\"]\n",
        "        tokenizer = task_datasets[\"stance_classification\"][\"tokenizer\"]\n",
        "\n",
        "        combined_text = f\"{claim} </s> {text}\"  # RoBERTa uses </s> as separator\n",
        "        inputs = tokenizer(combined_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        outputs = model(**inputs)\n",
        "        prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
        "\n",
        "        stance = \"pro\" if prediction == 1 else \"con\"\n",
        "        results[\"stance_classification\"] = stance\n",
        "\n",
        "        # Relationship identification uses the same prediction for simplicity\n",
        "        relationship = \"supportive\" if prediction == 1 else \"contradictory\"\n",
        "        results[\"relationship\"] = relationship\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "ZPd4xzuomTIf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "0KmEK-9cnV1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train all task models\n",
        "task_models = train_argument_mining_roberta(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510,
          "referenced_widgets": [
            "73653d6dd8a24102931b15c9dd50b6cb",
            "4e01f5cac04843fd90164cb62125b740",
            "4acbf3deadcb4e02bd09408a4495ad96",
            "cd219c5a929e4f55b27c95c434a36b29",
            "8328be77eab44e2aa1e0d54121fc5567",
            "c331e52447b74e86822bc4c7a73dc795",
            "72def41d5414471ba39d212bd7c1bf0d",
            "06e5a7e862ae4cfc85f1eba673e4ea67",
            "bdcbc54ce0ef488b952d2516ae006703",
            "02f153c765c24f7ea6373f44467c911d",
            "2b0a495a5e58448fa6ed3390bb57880f",
            "1cfe3781df8a4eb28a4c684b6dd5586a",
            "7836f20f2aaf471aa66b37ff2778ec22",
            "46e8b179136b472ba1e0e0a0bc08e0e7",
            "643b6d7295964fc9bd509db2765126f9",
            "dbaf790b68a9462e9ca043245b72c11a",
            "8071634d43ee4748b7fa1e0264159126",
            "6c1639d13785466085adfaa5df0d0d4c",
            "e64d60a00c634ff18646419d84511ffd",
            "953f181b479f4906b510163a3035f35b",
            "ed6d3cf042734b9e887b4353ef51022c",
            "befb9e7c560042d4ad2afb8a98681776"
          ]
        },
        "id": "Vl2MxHZHnVE4",
        "outputId": "cee1772d-8c25-4635-9562-06eed0cb3921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/52380 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73653d6dd8a24102931b15c9dd50b6cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/13096 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cfe3781df8a4eb28a4c684b6dd5586a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 1034498 || all params: 125681668 || trainable%: 0.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlen-rtz\u001b[0m (\u001b[33mlen-rtz-th-k-ln\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250518_185006-9wr19rj0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/len-rtz-th-k-ln/huggingface/runs/9wr19rj0' target=\"_blank\">./argument-mining-roberta-adu_identification</a></strong> to <a href='https://wandb.ai/len-rtz-th-k-ln/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/len-rtz-th-k-ln/huggingface' target=\"_blank\">https://wandb.ai/len-rtz-th-k-ln/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/len-rtz-th-k-ln/huggingface/runs/9wr19rj0' target=\"_blank\">https://wandb.ai/len-rtz-th-k-ln/huggingface/runs/9wr19rj0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3782' max='9822' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3782/9822 1:19:51 < 2:07:35, 0.79 it/s, Epoch 1.15/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}