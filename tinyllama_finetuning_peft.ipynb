{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPeJElPvdiF+vcM5KrMRapt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3265762bb32f4ff28831536de082625e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bd75baf5a5c4b5798714477cb5c5fe7",
              "IPY_MODEL_996430f5af4b4e83beaab1febb62d577",
              "IPY_MODEL_71d0ab773d844761b9e2ff8ce8cdadbc"
            ],
            "layout": "IPY_MODEL_fb8172f66ac744e7b4983af9aa972b1e"
          }
        },
        "4bd75baf5a5c4b5798714477cb5c5fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9c2be161bee4d04961eca989231858b",
            "placeholder": "​",
            "style": "IPY_MODEL_18e6af3bff404e5c8bc6105007dce9f0",
            "value": "Map: 100%"
          }
        },
        "996430f5af4b4e83beaab1febb62d577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0a683c4703147f1939091cd28eceeb9",
            "max": 196428,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2ac8aeb337b405da2678ec9e3cd366b",
            "value": 196428
          }
        },
        "71d0ab773d844761b9e2ff8ce8cdadbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d304b17c9f314e4aad6bc8d78ca68dc0",
            "placeholder": "​",
            "style": "IPY_MODEL_b3c9eee97e964a7fb62a67acb12a6472",
            "value": " 196428/196428 [10:56&lt;00:00, 380.11 examples/s]"
          }
        },
        "fb8172f66ac744e7b4983af9aa972b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9c2be161bee4d04961eca989231858b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e6af3bff404e5c8bc6105007dce9f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0a683c4703147f1939091cd28eceeb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ac8aeb337b405da2678ec9e3cd366b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d304b17c9f314e4aad6bc8d78ca68dc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3c9eee97e964a7fb62a67acb12a6472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f5b95ed714041dd8bd384b979c0ddd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a05c3f15474c4168ba56650f4a421fd9",
              "IPY_MODEL_d76b88275fc64d48a103b496781d87c1",
              "IPY_MODEL_60982904c13f4f90bd537c96e81c1f8c"
            ],
            "layout": "IPY_MODEL_d03250a1c179443ca41d229d3194a2cb"
          }
        },
        "a05c3f15474c4168ba56650f4a421fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07170c736961404897d27d89cd701837",
            "placeholder": "​",
            "style": "IPY_MODEL_19ba042589574e58b719aa485531a6b8",
            "value": "Map: 100%"
          }
        },
        "d76b88275fc64d48a103b496781d87c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfc6c94645644153a473f123efea130e",
            "max": 49110,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f72d5da7dc4493486793b635c7b51ea",
            "value": 49110
          }
        },
        "60982904c13f4f90bd537c96e81c1f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5f40886f27e4c8f8bc4f3d89477796a",
            "placeholder": "​",
            "style": "IPY_MODEL_00ebff35d1df4cdc821482d43f64017a",
            "value": " 49110/49110 [02:42&lt;00:00, 284.72 examples/s]"
          }
        },
        "d03250a1c179443ca41d229d3194a2cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07170c736961404897d27d89cd701837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19ba042589574e58b719aa485531a6b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfc6c94645644153a473f123efea130e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f72d5da7dc4493486793b635c7b51ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5f40886f27e4c8f8bc4f3d89477796a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00ebff35d1df4cdc821482d43f64017a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5d14bea2801417cabc7e2040eef42d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_199b1e23fad84a84a26f6019807732b6",
              "IPY_MODEL_c2946436eba14bdf94670abc952d937b",
              "IPY_MODEL_974768749c074cadbe855fdcc40059a0"
            ],
            "layout": "IPY_MODEL_94b7cc49dabd437e94d94723265a7060"
          }
        },
        "199b1e23fad84a84a26f6019807732b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfec4c79d859467582b126891373475b",
            "placeholder": "​",
            "style": "IPY_MODEL_4ed510fe8efe4f268b95663b27fe5845",
            "value": "Truncating train dataset: 100%"
          }
        },
        "c2946436eba14bdf94670abc952d937b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb786e336fc244bfa4ec3c9e9735c8f5",
            "max": 196428,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_149d4c930ca94fd5acb8938188dd2576",
            "value": 196428
          }
        },
        "974768749c074cadbe855fdcc40059a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d0b3f54a93a48d49b4530c58222ab2e",
            "placeholder": "​",
            "style": "IPY_MODEL_d86be779c3b44f59a966969e4e80f968",
            "value": " 196428/196428 [00:04&lt;00:00, 73513.82 examples/s]"
          }
        },
        "94b7cc49dabd437e94d94723265a7060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfec4c79d859467582b126891373475b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ed510fe8efe4f268b95663b27fe5845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb786e336fc244bfa4ec3c9e9735c8f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "149d4c930ca94fd5acb8938188dd2576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d0b3f54a93a48d49b4530c58222ab2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d86be779c3b44f59a966969e4e80f968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b997d61181dc4c0b81668bbdc37ffe70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c21c123698dc48bc82dfe7ca2d06f22e",
              "IPY_MODEL_770b22f990b642ff9cd94df3d06ab227",
              "IPY_MODEL_767cabaf0a794ab184e1676828503088"
            ],
            "layout": "IPY_MODEL_ad9fa90beb0549159258bf94f2deb222"
          }
        },
        "c21c123698dc48bc82dfe7ca2d06f22e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9a276894e894cc1a171e5c8ea9331da",
            "placeholder": "​",
            "style": "IPY_MODEL_135b17a3a3f04cd4805db6297a80918b",
            "value": "Truncating eval dataset: 100%"
          }
        },
        "770b22f990b642ff9cd94df3d06ab227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb5065ede8564239a5b452b755da14b4",
            "max": 49110,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_745f595c2ff0472fb24f5b0d9056ba41",
            "value": 49110
          }
        },
        "767cabaf0a794ab184e1676828503088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f2ed03677204398b97587a4cdfc6d01",
            "placeholder": "​",
            "style": "IPY_MODEL_cd3beb3df02a48d998c5f6579544584f",
            "value": " 49110/49110 [00:00&lt;00:00, 64959.49 examples/s]"
          }
        },
        "ad9fa90beb0549159258bf94f2deb222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a276894e894cc1a171e5c8ea9331da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "135b17a3a3f04cd4805db6297a80918b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb5065ede8564239a5b452b755da14b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "745f595c2ff0472fb24f5b0d9056ba41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f2ed03677204398b97587a4cdfc6d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd3beb3df02a48d998c5f6579544584f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Horizontal-Labs/training-zoo/blob/main/tinyllama_finetuning_peft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eimmnld_Nhu3",
        "outputId": "f59299a2-c4b9-4b4a-94a4-299364058109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.1\u001b[0m\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "81 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libmariadb-dev is already the newest version (1:10.6.21-0ubuntu0.22.04.2).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libaom-dev libarmadillo-dev libarpack2-dev libblosc-dev libcfitsio-dev\n",
            "  libdav1d-dev libde265-dev libfreexl-dev libfyba-dev libgeos-dev\n",
            "  libgeotiff-dev libgif-dev libhdf4-alt-dev libheif-dev libjson-c-dev\n",
            "  libkml-dev libkmlconvenience1 libkmlregionator1 libkmlxsd1 liblz4-dev\n",
            "  libminizip-dev libnetcdf-dev libodbccr2 libogdi-dev libopenjp2-7-dev\n",
            "  libpoppler-dev libpoppler-private-dev libpq-dev libproj-dev libqhull-dev\n",
            "  libqhull8.0 libqhullcpp8.0 librttopo-dev libspatialite-dev libsqlite3-dev\n",
            "  libsuperlu-dev liburiparser-dev libwebp-dev libx265-dev libxerces-c-dev\n",
            "  unixodbc-dev\n",
            "Use 'apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 81 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt update\n",
        "!apt install -y libmariadb-dev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mysql-connector-python sqlalchemy mariadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rnwq69pOOYTP",
        "outputId": "285f85f4-0467-45a9-cf82-ba0d7699062a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mysql-connector-python in /usr/local/lib/python3.11/dist-packages (9.3.0)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.40)\n",
            "Requirement already satisfied: mariadb in /usr/local/lib/python3.11/dist-packages (1.1.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mariadb) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WBKP7blOb8J",
        "outputId": "b4f71b88-25c2-4cba-9817-7b42c96508c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Horizontal-Labs/Argument-Mining.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDXPfzTCOea1",
        "outputId": "548cbc1b-e05c-4d34-b332-9eb88367b3cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Argument-Mining' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change direcotry\n",
        "import sys\n",
        "sys.path.append('/content/Argument-Mining')"
      ],
      "metadata": {
        "id": "Xm2hF8K_OhqC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "cache_dir = '/content/Argument-Mining/.cache'\n",
        "\n",
        "# Check if the cache folder exists and delete its contents\n",
        "if os.path.exists(cache_dir):\n",
        "    shutil.rmtree(cache_dir)  # Deletes the entire directory and its contents\n",
        "    print(f\"Cache folder at {cache_dir} has been deleted.\")\n",
        "else:\n",
        "    print(\"Cache folder does not exist.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az_3O9mqdwzv",
        "outputId": "f54c880f-b7cb-441c-f96d-e6ce581bc485"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cache folder at /content/Argument-Mining/.cache has been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Argument-Mining/\n",
        "!git pull origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zdgh4cZeb8M",
        "outputId": "f6eb6671-4d55-420a-e5e7-b4926e188de7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Argument-Mining\n",
            "From https://github.com/Horizontal-Labs/Argument-Mining\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "cache_dir = '/content/Argument-Mining/.cache'\n",
        "os.makedirs(cache_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "n7shxXWjfPQX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from db.queries import get_training_data, get_test_data\n",
        "\n",
        "# Load training data\n",
        "claims_train, premises_train, relationships_train = get_training_data()\n",
        "\n",
        "# Load test data\n",
        "claims_test, premises_test, relationships_test = get_test_data()"
      ],
      "metadata": {
        "id": "P7s4Ag0eO8Wu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Claims:\", len(claims_train))\n",
        "print(\"Train Premises:\", len(premises_train))\n",
        "print(\"Train Relationships:\", len(relationships_train))\n",
        "\n",
        "print(\"Test Claims:\", len(claims_test))\n",
        "print(\"Test Premises:\", len(claims_test))\n",
        "print(\"Test Relationships:\", len(claims_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPcFuqLEd7X6",
        "outputId": "e6afe159-57f6-4661-a9b7-b9772fca6be8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Claims: 40923\n",
            "Train Premises: 40923\n",
            "Train Relationships: 40923\n",
            "Test Claims: 10395\n",
            "Test Premises: 10395\n",
            "Test Relationships: 10395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check attributes available in one of the ADU objects\n",
        "print(vars(claims_train[0]))  # Check first claim object\n",
        "print(vars(premises_train[0]))  # Check first premise object"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n0E2b0sPmBe",
        "outputId": "4e85f40d-c46e-48be-fae8-f4d437e28459"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7983cc900530>, 'domain_id': 2, 'id': 3, 'text': 'This house believes that the sale of violent video games to minors should be banned', 'type': 'claim'}\n",
            "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7983a17fef90>, 'domain_id': 2, 'id': 5, 'text': 'video game violence is not related to serious aggressive behavior in real life', 'type': 'premise'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if any ADU is None\n",
        "print(f\"Claims Train has {sum(x is None for x in claims_train)} None values.\")\n",
        "print(f\"Premises Train has {sum(x is None for x in premises_train)} None values.\")\n",
        "print(f\"Relationship Train has {sum(x is None for x in relationships_train)} None values.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8C2oP90QvRC",
        "outputId": "9e37a614-7eea-4f80-cce6-db2bc9f12f7b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claims Train has 0 None values.\n",
            "Premises Train has 0 None values.\n",
            "Relationship Train has 0 None values.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create pairs of claims and premises\n",
        "debate_pairs = []\n",
        "\n",
        "for i in range(len(claims_train)):\n",
        "    debate_pairs.append({\n",
        "        \"claim\": claims_train[i].text,\n",
        "        \"premise\": premises_train[i].text,\n",
        "        \"stance\": relationships_train[i],\n",
        "    })\n",
        "\n",
        "# Create final DataFrame\n",
        "train_data = pd.DataFrame(debate_pairs)\n",
        "\n",
        "print(train_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rPUHo5kPU-M",
        "outputId": "ad2f9636-696d-48fb-c16e-c04684883456"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               claim  \\\n",
            "0  This house believes that the sale of violent v...   \n",
            "1  This house supports the one-child policy of th...   \n",
            "2  This house would permit the use of performance...   \n",
            "3  This house would make physical education compu...   \n",
            "4  This house believes in the use of affirmative ...   \n",
            "\n",
            "                                             premise      stance  \n",
            "0  video game violence is not related to serious ...  stance_con  \n",
            "1         The policy had proved remarkably effective  stance_pro  \n",
            "2  The use of drugs to enhance performance is con...  stance_con  \n",
            "3  Frequent and regular physical exercise boosts ...  stance_pro  \n",
            "4  In some countries which have laws on racial eq...  stance_con  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove 'stance_' prefix for simplicity\n",
        "train_data['stance'] = train_data['stance'].str.replace('stance_', '')\n",
        "\n",
        "print(train_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrI2x4RzZV_f",
        "outputId": "400ef60e-c73f-4e05-ddf8-ef9d6986681e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               claim  \\\n",
            "0  This house believes that the sale of violent v...   \n",
            "1  This house supports the one-child policy of th...   \n",
            "2  This house would permit the use of performance...   \n",
            "3  This house would make physical education compu...   \n",
            "4  This house believes in the use of affirmative ...   \n",
            "\n",
            "                                             premise stance  \n",
            "0  video game violence is not related to serious ...    con  \n",
            "1         The policy had proved remarkably effective    pro  \n",
            "2  The use of drugs to enhance performance is con...    con  \n",
            "3  Frequent and regular physical exercise boosts ...    pro  \n",
            "4  In some countries which have laws on racial eq...    con  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Finetuning**"
      ],
      "metadata": {
        "id": "gQhMttPkXHFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkwghAjsX_fq",
        "outputId": "410eeff8-3c96-4e3a-b937-8c3f879a3767"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.6.0)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl) (3.6.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.51.3)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.31.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (0.21.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.19.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.13.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI8_bXS8qXng",
        "outputId": "5d5e34da-e1e5-4966-aa2e-3e597b4b11fb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMT2F6jdryPR",
        "outputId": "d424fa06-9fe9-46cc-d6d9-ebf1dd850c0f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch # for model training and tensor operations\n",
        "from datasets import Dataset # interface for working with datasets\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,      # loads a pre-trained CLM\n",
        "    AutoTokenizer,             # loads corresponding tokenizer for a model\n",
        "    BitsAndBytesConfig,        # configuration for quantization techniques\n",
        "    TrainingArguments,          # holds arguments for training\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "\n",
        "# PEFT (Parameter-Efficient Fine-Tuning)\n",
        "from peft import (\n",
        "    get_peft_model,               # wraps the base model with PEFT capabilities\n",
        "    LoraConfig,                   # configuration for LoRA (Low-Rank Adaptation)\n",
        "    TaskType,                     # specifies the type of task (e.g. CLM)\n",
        "    prepare_model_for_kbit_training,  # prepares a quantized model\n",
        "    PeftModel                     # class for loading and managing PEFT models\n",
        ")\n",
        "\n",
        "from trl import SFTTrainer          # Trainer for supervised fine-tuning of language models.\n",
        "import evaluate # HF library to compute evaluation metrics for ML models\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report # common metrics for classification tasks"
      ],
      "metadata": {
        "id": "XgDK0aSWQmpT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, eval_data = train_test_split(train_data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ZQzEYL4TY6Ti"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Formatting for Multitask Learning with Instructions"
      ],
      "metadata": {
        "id": "tcKqUi4lbSt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_for_argument_mining(df):\n",
        "    formatted_data = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        # Format with instructions for each task\n",
        "\n",
        "        # Task 1: ADU Identification - Extract ADUs from text\n",
        "        # Samples for ADU identification using both claims and premises\n",
        "        claim_adu_sample = {\n",
        "            \"instruction\": \"Identify whether the following text contains an Argumentative Discourse Unit (ADU). An ADU is a span of text that serves as a claim or premise in an argument.\",\n",
        "            \"input\": f\"Text: {row['claim']}\",\n",
        "            \"output\": \"Yes, this text contains an ADU. It functions as a claim in an argument.\"\n",
        "        }\n",
        "\n",
        "        premise_adu_sample = {\n",
        "            \"instruction\": \"Identify whether the following text contains an Argumentative Discourse Unit (ADU). An ADU is a span of text that serves as a claim or premise in an argument.\",\n",
        "            \"input\": f\"Text: {row['premise']}\",\n",
        "            \"output\": \"Yes, this text contains an ADU. It functions as a premise in an argument.\"\n",
        "        }\n",
        "\n",
        "\n",
        "        # Task 2: ADU Classification (determine if claim or premise)\n",
        "        adu_class_sample = {\n",
        "            \"instruction\": \"Classify the following Argumentative Discourse Unit (ADU) as either a claim or premise. A claim is the main point being argued, while a premise provides support or evidence.\",\n",
        "            \"input\": f\"ADU: {row['claim']}\",\n",
        "            \"output\": \"This ADU is a claim.\"\n",
        "        }\n",
        "\n",
        "        adu_class_sample2 = {\n",
        "            \"instruction\": \"Classify the following Argumentative Discourse Unit (ADU) as either a claim or premise. A claim is the main point being argued, while a premise provides support or evidence.\",\n",
        "            \"input\": f\"ADU: {row['premise']}\",\n",
        "            \"output\": \"This ADU is a premise.\"\n",
        "        }\n",
        "\n",
        "        # Task 3: Stance Classification\n",
        "        stance_sample = {\n",
        "            \"instruction\": \"Determine if the premise supports or counters the given claim.\",\n",
        "            \"input\": f\"Claim: {row['claim']}\\nPremise: {row['premise']}\",\n",
        "            \"output\": f\"{row['stance']}\"\n",
        "        }\n",
        "\n",
        "        # Task 4: Relationship identification between ADUs\n",
        "        relationship_sample = {\n",
        "            \"instruction\": \"Identify the relationship between the following claim and premise. Explain how they are connected in the argument structure.\",\n",
        "            \"input\": f\"Claim: {row['claim']}\\nPremise: {row['premise']}\",\n",
        "            \"output\": f\"The premise {'supports' if row['stance'] == 'pro' else 'counters'} the claim. The relationship is {'supportive' if row['stance'] == 'pro' else 'contradictory'}, where the premise provides {'evidence for' if row['stance'] == 'pro' else 'evidence against'} the main argument.\"\n",
        "        }\n",
        "\n",
        "        # Add all tasks to our dataset\n",
        "        formatted_data.extend([\n",
        "            claim_adu_sample,\n",
        "            premise_adu_sample,\n",
        "            adu_class_sample,\n",
        "            adu_class_sample2,\n",
        "            stance_sample,\n",
        "            relationship_sample\n",
        "        ])\n",
        "\n",
        "    return formatted_data"
      ],
      "metadata": {
        "id": "Y8tYcdTbabWr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example, tokenizer, max_length=1024):\n",
        "    # Combine instruction and input text as prompt\n",
        "    prompt = example['instruction'] + \"\\n\" + example['input']\n",
        "    target = example['output']\n",
        "\n",
        "    # Tokenize inputs (prompt)\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    # Tokenize targets (outputs/labels)\n",
        "    targets = tokenizer(\n",
        "        target,\n",
        "        max_length=256,  # output length limit\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    # Prepare labels, replacing pad token id with -100 (ignore index)\n",
        "    labels = targets[\"input_ids\"].copy()\n",
        "    labels = [l if l != tokenizer.pad_token_id else -100 for l in labels]\n",
        "\n",
        "    # Return dictionary for dataset\n",
        "    return {\n",
        "        \"input_ids\": inputs[\"input_ids\"],\n",
        "        \"attention_mask\": inputs[\"attention_mask\"],\n",
        "        \"labels\": labels\n",
        "    }"
      ],
      "metadata": {
        "id": "rVr-vMm40DbK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Model Configuration"
      ],
      "metadata": {
        "id": "h34Q4g68bbGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns both the model and tokenizer, ready for fine-tuning or inference\n",
        "def setup_model(model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"):\n",
        "    try:\n",
        "        # QLoRA configuration - use 4-bit quantization for memory efficiency\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.float16\n",
        "        )\n",
        "\n",
        "        # Load pre-trained model with quantization\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            quantization_config=bnb_config, # see above\n",
        "            device_map=\"auto\", # maps model layers automatically to available CPU/GPUs\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        # Load correspondent tokenizer for the model\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "        tokenizer.padding_side = \"right\" # padding directions for filler tokens\n",
        "\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "mbTBoTPzbckP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PEFT LoRA configuration"
      ],
      "metadata": {
        "id": "JQB_aM_actYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def configure_peft(model):\n",
        "    peft_config = LoraConfig(\n",
        "        task_type=TaskType.CAUSAL_LM,\n",
        "        inference_mode=False,\n",
        "        r=8,\n",
        "        lora_alpha=32, # scales output of LoRA adapter before its added back to base model weights\n",
        "        lora_dropout=0.1,\n",
        "        # Target only key attention modules\n",
        "        target_modules=[\"q_proj\", \"v_proj\"],\n",
        "        bias=\"none\",       # Don't train biases for more stability\n",
        "    )\n",
        "\n",
        "    # Prepare model for training without gradient checkpointing (trade off memory vs slowing down training)\n",
        "    # model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n",
        "    model = get_peft_model(model, peft_config)\n",
        "\n",
        "    # Print trainable parameters info\n",
        "    print_trainable_parameters(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "eF4-YEkGcnb9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_training(model, train_dataset, eval_dataset, output_dir=\"./argument-mining-lora\"):\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=4,\n",
        "        gradient_accumulation_steps=4,\n",
        "        learning_rate=1e-4,            # Low-ish learning rate for stability\n",
        "        weight_decay=0.05,             # weight decay to combat overfitting\n",
        "        logging_steps=20,\n",
        "        save_strategy=\"epoch\",\n",
        "        warmup_ratio=0.03,\n",
        "        lr_scheduler_type=\"cosine\",\n",
        "        fp16=True,\n",
        "        eval_strategy=\"epoch\",   # Add evaluation during training\n",
        "        save_total_limit=2,            # Save disk space\n",
        "        load_best_model_at_end=True,   # Automatically use best model\n",
        "        remove_unused_columns=False    # Keep all columns for potential use\n",
        "    )\n",
        "\n",
        "    # Set up the trainer\n",
        "    trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset= eval_dataset\n",
        "    )\n",
        "\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "t-lfal1ndKAG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, tokenizer, test_data, task=\"stance\"):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    for item in test_data:\n",
        "        if task == \"stance\":\n",
        "            prompt = f\"Instruction: Determine if the premise supports or counters the given claim.\\nInput: Claim: {item['claim']}\\nPremise: {item['premise']}\\nOutput:\"\n",
        "        elif task == \"adu_identification\":\n",
        "            prompt = f\"Instruction: Identify whether the following text contains an Argumentative Discourse Unit (ADU).\\nInput: Text: {item['text']}\\nOutput:\"\n",
        "        elif task == \"adu_classification\":\n",
        "            prompt = f\"Instruction: Classify the following Argumentative Discourse Unit (ADU) as either a claim or premise.\\nInput: ADU: {item['text']}\\nOutput:\"\n",
        "        elif task == \"relationship\":\n",
        "            prompt = f\"Instruction: Identify the relationship between the following claim and premise.\\nInput: Claim: {item['claim']}\\nPremise: {item['premise']}\\nOutput:\"\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=50,\n",
        "                temperature=0.1,\n",
        "                do_sample=False,\n",
        "                num_beams=1\n",
        "            )\n",
        "\n",
        "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        prediction = generated_text.split(\"Output:\")[-1].strip().lower()\n",
        "\n",
        "        # Extract relevant information based on task\n",
        "        if task == \"stance\":\n",
        "            if \"pro\" in prediction:\n",
        "                predictions.append(\"pro\")\n",
        "            elif \"con\" in prediction:\n",
        "                predictions.append(\"con\")\n",
        "            else:\n",
        "                predictions.append(\"unknown\")\n",
        "\n",
        "            references.append(item['stance'])\n",
        "\n",
        "        elif task == \"adu_identification\":\n",
        "            if \"yes\" in prediction:\n",
        "                predictions.append(\"contains_adu\")\n",
        "            elif \"no\" in prediction:\n",
        "                predictions.append(\"no_adu\")\n",
        "            else:\n",
        "                predictions.append(\"unknown\")\n",
        "\n",
        "            references.append(item['contains_adu'])\n",
        "\n",
        "        elif task == \"adu_classification\":\n",
        "            if \"claim\" in prediction:\n",
        "                predictions.append(\"claim\")\n",
        "            elif \"premise\" in prediction:\n",
        "                predictions.append(\"premise\")\n",
        "            else:\n",
        "                predictions.append(\"unknown\")\n",
        "\n",
        "            references.append(item['adu_type'])\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(references, predictions)\n",
        "\n",
        "    # For binary tasks like ADU identification\n",
        "    if task == \"adu_identification\":\n",
        "        f1 = f1_score(references, predictions, average='binary', pos_label=\"contains_adu\")\n",
        "    # For multi-class tasks\n",
        "    else:\n",
        "        f1 = f1_score(references, predictions, average='weighted')\n",
        "\n",
        "    print(f\"Task: {task}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(classification_report(references, predictions))\n",
        "\n",
        "    return accuracy, f1"
      ],
      "metadata": {
        "id": "BDb1ur6qdiK9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Pipeline\n",
        "\n",
        "def train_argument_mining_model(train_data, model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"):\n",
        "    # Setup model and tokenizer\n",
        "    model, tokenizer = setup_model(model_id)\n",
        "\n",
        "    # Format data for training\n",
        "    formatted_train_data = format_for_argument_mining(train_data)\n",
        "    formatted_eval_data = format_for_argument_mining(eval_data)\n",
        "\n",
        "    # Create HF Dataset from list of dicts\n",
        "    hf_train_dataset = Dataset.from_list(formatted_train_data)\n",
        "    hf_eval_dataset = Dataset.from_list(formatted_eval_data)\n",
        "\n",
        "    # Apply tokenizer function to the train dataset (batched for speed)\n",
        "    train_dataset = hf_train_dataset.map(\n",
        "    lambda x: tokenize_function(x, tokenizer),\n",
        "    batched=False\n",
        "    )\n",
        "\n",
        "    # Apply tokenizer function to the eval dataset (batched for speed)\n",
        "    eval_dataset = hf_eval_dataset.map(\n",
        "    lambda x: tokenize_function(x, tokenizer),\n",
        "    batched=False\n",
        "    )\n",
        "\n",
        "    # Configure PEFT/LoRA\n",
        "    model = configure_peft(model)\n",
        "\n",
        "    # Setup training\n",
        "    trainer = setup_training(model, train_dataset, eval_dataset)\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the model and tokenizer\n",
        "    peft_model_id = f\"argument-mining-{model_id.split('/')[-1]}\"\n",
        "    trainer.model.save_pretrained(peft_model_id)\n",
        "    tokenizer.save_pretrained(peft_model_id)\n",
        "\n",
        "    print(f\"Model saved to {peft_model_id}\")\n",
        "    return model, tokenizer, peft_model_id"
      ],
      "metadata": {
        "id": "H3UuAhuYoL0H"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference(model, tokenizer, text, task=\"stance\", claim=None, premise=None):\n",
        "    \"\"\"\n",
        "    Run inference on different argument mining tasks\n",
        "\n",
        "    Args:\n",
        "        model: The fine-tuned model\n",
        "        tokenizer: The tokenizer\n",
        "        text: Text to analyze (for ADU tasks)\n",
        "        task: Which task to perform - \"adu_identification\", \"adu_classification\", \"stance\", or \"relationship\"\n",
        "        claim: The claim text (for stance and relationship tasks)\n",
        "        premise: The premise text (for stance and relationship tasks)\n",
        "\n",
        "    Returns:\n",
        "        Prediction result as a string\n",
        "    \"\"\"\n",
        "    if task == \"stance\":\n",
        "        if not claim or not premise:\n",
        "            return \"Error: Claim and premise required for stance classification\"\n",
        "        prompt = f\"Instruction: Determine if the premise supports or counters the given claim.\\nInput: Claim: {claim}\\nPremise: {premise}\\nOutput:\"\n",
        "\n",
        "    elif task == \"adu_identification\":\n",
        "        prompt = f\"Instruction: Identify whether the following text contains an Argumentative Discourse Unit (ADU). An ADU is a span of text that serves as a claim or premise in an argument.\\nInput: Text: {text}\\nOutput:\"\n",
        "\n",
        "    elif task == \"adu_classification\":\n",
        "        prompt = f\"Instruction: Classify the following Argumentative Discourse Unit (ADU) as either a claim or premise. A claim is the main point being argued, while a premise provides support or evidence.\\nInput: ADU: {text}\\nOutput:\"\n",
        "\n",
        "    elif task == \"relationship\":\n",
        "        if not claim or not premise:\n",
        "            return \"Error: Claim and premise required for relationship identification\"\n",
        "        prompt = f\"Instruction: Identify the relationship between the following claim and premise. Explain how they are connected in the argument structure.\\nInput: Claim: {claim}\\nPremise: {premise}\\nOutput:\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=100,\n",
        "            temperature=0.1,\n",
        "            do_sample=False  # Deterministic generation for evaluation\n",
        "        )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    prediction = generated_text.split(\"Output:\")[-1].strip()\n",
        "\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "gPykhuy4oomw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "eMPC0_TFoeXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Load your data\n",
        "\n",
        "    print(torch.cuda.is_available())\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "\n",
        "    print(\"Starting training pipeline...\")\n",
        "    model, tokenizer, model_id = train_argument_mining_model(train_data)\n",
        "\n",
        "    # Example inference for all tasks\n",
        "    print(\"\\n--- Example Inferences ---\")\n",
        "\n",
        "    # 1. ADU Identification example\n",
        "    example_text = \"The government should invest more in renewable energy.\"\n",
        "    adu_prediction = run_inference(model, tokenizer, example_text, task=\"adu_identification\")\n",
        "    print(f\"ADU Identification: {adu_prediction}\")\n",
        "\n",
        "    # 2. ADU Classification example\n",
        "    example_adu = \"Studies show that renewable energy creates more jobs than fossil fuels.\"\n",
        "    class_prediction = run_inference(model, tokenizer, example_adu, task=\"adu_classification\")\n",
        "    print(f\"ADU Classification: {class_prediction}\")\n",
        "\n",
        "    # 3. Stance Classification example\n",
        "    example_claim = \"This house believes that social media is harmful to society.\"\n",
        "    example_premise = \"Social media has been linked to increased rates of depression in teenagers.\"\n",
        "    stance_prediction = run_inference(model, tokenizer, None, task=\"stance\",\n",
        "                                     claim=example_claim, premise=example_premise)\n",
        "    print(f\"Stance Classification: {stance_prediction}\")\n",
        "\n",
        "    # 4. Relationship Identification example\n",
        "    relationship_prediction = run_inference(model, tokenizer, None, task=\"relationship\",\n",
        "                                           claim=example_claim, premise=example_premise)\n",
        "    print(f\"Relationship Identification: {relationship_prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471,
          "referenced_widgets": [
            "3265762bb32f4ff28831536de082625e",
            "4bd75baf5a5c4b5798714477cb5c5fe7",
            "996430f5af4b4e83beaab1febb62d577",
            "71d0ab773d844761b9e2ff8ce8cdadbc",
            "fb8172f66ac744e7b4983af9aa972b1e",
            "a9c2be161bee4d04961eca989231858b",
            "18e6af3bff404e5c8bc6105007dce9f0",
            "d0a683c4703147f1939091cd28eceeb9",
            "e2ac8aeb337b405da2678ec9e3cd366b",
            "d304b17c9f314e4aad6bc8d78ca68dc0",
            "b3c9eee97e964a7fb62a67acb12a6472",
            "0f5b95ed714041dd8bd384b979c0ddd8",
            "a05c3f15474c4168ba56650f4a421fd9",
            "d76b88275fc64d48a103b496781d87c1",
            "60982904c13f4f90bd537c96e81c1f8c",
            "d03250a1c179443ca41d229d3194a2cb",
            "07170c736961404897d27d89cd701837",
            "19ba042589574e58b719aa485531a6b8",
            "cfc6c94645644153a473f123efea130e",
            "9f72d5da7dc4493486793b635c7b51ea",
            "d5f40886f27e4c8f8bc4f3d89477796a",
            "00ebff35d1df4cdc821482d43f64017a",
            "f5d14bea2801417cabc7e2040eef42d0",
            "199b1e23fad84a84a26f6019807732b6",
            "c2946436eba14bdf94670abc952d937b",
            "974768749c074cadbe855fdcc40059a0",
            "94b7cc49dabd437e94d94723265a7060",
            "bfec4c79d859467582b126891373475b",
            "4ed510fe8efe4f268b95663b27fe5845",
            "fb786e336fc244bfa4ec3c9e9735c8f5",
            "149d4c930ca94fd5acb8938188dd2576",
            "0d0b3f54a93a48d49b4530c58222ab2e",
            "d86be779c3b44f59a966969e4e80f968",
            "b997d61181dc4c0b81668bbdc37ffe70",
            "c21c123698dc48bc82dfe7ca2d06f22e",
            "770b22f990b642ff9cd94df3d06ab227",
            "767cabaf0a794ab184e1676828503088",
            "ad9fa90beb0549159258bf94f2deb222",
            "b9a276894e894cc1a171e5c8ea9331da",
            "135b17a3a3f04cd4805db6297a80918b",
            "eb5065ede8564239a5b452b755da14b4",
            "745f595c2ff0472fb24f5b0d9056ba41",
            "8f2ed03677204398b97587a4cdfc6d01",
            "cd3beb3df02a48d998c5f6579544584f"
          ]
        },
        "id": "_zyf2b8woXVx",
        "outputId": "7b15bb59-85f1-4d85-dca0-f764d34287df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n",
            "Starting training pipeline...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/196428 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3265762bb32f4ff28831536de082625e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/49110 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f5b95ed714041dd8bd384b979c0ddd8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 1126400 || all params: 616732672 || trainable%: 0.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/196428 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5d14bea2801417cabc7e2040eef42d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating eval dataset:   0%|          | 0/49110 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b997d61181dc4c0b81668bbdc37ffe70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlen-rtz\u001b[0m (\u001b[33mlen-rtz-th-k-ln\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/Argument-Mining/wandb/run-20250518_173055-a8ykrya7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/len-rtz-th-k-ln/huggingface/runs/a8ykrya7' target=\"_blank\">./argument-mining-lora</a></strong> to <a href='https://wandb.ai/len-rtz-th-k-ln/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/len-rtz-th-k-ln/huggingface' target=\"_blank\">https://wandb.ai/len-rtz-th-k-ln/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/len-rtz-th-k-ln/huggingface/runs/a8ykrya7' target=\"_blank\">https://wandb.ai/len-rtz-th-k-ln/huggingface/runs/a8ykrya7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='223' max='36828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  223/36828 19:54 < 54:58:41, 0.18 it/s, Epoch 0.02/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}