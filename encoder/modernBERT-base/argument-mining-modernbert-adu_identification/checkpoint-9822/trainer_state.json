{
  "best_global_step": 3274,
  "best_metric": 1.0,
  "best_model_checkpoint": "./argument-mining-modernbert-adu_identification\\checkpoint-3274",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 9822,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006108735491753207,
      "grad_norm": 12.400099754333496,
      "learning_rate": 3.865717192268566e-07,
      "loss": 1.1983,
      "step": 20
    },
    {
      "epoch": 0.012217470983506415,
      "grad_norm": 14.308473587036133,
      "learning_rate": 7.934893184130214e-07,
      "loss": 1.1874,
      "step": 40
    },
    {
      "epoch": 0.01832620647525962,
      "grad_norm": 12.326553344726562,
      "learning_rate": 1.2004069175991862e-06,
      "loss": 1.1383,
      "step": 60
    },
    {
      "epoch": 0.02443494196701283,
      "grad_norm": 11.782937049865723,
      "learning_rate": 1.607324516785351e-06,
      "loss": 1.0849,
      "step": 80
    },
    {
      "epoch": 0.030543677458766034,
      "grad_norm": 12.999295234680176,
      "learning_rate": 2.014242115971516e-06,
      "loss": 1.0439,
      "step": 100
    },
    {
      "epoch": 0.03665241295051924,
      "grad_norm": 11.541770935058594,
      "learning_rate": 2.4211597151576806e-06,
      "loss": 0.9775,
      "step": 120
    },
    {
      "epoch": 0.04276114844227245,
      "grad_norm": 9.196444511413574,
      "learning_rate": 2.8280773143438456e-06,
      "loss": 0.8497,
      "step": 140
    },
    {
      "epoch": 0.04886988393402566,
      "grad_norm": 8.635388374328613,
      "learning_rate": 3.23499491353001e-06,
      "loss": 0.779,
      "step": 160
    },
    {
      "epoch": 0.05497861942577886,
      "grad_norm": 7.723322868347168,
      "learning_rate": 3.641912512716175e-06,
      "loss": 0.6315,
      "step": 180
    },
    {
      "epoch": 0.06108735491753207,
      "grad_norm": 6.094361782073975,
      "learning_rate": 4.04883011190234e-06,
      "loss": 0.5093,
      "step": 200
    },
    {
      "epoch": 0.06719609040928527,
      "grad_norm": 4.093105316162109,
      "learning_rate": 4.455747711088505e-06,
      "loss": 0.3645,
      "step": 220
    },
    {
      "epoch": 0.07330482590103848,
      "grad_norm": 5.230907440185547,
      "learning_rate": 4.86266531027467e-06,
      "loss": 0.2473,
      "step": 240
    },
    {
      "epoch": 0.0794135613927917,
      "grad_norm": 1.3543790578842163,
      "learning_rate": 5.269582909460834e-06,
      "loss": 0.1409,
      "step": 260
    },
    {
      "epoch": 0.0855222968845449,
      "grad_norm": 0.7053036689758301,
      "learning_rate": 5.676500508647e-06,
      "loss": 0.07,
      "step": 280
    },
    {
      "epoch": 0.0916310323762981,
      "grad_norm": 0.3687954843044281,
      "learning_rate": 6.083418107833164e-06,
      "loss": 0.0271,
      "step": 300
    },
    {
      "epoch": 0.09773976786805132,
      "grad_norm": 0.3286372423171997,
      "learning_rate": 6.49033570701933e-06,
      "loss": 0.0129,
      "step": 320
    },
    {
      "epoch": 0.10384850335980451,
      "grad_norm": 0.1509452611207962,
      "learning_rate": 6.897253306205493e-06,
      "loss": 0.0062,
      "step": 340
    },
    {
      "epoch": 0.10995723885155773,
      "grad_norm": 0.12735070288181305,
      "learning_rate": 7.304170905391659e-06,
      "loss": 0.0037,
      "step": 360
    },
    {
      "epoch": 0.11606597434331094,
      "grad_norm": 0.1037168949842453,
      "learning_rate": 7.711088504577823e-06,
      "loss": 0.0022,
      "step": 380
    },
    {
      "epoch": 0.12217470983506414,
      "grad_norm": 0.051938246935606,
      "learning_rate": 8.11800610376399e-06,
      "loss": 0.0018,
      "step": 400
    },
    {
      "epoch": 0.12828344532681735,
      "grad_norm": 0.013138577342033386,
      "learning_rate": 8.524923702950153e-06,
      "loss": 0.0011,
      "step": 420
    },
    {
      "epoch": 0.13439218081857054,
      "grad_norm": 0.030213352292776108,
      "learning_rate": 8.931841302136319e-06,
      "loss": 0.001,
      "step": 440
    },
    {
      "epoch": 0.14050091631032377,
      "grad_norm": 0.027091749012470245,
      "learning_rate": 9.338758901322483e-06,
      "loss": 0.0007,
      "step": 460
    },
    {
      "epoch": 0.14660965180207697,
      "grad_norm": 0.02844395861029625,
      "learning_rate": 9.745676500508648e-06,
      "loss": 0.0006,
      "step": 480
    },
    {
      "epoch": 0.15271838729383017,
      "grad_norm": 0.006842598784714937,
      "learning_rate": 1.0152594099694813e-05,
      "loss": 0.0004,
      "step": 500
    },
    {
      "epoch": 0.1588271227855834,
      "grad_norm": 0.01850876212120056,
      "learning_rate": 1.0559511698880977e-05,
      "loss": 0.0004,
      "step": 520
    },
    {
      "epoch": 0.1649358582773366,
      "grad_norm": 0.12056729942560196,
      "learning_rate": 1.0966429298067143e-05,
      "loss": 0.0003,
      "step": 540
    },
    {
      "epoch": 0.1710445937690898,
      "grad_norm": 0.0048512909561395645,
      "learning_rate": 1.1373346897253308e-05,
      "loss": 0.0003,
      "step": 560
    },
    {
      "epoch": 0.177153329260843,
      "grad_norm": 0.01749168336391449,
      "learning_rate": 1.1780264496439473e-05,
      "loss": 0.0001,
      "step": 580
    },
    {
      "epoch": 0.1832620647525962,
      "grad_norm": 0.004617692437022924,
      "learning_rate": 1.2187182095625635e-05,
      "loss": 0.0001,
      "step": 600
    },
    {
      "epoch": 0.1893708002443494,
      "grad_norm": 0.010266737081110477,
      "learning_rate": 1.2594099694811802e-05,
      "loss": 0.0001,
      "step": 620
    },
    {
      "epoch": 0.19547953573610263,
      "grad_norm": 0.0029685497283935547,
      "learning_rate": 1.3001017293997966e-05,
      "loss": 0.0002,
      "step": 640
    },
    {
      "epoch": 0.20158827122785583,
      "grad_norm": 0.0070951529778540134,
      "learning_rate": 1.340793489318413e-05,
      "loss": 0.0001,
      "step": 660
    },
    {
      "epoch": 0.20769700671960903,
      "grad_norm": 0.0006093500996939838,
      "learning_rate": 1.3814852492370297e-05,
      "loss": 0.0001,
      "step": 680
    },
    {
      "epoch": 0.21380574221136225,
      "grad_norm": 0.0027916713152080774,
      "learning_rate": 1.4221770091556462e-05,
      "loss": 0.0001,
      "step": 700
    },
    {
      "epoch": 0.21991447770311545,
      "grad_norm": 0.0031972257420420647,
      "learning_rate": 1.4628687690742626e-05,
      "loss": 0.0001,
      "step": 720
    },
    {
      "epoch": 0.22602321319486865,
      "grad_norm": 0.005021069198846817,
      "learning_rate": 1.5035605289928789e-05,
      "loss": 0.0001,
      "step": 740
    },
    {
      "epoch": 0.23213194868662188,
      "grad_norm": 0.0006609234842471778,
      "learning_rate": 1.5442522889114954e-05,
      "loss": 0.0001,
      "step": 760
    },
    {
      "epoch": 0.23824068417837507,
      "grad_norm": 0.001981377135962248,
      "learning_rate": 1.5849440488301118e-05,
      "loss": 0.0,
      "step": 780
    },
    {
      "epoch": 0.24434941967012827,
      "grad_norm": 0.00039499570266343653,
      "learning_rate": 1.6256358087487286e-05,
      "loss": 0.0001,
      "step": 800
    },
    {
      "epoch": 0.25045815516188147,
      "grad_norm": 0.003763243556022644,
      "learning_rate": 1.666327568667345e-05,
      "loss": 0.0,
      "step": 820
    },
    {
      "epoch": 0.2565668906536347,
      "grad_norm": 0.0009041662560775876,
      "learning_rate": 1.7070193285859615e-05,
      "loss": 0.0,
      "step": 840
    },
    {
      "epoch": 0.2626756261453879,
      "grad_norm": 0.0002219624147983268,
      "learning_rate": 1.747711088504578e-05,
      "loss": 0.0001,
      "step": 860
    },
    {
      "epoch": 0.2687843616371411,
      "grad_norm": 0.001611029845662415,
      "learning_rate": 1.7884028484231945e-05,
      "loss": 0.0,
      "step": 880
    },
    {
      "epoch": 0.2748930971288943,
      "grad_norm": 0.00015967051149345934,
      "learning_rate": 1.829094608341811e-05,
      "loss": 0.0,
      "step": 900
    },
    {
      "epoch": 0.28100183262064754,
      "grad_norm": 0.0057272412814199924,
      "learning_rate": 1.8697863682604274e-05,
      "loss": 0.0,
      "step": 920
    },
    {
      "epoch": 0.2871105681124007,
      "grad_norm": 0.0006666608387604356,
      "learning_rate": 1.9104781281790438e-05,
      "loss": 0.0,
      "step": 940
    },
    {
      "epoch": 0.29321930360415394,
      "grad_norm": 0.020704733207821846,
      "learning_rate": 1.9511698880976603e-05,
      "loss": 0.0,
      "step": 960
    },
    {
      "epoch": 0.29932803909590716,
      "grad_norm": 0.0006177315954118967,
      "learning_rate": 1.9918616480162767e-05,
      "loss": 0.0,
      "step": 980
    },
    {
      "epoch": 0.30543677458766033,
      "grad_norm": 0.001629187143407762,
      "learning_rate": 1.9963796809593846e-05,
      "loss": 0.0,
      "step": 1000
    },
    {
      "epoch": 0.31154551007941356,
      "grad_norm": 0.000658574397675693,
      "learning_rate": 1.9918542821586154e-05,
      "loss": 0.0,
      "step": 1020
    },
    {
      "epoch": 0.3176542455711668,
      "grad_norm": 0.0003205707762390375,
      "learning_rate": 1.987328883357846e-05,
      "loss": 0.0,
      "step": 1040
    },
    {
      "epoch": 0.32376298106291995,
      "grad_norm": 0.00551701569929719,
      "learning_rate": 1.982803484557077e-05,
      "loss": 0.0,
      "step": 1060
    },
    {
      "epoch": 0.3298717165546732,
      "grad_norm": 0.0003404159506317228,
      "learning_rate": 1.9782780857563076e-05,
      "loss": 0.0,
      "step": 1080
    },
    {
      "epoch": 0.3359804520464264,
      "grad_norm": 0.00032207000185735524,
      "learning_rate": 1.973752686955538e-05,
      "loss": 0.0,
      "step": 1100
    },
    {
      "epoch": 0.3420891875381796,
      "grad_norm": 0.0008175582624971867,
      "learning_rate": 1.9692272881547688e-05,
      "loss": 0.0,
      "step": 1120
    },
    {
      "epoch": 0.3481979230299328,
      "grad_norm": 0.00031801010482013226,
      "learning_rate": 1.9647018893539995e-05,
      "loss": 0.0,
      "step": 1140
    },
    {
      "epoch": 0.354306658521686,
      "grad_norm": 0.00041021895594894886,
      "learning_rate": 1.9601764905532303e-05,
      "loss": 0.0,
      "step": 1160
    },
    {
      "epoch": 0.3604153940134392,
      "grad_norm": 0.0006005713366903365,
      "learning_rate": 1.955651091752461e-05,
      "loss": 0.0052,
      "step": 1180
    },
    {
      "epoch": 0.3665241295051924,
      "grad_norm": 0.00041950560989789665,
      "learning_rate": 1.9511256929516914e-05,
      "loss": 0.0,
      "step": 1200
    },
    {
      "epoch": 0.37263286499694565,
      "grad_norm": 0.006403460167348385,
      "learning_rate": 1.9466002941509222e-05,
      "loss": 0.0,
      "step": 1220
    },
    {
      "epoch": 0.3787416004886988,
      "grad_norm": 0.0007222584099508822,
      "learning_rate": 1.942074895350153e-05,
      "loss": 0.0,
      "step": 1240
    },
    {
      "epoch": 0.38485033598045204,
      "grad_norm": 0.0009637826005928218,
      "learning_rate": 1.9375494965493837e-05,
      "loss": 0.0,
      "step": 1260
    },
    {
      "epoch": 0.39095907147220527,
      "grad_norm": 0.0003178020706400275,
      "learning_rate": 1.9330240977486144e-05,
      "loss": 0.0,
      "step": 1280
    },
    {
      "epoch": 0.39706780696395844,
      "grad_norm": 3.7188503483776e-05,
      "learning_rate": 1.928498698947845e-05,
      "loss": 0.0,
      "step": 1300
    },
    {
      "epoch": 0.40317654245571166,
      "grad_norm": 0.0003238545614294708,
      "learning_rate": 1.9239733001470756e-05,
      "loss": 0.0,
      "step": 1320
    },
    {
      "epoch": 0.4092852779474649,
      "grad_norm": 5.091378261568025e-05,
      "learning_rate": 1.9194479013463063e-05,
      "loss": 0.0,
      "step": 1340
    },
    {
      "epoch": 0.41539401343921806,
      "grad_norm": 0.00042147512431256473,
      "learning_rate": 1.9149225025455367e-05,
      "loss": 0.0,
      "step": 1360
    },
    {
      "epoch": 0.4215027489309713,
      "grad_norm": 6.151907291496173e-05,
      "learning_rate": 1.910397103744768e-05,
      "loss": 0.0,
      "step": 1380
    },
    {
      "epoch": 0.4276114844227245,
      "grad_norm": 0.0014860967639833689,
      "learning_rate": 1.9058717049439982e-05,
      "loss": 0.0,
      "step": 1400
    },
    {
      "epoch": 0.4337202199144777,
      "grad_norm": 0.00029171057394705713,
      "learning_rate": 1.901346306143229e-05,
      "loss": 0.0,
      "step": 1420
    },
    {
      "epoch": 0.4398289554062309,
      "grad_norm": 2.3368038455373608e-05,
      "learning_rate": 1.8968209073424597e-05,
      "loss": 0.0,
      "step": 1440
    },
    {
      "epoch": 0.44593769089798413,
      "grad_norm": 0.00016489721019752324,
      "learning_rate": 1.89229550854169e-05,
      "loss": 0.0,
      "step": 1460
    },
    {
      "epoch": 0.4520464263897373,
      "grad_norm": 8.190864900825545e-05,
      "learning_rate": 1.8877701097409212e-05,
      "loss": 0.0,
      "step": 1480
    },
    {
      "epoch": 0.4581551618814905,
      "grad_norm": 0.00023953942582011223,
      "learning_rate": 1.8832447109401516e-05,
      "loss": 0.0,
      "step": 1500
    },
    {
      "epoch": 0.46426389737324375,
      "grad_norm": 6.830177153460681e-05,
      "learning_rate": 1.8787193121393824e-05,
      "loss": 0.0,
      "step": 1520
    },
    {
      "epoch": 0.4703726328649969,
      "grad_norm": 0.0006577755557373166,
      "learning_rate": 1.874193913338613e-05,
      "loss": 0.0,
      "step": 1540
    },
    {
      "epoch": 0.47648136835675015,
      "grad_norm": 3.985461080446839e-05,
      "learning_rate": 1.8696685145378436e-05,
      "loss": 0.0,
      "step": 1560
    },
    {
      "epoch": 0.48259010384850337,
      "grad_norm": 0.0002218626468675211,
      "learning_rate": 1.8651431157370746e-05,
      "loss": 0.0,
      "step": 1580
    },
    {
      "epoch": 0.48869883934025654,
      "grad_norm": 0.0001651157799642533,
      "learning_rate": 1.860617716936305e-05,
      "loss": 0.0,
      "step": 1600
    },
    {
      "epoch": 0.49480757483200977,
      "grad_norm": 0.0006914675468578935,
      "learning_rate": 1.8560923181355358e-05,
      "loss": 0.0,
      "step": 1620
    },
    {
      "epoch": 0.5009163103237629,
      "grad_norm": 1.723111745377537e-05,
      "learning_rate": 1.8515669193347665e-05,
      "loss": 0.0,
      "step": 1640
    },
    {
      "epoch": 0.5070250458155162,
      "grad_norm": 0.0008821169612929225,
      "learning_rate": 1.847041520533997e-05,
      "loss": 0.0,
      "step": 1660
    },
    {
      "epoch": 0.5131337813072694,
      "grad_norm": 6.577936437679455e-05,
      "learning_rate": 1.842516121733228e-05,
      "loss": 0.0,
      "step": 1680
    },
    {
      "epoch": 0.5192425167990226,
      "grad_norm": 0.0009626816608943045,
      "learning_rate": 1.8379907229324585e-05,
      "loss": 0.0,
      "step": 1700
    },
    {
      "epoch": 0.5253512522907758,
      "grad_norm": 2.2510850612889044e-05,
      "learning_rate": 1.8334653241316892e-05,
      "loss": 0.0,
      "step": 1720
    },
    {
      "epoch": 0.531459987782529,
      "grad_norm": 0.0002145500766346231,
      "learning_rate": 1.82893992533092e-05,
      "loss": 0.0,
      "step": 1740
    },
    {
      "epoch": 0.5375687232742822,
      "grad_norm": 0.0003642650553956628,
      "learning_rate": 1.8244145265301507e-05,
      "loss": 0.0,
      "step": 1760
    },
    {
      "epoch": 0.5436774587660355,
      "grad_norm": 4.919306593365036e-05,
      "learning_rate": 1.8198891277293815e-05,
      "loss": 0.0,
      "step": 1780
    },
    {
      "epoch": 0.5497861942577886,
      "grad_norm": 0.0002395156625425443,
      "learning_rate": 1.815363728928612e-05,
      "loss": 0.0,
      "step": 1800
    },
    {
      "epoch": 0.5558949297495418,
      "grad_norm": 2.8957907488802448e-05,
      "learning_rate": 1.8108383301278426e-05,
      "loss": 0.0,
      "step": 1820
    },
    {
      "epoch": 0.5620036652412951,
      "grad_norm": 0.00022055547742638737,
      "learning_rate": 1.8063129313270734e-05,
      "loss": 0.0,
      "step": 1840
    },
    {
      "epoch": 0.5681124007330483,
      "grad_norm": 0.00018589374667499214,
      "learning_rate": 1.801787532526304e-05,
      "loss": 0.0,
      "step": 1860
    },
    {
      "epoch": 0.5742211362248014,
      "grad_norm": 0.00023473000328522176,
      "learning_rate": 1.797262133725535e-05,
      "loss": 0.0,
      "step": 1880
    },
    {
      "epoch": 0.5803298717165547,
      "grad_norm": 2.8126758479629643e-05,
      "learning_rate": 1.7927367349247653e-05,
      "loss": 0.0,
      "step": 1900
    },
    {
      "epoch": 0.5864386072083079,
      "grad_norm": 5.03895862493664e-05,
      "learning_rate": 1.788211336123996e-05,
      "loss": 0.0,
      "step": 1920
    },
    {
      "epoch": 0.592547342700061,
      "grad_norm": 7.964979886310175e-05,
      "learning_rate": 1.7836859373232268e-05,
      "loss": 0.0,
      "step": 1940
    },
    {
      "epoch": 0.5986560781918143,
      "grad_norm": 8.680385508341715e-05,
      "learning_rate": 1.7791605385224575e-05,
      "loss": 0.0,
      "step": 1960
    },
    {
      "epoch": 0.6047648136835675,
      "grad_norm": 0.012063160538673401,
      "learning_rate": 1.7746351397216883e-05,
      "loss": 0.0,
      "step": 1980
    },
    {
      "epoch": 0.6108735491753207,
      "grad_norm": 2.5256067601731047e-05,
      "learning_rate": 1.7701097409209187e-05,
      "loss": 0.0,
      "step": 2000
    },
    {
      "epoch": 0.6169822846670739,
      "grad_norm": 1.4461365026363637e-05,
      "learning_rate": 1.7655843421201494e-05,
      "loss": 0.0,
      "step": 2020
    },
    {
      "epoch": 0.6230910201588271,
      "grad_norm": 0.0003046123601961881,
      "learning_rate": 1.76105894331938e-05,
      "loss": 0.0,
      "step": 2040
    },
    {
      "epoch": 0.6291997556505803,
      "grad_norm": 4.016573075205088e-05,
      "learning_rate": 1.756533544518611e-05,
      "loss": 0.0,
      "step": 2060
    },
    {
      "epoch": 0.6353084911423336,
      "grad_norm": 2.9901688321842812e-05,
      "learning_rate": 1.7520081457178417e-05,
      "loss": 0.0,
      "step": 2080
    },
    {
      "epoch": 0.6414172266340867,
      "grad_norm": 0.00047802471090108156,
      "learning_rate": 1.7474827469170724e-05,
      "loss": 0.0012,
      "step": 2100
    },
    {
      "epoch": 0.6475259621258399,
      "grad_norm": 6.06982757744845e-05,
      "learning_rate": 1.7429573481163028e-05,
      "loss": 0.0,
      "step": 2120
    },
    {
      "epoch": 0.6536346976175932,
      "grad_norm": 1.9158838767907582e-05,
      "learning_rate": 1.7384319493155336e-05,
      "loss": 0.0,
      "step": 2140
    },
    {
      "epoch": 0.6597434331093464,
      "grad_norm": 6.452037723647663e-06,
      "learning_rate": 1.7339065505147643e-05,
      "loss": 0.0,
      "step": 2160
    },
    {
      "epoch": 0.6658521686010995,
      "grad_norm": 7.17880466254428e-05,
      "learning_rate": 1.729381151713995e-05,
      "loss": 0.0,
      "step": 2180
    },
    {
      "epoch": 0.6719609040928528,
      "grad_norm": 0.0032405073288828135,
      "learning_rate": 1.7248557529132258e-05,
      "loss": 0.0,
      "step": 2200
    },
    {
      "epoch": 0.678069639584606,
      "grad_norm": 5.5683343816781417e-05,
      "learning_rate": 1.7203303541124562e-05,
      "loss": 0.0,
      "step": 2220
    },
    {
      "epoch": 0.6841783750763591,
      "grad_norm": 3.769348040805198e-05,
      "learning_rate": 1.715804955311687e-05,
      "loss": 0.0,
      "step": 2240
    },
    {
      "epoch": 0.6902871105681124,
      "grad_norm": 5.3633768402505666e-05,
      "learning_rate": 1.7112795565109177e-05,
      "loss": 0.0,
      "step": 2260
    },
    {
      "epoch": 0.6963958460598656,
      "grad_norm": 0.003320802003145218,
      "learning_rate": 1.706754157710148e-05,
      "loss": 0.0,
      "step": 2280
    },
    {
      "epoch": 0.7025045815516188,
      "grad_norm": 9.956937719834968e-05,
      "learning_rate": 1.7022287589093792e-05,
      "loss": 0.0,
      "step": 2300
    },
    {
      "epoch": 0.708613317043372,
      "grad_norm": 0.00021457357797771692,
      "learning_rate": 1.6977033601086096e-05,
      "loss": 0.0,
      "step": 2320
    },
    {
      "epoch": 0.7147220525351252,
      "grad_norm": 2.2512729628942907e-05,
      "learning_rate": 1.6931779613078404e-05,
      "loss": 0.0,
      "step": 2340
    },
    {
      "epoch": 0.7208307880268784,
      "grad_norm": 1.588170744071249e-05,
      "learning_rate": 1.688652562507071e-05,
      "loss": 0.0,
      "step": 2360
    },
    {
      "epoch": 0.7269395235186317,
      "grad_norm": 0.0002954806259367615,
      "learning_rate": 1.6841271637063015e-05,
      "loss": 0.0,
      "step": 2380
    },
    {
      "epoch": 0.7330482590103848,
      "grad_norm": 0.001866354956291616,
      "learning_rate": 1.6796017649055326e-05,
      "loss": 0.0,
      "step": 2400
    },
    {
      "epoch": 0.739156994502138,
      "grad_norm": 0.00017774761363398284,
      "learning_rate": 1.675076366104763e-05,
      "loss": 0.0,
      "step": 2420
    },
    {
      "epoch": 0.7452657299938913,
      "grad_norm": 1.3824997949996032e-05,
      "learning_rate": 1.6705509673039938e-05,
      "loss": 0.0,
      "step": 2440
    },
    {
      "epoch": 0.7513744654856445,
      "grad_norm": 1.403527130605653e-05,
      "learning_rate": 1.6660255685032245e-05,
      "loss": 0.0,
      "step": 2460
    },
    {
      "epoch": 0.7574832009773976,
      "grad_norm": 7.78220419306308e-05,
      "learning_rate": 1.661500169702455e-05,
      "loss": 0.0,
      "step": 2480
    },
    {
      "epoch": 0.7635919364691509,
      "grad_norm": 0.0004524637770373374,
      "learning_rate": 1.656974770901686e-05,
      "loss": 0.0,
      "step": 2500
    },
    {
      "epoch": 0.7697006719609041,
      "grad_norm": 3.276535790064372e-05,
      "learning_rate": 1.6524493721009164e-05,
      "loss": 0.0,
      "step": 2520
    },
    {
      "epoch": 0.7758094074526573,
      "grad_norm": 0.0006202255608513951,
      "learning_rate": 1.6479239733001472e-05,
      "loss": 0.0,
      "step": 2540
    },
    {
      "epoch": 0.7819181429444105,
      "grad_norm": 2.3161508579505607e-05,
      "learning_rate": 1.643398574499378e-05,
      "loss": 0.0,
      "step": 2560
    },
    {
      "epoch": 0.7880268784361637,
      "grad_norm": 8.531838830094784e-06,
      "learning_rate": 1.6388731756986083e-05,
      "loss": 0.0,
      "step": 2580
    },
    {
      "epoch": 0.7941356139279169,
      "grad_norm": 2.592803502921015e-05,
      "learning_rate": 1.6343477768978394e-05,
      "loss": 0.0,
      "step": 2600
    },
    {
      "epoch": 0.8002443494196702,
      "grad_norm": 4.683095176005736e-05,
      "learning_rate": 1.62982237809707e-05,
      "loss": 0.0,
      "step": 2620
    },
    {
      "epoch": 0.8063530849114233,
      "grad_norm": 3.9714359445497394e-05,
      "learning_rate": 1.6252969792963006e-05,
      "loss": 0.0,
      "step": 2640
    },
    {
      "epoch": 0.8124618204031765,
      "grad_norm": 4.0372367948293686e-05,
      "learning_rate": 1.6207715804955313e-05,
      "loss": 0.0,
      "step": 2660
    },
    {
      "epoch": 0.8185705558949298,
      "grad_norm": 0.000146931255585514,
      "learning_rate": 1.6162461816947618e-05,
      "loss": 0.0,
      "step": 2680
    },
    {
      "epoch": 0.8246792913866829,
      "grad_norm": 3.735457357834093e-05,
      "learning_rate": 1.611720782893993e-05,
      "loss": 0.0,
      "step": 2700
    },
    {
      "epoch": 0.8307880268784361,
      "grad_norm": 0.0001235521922353655,
      "learning_rate": 1.6071953840932232e-05,
      "loss": 0.0,
      "step": 2720
    },
    {
      "epoch": 0.8368967623701894,
      "grad_norm": 5.373641670303186e-06,
      "learning_rate": 1.602669985292454e-05,
      "loss": 0.0,
      "step": 2740
    },
    {
      "epoch": 0.8430054978619426,
      "grad_norm": 2.2614691260969266e-05,
      "learning_rate": 1.5981445864916847e-05,
      "loss": 0.0,
      "step": 2760
    },
    {
      "epoch": 0.8491142333536957,
      "grad_norm": 8.23852406028891e-06,
      "learning_rate": 1.593619187690915e-05,
      "loss": 0.0,
      "step": 2780
    },
    {
      "epoch": 0.855222968845449,
      "grad_norm": 2.084010156977456e-05,
      "learning_rate": 1.5890937888901462e-05,
      "loss": 0.0,
      "step": 2800
    },
    {
      "epoch": 0.8613317043372022,
      "grad_norm": 0.00022606820857618004,
      "learning_rate": 1.5845683900893767e-05,
      "loss": 0.0,
      "step": 2820
    },
    {
      "epoch": 0.8674404398289554,
      "grad_norm": 6.42108716419898e-05,
      "learning_rate": 1.5800429912886074e-05,
      "loss": 0.0,
      "step": 2840
    },
    {
      "epoch": 0.8735491753207086,
      "grad_norm": 0.00010934592137346044,
      "learning_rate": 1.575517592487838e-05,
      "loss": 0.0,
      "step": 2860
    },
    {
      "epoch": 0.8796579108124618,
      "grad_norm": 5.4220166930463165e-05,
      "learning_rate": 1.570992193687069e-05,
      "loss": 0.0,
      "step": 2880
    },
    {
      "epoch": 0.885766646304215,
      "grad_norm": 0.00011957731476286426,
      "learning_rate": 1.5664667948862996e-05,
      "loss": 0.0,
      "step": 2900
    },
    {
      "epoch": 0.8918753817959683,
      "grad_norm": 4.480610368773341e-05,
      "learning_rate": 1.56194139608553e-05,
      "loss": 0.0,
      "step": 2920
    },
    {
      "epoch": 0.8979841172877214,
      "grad_norm": 4.549277491605608e-06,
      "learning_rate": 1.5574159972847608e-05,
      "loss": 0.0,
      "step": 2940
    },
    {
      "epoch": 0.9040928527794746,
      "grad_norm": 0.0005228703957982361,
      "learning_rate": 1.5528905984839916e-05,
      "loss": 0.0,
      "step": 2960
    },
    {
      "epoch": 0.9102015882712279,
      "grad_norm": 2.7460104320198298e-05,
      "learning_rate": 1.5483651996832223e-05,
      "loss": 0.0,
      "step": 2980
    },
    {
      "epoch": 0.916310323762981,
      "grad_norm": 9.633360605221242e-06,
      "learning_rate": 1.543839800882453e-05,
      "loss": 0.0,
      "step": 3000
    },
    {
      "epoch": 0.9224190592547342,
      "grad_norm": 5.38237982254941e-05,
      "learning_rate": 1.5393144020816835e-05,
      "loss": 0.0,
      "step": 3020
    },
    {
      "epoch": 0.9285277947464875,
      "grad_norm": 3.3436510420870036e-05,
      "learning_rate": 1.5347890032809142e-05,
      "loss": 0.0,
      "step": 3040
    },
    {
      "epoch": 0.9346365302382407,
      "grad_norm": 3.667506462079473e-05,
      "learning_rate": 1.530263604480145e-05,
      "loss": 0.0,
      "step": 3060
    },
    {
      "epoch": 0.9407452657299938,
      "grad_norm": 0.000111857705633156,
      "learning_rate": 1.5257382056793757e-05,
      "loss": 0.0,
      "step": 3080
    },
    {
      "epoch": 0.9468540012217471,
      "grad_norm": 6.155701157695148e-06,
      "learning_rate": 1.5212128068786063e-05,
      "loss": 0.0,
      "step": 3100
    },
    {
      "epoch": 0.9529627367135003,
      "grad_norm": 0.0005919108516536653,
      "learning_rate": 1.5166874080778369e-05,
      "loss": 0.0,
      "step": 3120
    },
    {
      "epoch": 0.9590714722052535,
      "grad_norm": 2.2690450350637548e-05,
      "learning_rate": 1.5121620092770676e-05,
      "loss": 0.0,
      "step": 3140
    },
    {
      "epoch": 0.9651802076970067,
      "grad_norm": 6.0387043049559e-05,
      "learning_rate": 1.5076366104762984e-05,
      "loss": 0.0,
      "step": 3160
    },
    {
      "epoch": 0.9712889431887599,
      "grad_norm": 9.73990245256573e-05,
      "learning_rate": 1.5031112116755291e-05,
      "loss": 0.0,
      "step": 3180
    },
    {
      "epoch": 0.9773976786805131,
      "grad_norm": 8.816643094178289e-05,
      "learning_rate": 1.4985858128747597e-05,
      "loss": 0.0,
      "step": 3200
    },
    {
      "epoch": 0.9835064141722664,
      "grad_norm": 1.3019060133956373e-05,
      "learning_rate": 1.4940604140739904e-05,
      "loss": 0.0,
      "step": 3220
    },
    {
      "epoch": 0.9896151496640195,
      "grad_norm": 1.3225118891568854e-05,
      "learning_rate": 1.489535015273221e-05,
      "loss": 0.0,
      "step": 3240
    },
    {
      "epoch": 0.9957238851557727,
      "grad_norm": 2.3799893824616447e-05,
      "learning_rate": 1.4850096164724516e-05,
      "loss": 0.0,
      "step": 3260
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 1.0,
      "eval_loss": 1.1455601907073287e-06,
      "eval_runtime": 221.1464,
      "eval_samples_per_second": 59.219,
      "eval_steps_per_second": 7.402,
      "step": 3274
    },
    {
      "epoch": 1.0018326206475259,
      "grad_norm": 9.585735824657604e-06,
      "learning_rate": 1.4804842176716825e-05,
      "loss": 0.0,
      "step": 3280
    },
    {
      "epoch": 1.0079413561392792,
      "grad_norm": 2.0759580365847796e-05,
      "learning_rate": 1.4759588188709131e-05,
      "loss": 0.0,
      "step": 3300
    },
    {
      "epoch": 1.0140500916310324,
      "grad_norm": 1.2483549653552473e-05,
      "learning_rate": 1.4714334200701438e-05,
      "loss": 0.0,
      "step": 3320
    },
    {
      "epoch": 1.0201588271227855,
      "grad_norm": 2.524546107451897e-05,
      "learning_rate": 1.4669080212693744e-05,
      "loss": 0.0,
      "step": 3340
    },
    {
      "epoch": 1.0262675626145388,
      "grad_norm": 3.507562723825686e-05,
      "learning_rate": 1.462382622468605e-05,
      "loss": 0.0,
      "step": 3360
    },
    {
      "epoch": 1.032376298106292,
      "grad_norm": 9.142755516222678e-06,
      "learning_rate": 1.457857223667836e-05,
      "loss": 0.0,
      "step": 3380
    },
    {
      "epoch": 1.0384850335980451,
      "grad_norm": 3.743052002391778e-05,
      "learning_rate": 1.4533318248670665e-05,
      "loss": 0.0,
      "step": 3400
    },
    {
      "epoch": 1.0445937690897984,
      "grad_norm": 4.3336203816579655e-06,
      "learning_rate": 1.4488064260662972e-05,
      "loss": 0.0,
      "step": 3420
    },
    {
      "epoch": 1.0507025045815517,
      "grad_norm": 6.15221870248206e-06,
      "learning_rate": 1.4442810272655278e-05,
      "loss": 0.0,
      "step": 3440
    },
    {
      "epoch": 1.0568112400733047,
      "grad_norm": 5.7009360716619994e-06,
      "learning_rate": 1.4397556284647584e-05,
      "loss": 0.0,
      "step": 3460
    },
    {
      "epoch": 1.062919975565058,
      "grad_norm": 1.6867970771272667e-05,
      "learning_rate": 1.4352302296639893e-05,
      "loss": 0.0,
      "step": 3480
    },
    {
      "epoch": 1.0690287110568113,
      "grad_norm": 1.8089530158249545e-06,
      "learning_rate": 1.4307048308632199e-05,
      "loss": 0.0,
      "step": 3500
    },
    {
      "epoch": 1.0751374465485644,
      "grad_norm": 1.5498188076890074e-05,
      "learning_rate": 1.4261794320624507e-05,
      "loss": 0.0,
      "step": 3520
    },
    {
      "epoch": 1.0812461820403176,
      "grad_norm": 6.217458576429635e-06,
      "learning_rate": 1.4216540332616812e-05,
      "loss": 0.0,
      "step": 3540
    },
    {
      "epoch": 1.087354917532071,
      "grad_norm": 6.060519353923155e-06,
      "learning_rate": 1.4171286344609121e-05,
      "loss": 0.0,
      "step": 3560
    },
    {
      "epoch": 1.093463653023824,
      "grad_norm": 3.348187965457328e-05,
      "learning_rate": 1.4126032356601427e-05,
      "loss": 0.0,
      "step": 3580
    },
    {
      "epoch": 1.0995723885155773,
      "grad_norm": 9.939114534063265e-06,
      "learning_rate": 1.4080778368593733e-05,
      "loss": 0.0,
      "step": 3600
    },
    {
      "epoch": 1.1056811240073305,
      "grad_norm": 1.1102654752903618e-05,
      "learning_rate": 1.403552438058604e-05,
      "loss": 0.0,
      "step": 3620
    },
    {
      "epoch": 1.1117898594990836,
      "grad_norm": 5.994378170726122e-06,
      "learning_rate": 1.3990270392578346e-05,
      "loss": 0.0,
      "step": 3640
    },
    {
      "epoch": 1.1178985949908369,
      "grad_norm": 1.0161525096918922e-05,
      "learning_rate": 1.3945016404570656e-05,
      "loss": 0.0,
      "step": 3660
    },
    {
      "epoch": 1.1240073304825902,
      "grad_norm": 2.6172529032919556e-05,
      "learning_rate": 1.3899762416562961e-05,
      "loss": 0.0,
      "step": 3680
    },
    {
      "epoch": 1.1301160659743432,
      "grad_norm": 5.1264589274069294e-05,
      "learning_rate": 1.3854508428555267e-05,
      "loss": 0.0,
      "step": 3700
    },
    {
      "epoch": 1.1362248014660965,
      "grad_norm": 0.0011414497857913375,
      "learning_rate": 1.3809254440547575e-05,
      "loss": 0.0,
      "step": 3720
    },
    {
      "epoch": 1.1423335369578498,
      "grad_norm": 8.836397682898678e-06,
      "learning_rate": 1.376400045253988e-05,
      "loss": 0.0,
      "step": 3740
    },
    {
      "epoch": 1.1484422724496028,
      "grad_norm": 5.2913477702531964e-05,
      "learning_rate": 1.371874646453219e-05,
      "loss": 0.0,
      "step": 3760
    },
    {
      "epoch": 1.1545510079413561,
      "grad_norm": 1.0061251487059053e-05,
      "learning_rate": 1.3673492476524495e-05,
      "loss": 0.0,
      "step": 3780
    },
    {
      "epoch": 1.1606597434331094,
      "grad_norm": 1.1465654097264633e-05,
      "learning_rate": 1.3628238488516801e-05,
      "loss": 0.0,
      "step": 3800
    },
    {
      "epoch": 1.1667684789248625,
      "grad_norm": 2.535928251745645e-05,
      "learning_rate": 1.3582984500509109e-05,
      "loss": 0.0,
      "step": 3820
    },
    {
      "epoch": 1.1728772144166157,
      "grad_norm": 5.514732038136572e-06,
      "learning_rate": 1.3537730512501414e-05,
      "loss": 0.0,
      "step": 3840
    },
    {
      "epoch": 1.178985949908369,
      "grad_norm": 5.343824886949733e-05,
      "learning_rate": 1.3492476524493724e-05,
      "loss": 0.0,
      "step": 3860
    },
    {
      "epoch": 1.185094685400122,
      "grad_norm": 0.0006312133045867085,
      "learning_rate": 1.344722253648603e-05,
      "loss": 0.0,
      "step": 3880
    },
    {
      "epoch": 1.1912034208918754,
      "grad_norm": 3.2717318390496075e-05,
      "learning_rate": 1.3401968548478337e-05,
      "loss": 0.0,
      "step": 3900
    },
    {
      "epoch": 1.1973121563836286,
      "grad_norm": 3.416007984924363e-06,
      "learning_rate": 1.3356714560470643e-05,
      "loss": 0.0,
      "step": 3920
    },
    {
      "epoch": 1.2034208918753817,
      "grad_norm": 0.0007086900877766311,
      "learning_rate": 1.3311460572462948e-05,
      "loss": 0.0,
      "step": 3940
    },
    {
      "epoch": 1.209529627367135,
      "grad_norm": 4.4334967242321e-05,
      "learning_rate": 1.3266206584455256e-05,
      "loss": 0.0,
      "step": 3960
    },
    {
      "epoch": 1.2156383628588883,
      "grad_norm": 1.6747702829889022e-05,
      "learning_rate": 1.3220952596447563e-05,
      "loss": 0.0,
      "step": 3980
    },
    {
      "epoch": 1.2217470983506413,
      "grad_norm": 0.00032168804318644106,
      "learning_rate": 1.3175698608439871e-05,
      "loss": 0.0,
      "step": 4000
    },
    {
      "epoch": 1.2278558338423946,
      "grad_norm": 6.837509772594785e-06,
      "learning_rate": 1.3130444620432177e-05,
      "loss": 0.0,
      "step": 4020
    },
    {
      "epoch": 1.2339645693341479,
      "grad_norm": 2.6908126528724097e-05,
      "learning_rate": 1.3085190632424483e-05,
      "loss": 0.0,
      "step": 4040
    },
    {
      "epoch": 1.240073304825901,
      "grad_norm": 5.9339213294151705e-06,
      "learning_rate": 1.303993664441679e-05,
      "loss": 0.0,
      "step": 4060
    },
    {
      "epoch": 1.2461820403176542,
      "grad_norm": 5.5857970437500626e-05,
      "learning_rate": 1.2994682656409097e-05,
      "loss": 0.0,
      "step": 4080
    },
    {
      "epoch": 1.2522907758094075,
      "grad_norm": 1.8494108644517837e-06,
      "learning_rate": 1.2949428668401405e-05,
      "loss": 0.0,
      "step": 4100
    },
    {
      "epoch": 1.2583995113011608,
      "grad_norm": 0.00024893504451029,
      "learning_rate": 1.290417468039371e-05,
      "loss": 0.0,
      "step": 4120
    },
    {
      "epoch": 1.2645082467929138,
      "grad_norm": 1.7021218809532e-05,
      "learning_rate": 1.2858920692386017e-05,
      "loss": 0.0,
      "step": 4140
    },
    {
      "epoch": 1.2706169822846671,
      "grad_norm": 2.364371084695449e-06,
      "learning_rate": 1.2813666704378324e-05,
      "loss": 0.0,
      "step": 4160
    },
    {
      "epoch": 1.2767257177764204,
      "grad_norm": 3.921712777810171e-05,
      "learning_rate": 1.276841271637063e-05,
      "loss": 0.0,
      "step": 4180
    },
    {
      "epoch": 1.2828344532681735,
      "grad_norm": 3.995329825556837e-05,
      "learning_rate": 1.2723158728362939e-05,
      "loss": 0.0,
      "step": 4200
    },
    {
      "epoch": 1.2889431887599268,
      "grad_norm": 1.2285620869079139e-05,
      "learning_rate": 1.2677904740355245e-05,
      "loss": 0.0,
      "step": 4220
    },
    {
      "epoch": 1.29505192425168,
      "grad_norm": 3.501337778288871e-05,
      "learning_rate": 1.263265075234755e-05,
      "loss": 0.0,
      "step": 4240
    },
    {
      "epoch": 1.301160659743433,
      "grad_norm": 4.286470357328653e-06,
      "learning_rate": 1.2587396764339858e-05,
      "loss": 0.0,
      "step": 4260
    },
    {
      "epoch": 1.3072693952351864,
      "grad_norm": 5.281724043015856e-06,
      "learning_rate": 1.2542142776332164e-05,
      "loss": 0.0,
      "step": 4280
    },
    {
      "epoch": 1.3133781307269397,
      "grad_norm": 0.00011825050023617223,
      "learning_rate": 1.2496888788324473e-05,
      "loss": 0.0,
      "step": 4300
    },
    {
      "epoch": 1.3194868662186927,
      "grad_norm": 4.46762078354368e-06,
      "learning_rate": 1.2451634800316779e-05,
      "loss": 0.0,
      "step": 4320
    },
    {
      "epoch": 1.325595601710446,
      "grad_norm": 4.463794903131202e-05,
      "learning_rate": 1.2406380812309086e-05,
      "loss": 0.0,
      "step": 4340
    },
    {
      "epoch": 1.3317043372021993,
      "grad_norm": 5.290048648021184e-06,
      "learning_rate": 1.2361126824301392e-05,
      "loss": 0.0,
      "step": 4360
    },
    {
      "epoch": 1.3378130726939523,
      "grad_norm": 4.827423254027963e-06,
      "learning_rate": 1.2315872836293698e-05,
      "loss": 0.0,
      "step": 4380
    },
    {
      "epoch": 1.3439218081857056,
      "grad_norm": 0.00012230627180542797,
      "learning_rate": 1.2270618848286007e-05,
      "loss": 0.0,
      "step": 4400
    },
    {
      "epoch": 1.350030543677459,
      "grad_norm": 2.43909630626149e-06,
      "learning_rate": 1.2225364860278313e-05,
      "loss": 0.0,
      "step": 4420
    },
    {
      "epoch": 1.356139279169212,
      "grad_norm": 9.956642315955833e-06,
      "learning_rate": 1.218011087227062e-05,
      "loss": 0.0,
      "step": 4440
    },
    {
      "epoch": 1.3622480146609652,
      "grad_norm": 3.214599246348371e-06,
      "learning_rate": 1.2134856884262926e-05,
      "loss": 0.0,
      "step": 4460
    },
    {
      "epoch": 1.3683567501527185,
      "grad_norm": 5.134502316650469e-06,
      "learning_rate": 1.2089602896255232e-05,
      "loss": 0.0,
      "step": 4480
    },
    {
      "epoch": 1.3744654856444716,
      "grad_norm": 7.63294956414029e-05,
      "learning_rate": 1.2044348908247541e-05,
      "loss": 0.0,
      "step": 4500
    },
    {
      "epoch": 1.3805742211362249,
      "grad_norm": 0.00013421563198789954,
      "learning_rate": 1.1999094920239847e-05,
      "loss": 0.0,
      "step": 4520
    },
    {
      "epoch": 1.3866829566279781,
      "grad_norm": 1.922002775245346e-05,
      "learning_rate": 1.1953840932232154e-05,
      "loss": 0.0,
      "step": 4540
    },
    {
      "epoch": 1.3927916921197312,
      "grad_norm": 1.461135980207473e-06,
      "learning_rate": 1.190858694422446e-05,
      "loss": 0.0,
      "step": 4560
    },
    {
      "epoch": 1.3989004276114845,
      "grad_norm": 4.571218141791178e-06,
      "learning_rate": 1.1863332956216766e-05,
      "loss": 0.0,
      "step": 4580
    },
    {
      "epoch": 1.4050091631032378,
      "grad_norm": 2.148834209947381e-05,
      "learning_rate": 1.1818078968209075e-05,
      "loss": 0.0,
      "step": 4600
    },
    {
      "epoch": 1.4111178985949908,
      "grad_norm": 3.1798143027117476e-05,
      "learning_rate": 1.1772824980201381e-05,
      "loss": 0.0,
      "step": 4620
    },
    {
      "epoch": 1.417226634086744,
      "grad_norm": 3.941022441722453e-06,
      "learning_rate": 1.1727570992193688e-05,
      "loss": 0.0,
      "step": 4640
    },
    {
      "epoch": 1.4233353695784974,
      "grad_norm": 2.529627636249643e-06,
      "learning_rate": 1.1682317004185994e-05,
      "loss": 0.0,
      "step": 4660
    },
    {
      "epoch": 1.4294441050702504,
      "grad_norm": 2.1758867660537362e-05,
      "learning_rate": 1.1637063016178303e-05,
      "loss": 0.0,
      "step": 4680
    },
    {
      "epoch": 1.4355528405620037,
      "grad_norm": 2.5544808522681706e-05,
      "learning_rate": 1.159180902817061e-05,
      "loss": 0.0,
      "step": 4700
    },
    {
      "epoch": 1.441661576053757,
      "grad_norm": 5.4638156143482774e-05,
      "learning_rate": 1.1546555040162915e-05,
      "loss": 0.0,
      "step": 4720
    },
    {
      "epoch": 1.44777031154551,
      "grad_norm": 5.945960583630949e-05,
      "learning_rate": 1.1501301052155222e-05,
      "loss": 0.0,
      "step": 4740
    },
    {
      "epoch": 1.4538790470372633,
      "grad_norm": 3.3644205359451007e-06,
      "learning_rate": 1.1456047064147528e-05,
      "loss": 0.0,
      "step": 4760
    },
    {
      "epoch": 1.4599877825290166,
      "grad_norm": 9.934343688655645e-05,
      "learning_rate": 1.1410793076139837e-05,
      "loss": 0.0,
      "step": 4780
    },
    {
      "epoch": 1.4660965180207697,
      "grad_norm": 8.470210559607949e-06,
      "learning_rate": 1.1365539088132143e-05,
      "loss": 0.0,
      "step": 4800
    },
    {
      "epoch": 1.472205253512523,
      "grad_norm": 1.0224685865978245e-05,
      "learning_rate": 1.1320285100124449e-05,
      "loss": 0.0,
      "step": 4820
    },
    {
      "epoch": 1.4783139890042762,
      "grad_norm": 0.00020163519366178662,
      "learning_rate": 1.1275031112116757e-05,
      "loss": 0.0,
      "step": 4840
    },
    {
      "epoch": 1.4844227244960293,
      "grad_norm": 5.888766736461548e-06,
      "learning_rate": 1.1229777124109062e-05,
      "loss": 0.0,
      "step": 4860
    },
    {
      "epoch": 1.4905314599877826,
      "grad_norm": 8.780153621046338e-06,
      "learning_rate": 1.118452313610137e-05,
      "loss": 0.0,
      "step": 4880
    },
    {
      "epoch": 1.4966401954795359,
      "grad_norm": 8.62317483552033e-06,
      "learning_rate": 1.1139269148093677e-05,
      "loss": 0.0,
      "step": 4900
    },
    {
      "epoch": 1.502748930971289,
      "grad_norm": 6.118877990957117e-06,
      "learning_rate": 1.1094015160085983e-05,
      "loss": 0.0,
      "step": 4920
    },
    {
      "epoch": 1.5088576664630422,
      "grad_norm": 0.0003139071341138333,
      "learning_rate": 1.104876117207829e-05,
      "loss": 0.0,
      "step": 4940
    },
    {
      "epoch": 1.5149664019547955,
      "grad_norm": 3.787264176935423e-06,
      "learning_rate": 1.1003507184070596e-05,
      "loss": 0.0,
      "step": 4960
    },
    {
      "epoch": 1.5210751374465485,
      "grad_norm": 4.861378783971304e-06,
      "learning_rate": 1.0958253196062904e-05,
      "loss": 0.0,
      "step": 4980
    },
    {
      "epoch": 1.5271838729383018,
      "grad_norm": 1.3166311873646919e-05,
      "learning_rate": 1.0912999208055211e-05,
      "loss": 0.0,
      "step": 5000
    },
    {
      "epoch": 1.533292608430055,
      "grad_norm": 0.018076367676258087,
      "learning_rate": 1.0867745220047519e-05,
      "loss": 0.0,
      "step": 5020
    },
    {
      "epoch": 1.5394013439218082,
      "grad_norm": 8.231510037148837e-06,
      "learning_rate": 1.0822491232039825e-05,
      "loss": 0.0,
      "step": 5040
    },
    {
      "epoch": 1.5455100794135614,
      "grad_norm": 1.3495799748852733e-06,
      "learning_rate": 1.077723724403213e-05,
      "loss": 0.0,
      "step": 5060
    },
    {
      "epoch": 1.5516188149053147,
      "grad_norm": 2.4841231152095133e-06,
      "learning_rate": 1.0731983256024438e-05,
      "loss": 0.0,
      "step": 5080
    },
    {
      "epoch": 1.5577275503970678,
      "grad_norm": 0.00016012726700864732,
      "learning_rate": 1.0686729268016744e-05,
      "loss": 0.0,
      "step": 5100
    },
    {
      "epoch": 1.563836285888821,
      "grad_norm": 2.761365976766683e-06,
      "learning_rate": 1.0641475280009053e-05,
      "loss": 0.0,
      "step": 5120
    },
    {
      "epoch": 1.5699450213805743,
      "grad_norm": 4.408156200952362e-06,
      "learning_rate": 1.0596221292001359e-05,
      "loss": 0.0,
      "step": 5140
    },
    {
      "epoch": 1.5760537568723274,
      "grad_norm": 3.1026770557218697e-06,
      "learning_rate": 1.0550967303993664e-05,
      "loss": 0.0,
      "step": 5160
    },
    {
      "epoch": 1.5821624923640807,
      "grad_norm": 7.884461410867516e-06,
      "learning_rate": 1.0505713315985972e-05,
      "loss": 0.0,
      "step": 5180
    },
    {
      "epoch": 1.588271227855834,
      "grad_norm": 1.9287001123302616e-05,
      "learning_rate": 1.0460459327978278e-05,
      "loss": 0.0,
      "step": 5200
    },
    {
      "epoch": 1.594379963347587,
      "grad_norm": 1.5644947097825934e-06,
      "learning_rate": 1.0415205339970587e-05,
      "loss": 0.0,
      "step": 5220
    },
    {
      "epoch": 1.6004886988393403,
      "grad_norm": 5.021319338993635e-06,
      "learning_rate": 1.0369951351962893e-05,
      "loss": 0.0,
      "step": 5240
    },
    {
      "epoch": 1.6065974343310936,
      "grad_norm": 1.9785529730143026e-06,
      "learning_rate": 1.0324697363955199e-05,
      "loss": 0.0,
      "step": 5260
    },
    {
      "epoch": 1.6127061698228466,
      "grad_norm": 1.731540760374628e-05,
      "learning_rate": 1.0279443375947506e-05,
      "loss": 0.0,
      "step": 5280
    },
    {
      "epoch": 1.6188149053146,
      "grad_norm": 2.815171455949894e-06,
      "learning_rate": 1.0234189387939812e-05,
      "loss": 0.0,
      "step": 5300
    },
    {
      "epoch": 1.6249236408063532,
      "grad_norm": 6.648539056186564e-06,
      "learning_rate": 1.0188935399932121e-05,
      "loss": 0.0,
      "step": 5320
    },
    {
      "epoch": 1.6310323762981063,
      "grad_norm": 1.593894694451592e-06,
      "learning_rate": 1.0143681411924427e-05,
      "loss": 0.0,
      "step": 5340
    },
    {
      "epoch": 1.6371411117898595,
      "grad_norm": 2.9147015538910637e-06,
      "learning_rate": 1.0098427423916734e-05,
      "loss": 0.0,
      "step": 5360
    },
    {
      "epoch": 1.6432498472816128,
      "grad_norm": 1.0315691724827047e-05,
      "learning_rate": 1.005317343590904e-05,
      "loss": 0.0,
      "step": 5380
    },
    {
      "epoch": 1.6493585827733659,
      "grad_norm": 2.0157094695605338e-05,
      "learning_rate": 1.0007919447901346e-05,
      "loss": 0.0,
      "step": 5400
    },
    {
      "epoch": 1.6554673182651192,
      "grad_norm": 2.7964481432718458e-06,
      "learning_rate": 9.962665459893653e-06,
      "loss": 0.0,
      "step": 5420
    },
    {
      "epoch": 1.6615760537568725,
      "grad_norm": 5.26541271028691e-06,
      "learning_rate": 9.91741147188596e-06,
      "loss": 0.0,
      "step": 5440
    },
    {
      "epoch": 1.6676847892486255,
      "grad_norm": 2.5117367840721272e-05,
      "learning_rate": 9.872157483878268e-06,
      "loss": 0.0,
      "step": 5460
    },
    {
      "epoch": 1.6737935247403788,
      "grad_norm": 3.228873902116902e-05,
      "learning_rate": 9.826903495870574e-06,
      "loss": 0.0,
      "step": 5480
    },
    {
      "epoch": 1.679902260232132,
      "grad_norm": 9.021793812280521e-05,
      "learning_rate": 9.781649507862882e-06,
      "loss": 0.0,
      "step": 5500
    },
    {
      "epoch": 1.6860109957238851,
      "grad_norm": 2.3988750399439596e-06,
      "learning_rate": 9.736395519855189e-06,
      "loss": 0.0,
      "step": 5520
    },
    {
      "epoch": 1.6921197312156384,
      "grad_norm": 1.263867670786567e-05,
      "learning_rate": 9.691141531847495e-06,
      "loss": 0.0,
      "step": 5540
    },
    {
      "epoch": 1.6982284667073917,
      "grad_norm": 3.8059406506363302e-06,
      "learning_rate": 9.6458875438398e-06,
      "loss": 0.0,
      "step": 5560
    },
    {
      "epoch": 1.7043372021991448,
      "grad_norm": 1.2080407941539306e-05,
      "learning_rate": 9.600633555832108e-06,
      "loss": 0.0,
      "step": 5580
    },
    {
      "epoch": 1.710445937690898,
      "grad_norm": 2.4030646272876766e-06,
      "learning_rate": 9.555379567824416e-06,
      "loss": 0.0,
      "step": 5600
    },
    {
      "epoch": 1.7165546731826513,
      "grad_norm": 1.0229862709820736e-05,
      "learning_rate": 9.510125579816723e-06,
      "loss": 0.0,
      "step": 5620
    },
    {
      "epoch": 1.7226634086744044,
      "grad_norm": 2.197335788878263e-06,
      "learning_rate": 9.464871591809029e-06,
      "loss": 0.0,
      "step": 5640
    },
    {
      "epoch": 1.7287721441661577,
      "grad_norm": 7.247010671562748e-06,
      "learning_rate": 9.419617603801335e-06,
      "loss": 0.0,
      "step": 5660
    },
    {
      "epoch": 1.734880879657911,
      "grad_norm": 3.206854307791218e-05,
      "learning_rate": 9.374363615793642e-06,
      "loss": 0.0,
      "step": 5680
    },
    {
      "epoch": 1.740989615149664,
      "grad_norm": 4.956354587193346e-06,
      "learning_rate": 9.32910962778595e-06,
      "loss": 0.0,
      "step": 5700
    },
    {
      "epoch": 1.7470983506414173,
      "grad_norm": 1.2389617950248066e-05,
      "learning_rate": 9.283855639778257e-06,
      "loss": 0.0,
      "step": 5720
    },
    {
      "epoch": 1.7532070861331706,
      "grad_norm": 7.4588979259715416e-06,
      "learning_rate": 9.238601651770563e-06,
      "loss": 0.0,
      "step": 5740
    },
    {
      "epoch": 1.7593158216249236,
      "grad_norm": 5.196567872189917e-05,
      "learning_rate": 9.193347663762869e-06,
      "loss": 0.0,
      "step": 5760
    },
    {
      "epoch": 1.765424557116677,
      "grad_norm": 1.542001700727269e-05,
      "learning_rate": 9.148093675755176e-06,
      "loss": 0.0,
      "step": 5780
    },
    {
      "epoch": 1.7715332926084302,
      "grad_norm": 5.307194896886358e-06,
      "learning_rate": 9.102839687747484e-06,
      "loss": 0.0,
      "step": 5800
    },
    {
      "epoch": 1.7776420281001832,
      "grad_norm": 6.591589226445649e-06,
      "learning_rate": 9.057585699739791e-06,
      "loss": 0.0,
      "step": 5820
    },
    {
      "epoch": 1.7837507635919365,
      "grad_norm": 4.813978648599004e-06,
      "learning_rate": 9.012331711732097e-06,
      "loss": 0.0,
      "step": 5840
    },
    {
      "epoch": 1.7898594990836898,
      "grad_norm": 9.162420610664412e-06,
      "learning_rate": 8.967077723724404e-06,
      "loss": 0.0,
      "step": 5860
    },
    {
      "epoch": 1.7959682345754429,
      "grad_norm": 6.3425800362892915e-06,
      "learning_rate": 8.92182373571671e-06,
      "loss": 0.0,
      "step": 5880
    },
    {
      "epoch": 1.8020769700671961,
      "grad_norm": 7.377822839771397e-06,
      "learning_rate": 8.876569747709018e-06,
      "loss": 0.0,
      "step": 5900
    },
    {
      "epoch": 1.8081857055589494,
      "grad_norm": 1.6923726434470154e-05,
      "learning_rate": 8.831315759701325e-06,
      "loss": 0.0,
      "step": 5920
    },
    {
      "epoch": 1.8142944410507025,
      "grad_norm": 1.8437929611536674e-05,
      "learning_rate": 8.786061771693631e-06,
      "loss": 0.0,
      "step": 5940
    },
    {
      "epoch": 1.8204031765424558,
      "grad_norm": 3.825522526312852e-06,
      "learning_rate": 8.740807783685938e-06,
      "loss": 0.0,
      "step": 5960
    },
    {
      "epoch": 1.826511912034209,
      "grad_norm": 1.887164785330242e-06,
      "learning_rate": 8.695553795678244e-06,
      "loss": 0.0,
      "step": 5980
    },
    {
      "epoch": 1.832620647525962,
      "grad_norm": 1.8887781152443495e-06,
      "learning_rate": 8.650299807670552e-06,
      "loss": 0.0,
      "step": 6000
    },
    {
      "epoch": 1.8387293830177154,
      "grad_norm": 2.7268351914244704e-05,
      "learning_rate": 8.605045819662858e-06,
      "loss": 0.0,
      "step": 6020
    },
    {
      "epoch": 1.8448381185094687,
      "grad_norm": 2.2082826035330072e-05,
      "learning_rate": 8.559791831655165e-06,
      "loss": 0.0,
      "step": 6040
    },
    {
      "epoch": 1.8509468540012217,
      "grad_norm": 1.1194990293006413e-05,
      "learning_rate": 8.514537843647473e-06,
      "loss": 0.0,
      "step": 6060
    },
    {
      "epoch": 1.857055589492975,
      "grad_norm": 0.00011752400314435363,
      "learning_rate": 8.46928385563978e-06,
      "loss": 0.0001,
      "step": 6080
    },
    {
      "epoch": 1.8631643249847283,
      "grad_norm": 8.505550681547902e-07,
      "learning_rate": 8.424029867632086e-06,
      "loss": 0.0,
      "step": 6100
    },
    {
      "epoch": 1.8692730604764813,
      "grad_norm": 1.4073913007450756e-05,
      "learning_rate": 8.378775879624392e-06,
      "loss": 0.0,
      "step": 6120
    },
    {
      "epoch": 1.8753817959682346,
      "grad_norm": 3.2414704946859274e-06,
      "learning_rate": 8.333521891616699e-06,
      "loss": 0.0,
      "step": 6140
    },
    {
      "epoch": 1.881490531459988,
      "grad_norm": 2.8519930310721975e-06,
      "learning_rate": 8.288267903609007e-06,
      "loss": 0.0,
      "step": 6160
    },
    {
      "epoch": 1.887599266951741,
      "grad_norm": 0.0001946232805494219,
      "learning_rate": 8.243013915601314e-06,
      "loss": 0.0,
      "step": 6180
    },
    {
      "epoch": 1.8937080024434942,
      "grad_norm": 3.0040407636988675e-06,
      "learning_rate": 8.19775992759362e-06,
      "loss": 0.0,
      "step": 6200
    },
    {
      "epoch": 1.8998167379352475,
      "grad_norm": 5.535825039260089e-06,
      "learning_rate": 8.152505939585926e-06,
      "loss": 0.0,
      "step": 6220
    },
    {
      "epoch": 1.9059254734270006,
      "grad_norm": 1.5270394214894623e-05,
      "learning_rate": 8.107251951578233e-06,
      "loss": 0.0,
      "step": 6240
    },
    {
      "epoch": 1.9120342089187539,
      "grad_norm": 1.574206976329151e-06,
      "learning_rate": 8.06199796357054e-06,
      "loss": 0.0,
      "step": 6260
    },
    {
      "epoch": 1.9181429444105071,
      "grad_norm": 0.0001246115571120754,
      "learning_rate": 8.016743975562848e-06,
      "loss": 0.0,
      "step": 6280
    },
    {
      "epoch": 1.9242516799022602,
      "grad_norm": 0.0003654256579466164,
      "learning_rate": 7.971489987555154e-06,
      "loss": 0.0,
      "step": 6300
    },
    {
      "epoch": 1.9303604153940135,
      "grad_norm": 2.466652631483157e-06,
      "learning_rate": 7.92623599954746e-06,
      "loss": 0.0,
      "step": 6320
    },
    {
      "epoch": 1.9364691508857668,
      "grad_norm": 4.5361187517301005e-07,
      "learning_rate": 7.880982011539767e-06,
      "loss": 0.0,
      "step": 6340
    },
    {
      "epoch": 1.9425778863775198,
      "grad_norm": 2.4247885903605493e-06,
      "learning_rate": 7.835728023532075e-06,
      "loss": 0.0,
      "step": 6360
    },
    {
      "epoch": 1.948686621869273,
      "grad_norm": 5.9240524024062324e-06,
      "learning_rate": 7.790474035524382e-06,
      "loss": 0.0,
      "step": 6380
    },
    {
      "epoch": 1.9547953573610264,
      "grad_norm": 7.741143690509489e-07,
      "learning_rate": 7.745220047516688e-06,
      "loss": 0.0,
      "step": 6400
    },
    {
      "epoch": 1.9609040928527794,
      "grad_norm": 2.3169386622612365e-06,
      "learning_rate": 7.699966059508995e-06,
      "loss": 0.0,
      "step": 6420
    },
    {
      "epoch": 1.9670128283445327,
      "grad_norm": 1.0454808034410235e-05,
      "learning_rate": 7.654712071501301e-06,
      "loss": 0.0,
      "step": 6440
    },
    {
      "epoch": 1.973121563836286,
      "grad_norm": 3.053396358154714e-05,
      "learning_rate": 7.609458083493608e-06,
      "loss": 0.0,
      "step": 6460
    },
    {
      "epoch": 1.979230299328039,
      "grad_norm": 1.8891309991886374e-06,
      "learning_rate": 7.564204095485915e-06,
      "loss": 0.0,
      "step": 6480
    },
    {
      "epoch": 1.9853390348197923,
      "grad_norm": 3.556998308340553e-06,
      "learning_rate": 7.518950107478222e-06,
      "loss": 0.0,
      "step": 6500
    },
    {
      "epoch": 1.9914477703115456,
      "grad_norm": 1.4654955293735838e-06,
      "learning_rate": 7.4736961194705295e-06,
      "loss": 0.0,
      "step": 6520
    },
    {
      "epoch": 1.9975565058032987,
      "grad_norm": 2.477886937413132e-06,
      "learning_rate": 7.428442131462835e-06,
      "loss": 0.0,
      "step": 6540
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 1.0,
      "eval_loss": 2.143328714510062e-07,
      "eval_runtime": 219.1158,
      "eval_samples_per_second": 59.767,
      "eval_steps_per_second": 7.471,
      "step": 6548
    },
    {
      "epoch": 2.0036652412950517,
      "grad_norm": 4.820493813895155e-06,
      "learning_rate": 7.383188143455142e-06,
      "loss": 0.0,
      "step": 6560
    },
    {
      "epoch": 2.0097739767868052,
      "grad_norm": 1.8729418798102415e-06,
      "learning_rate": 7.337934155447449e-06,
      "loss": 0.0,
      "step": 6580
    },
    {
      "epoch": 2.0158827122785583,
      "grad_norm": 8.442374564765487e-06,
      "learning_rate": 7.292680167439756e-06,
      "loss": 0.0,
      "step": 6600
    },
    {
      "epoch": 2.0219914477703114,
      "grad_norm": 1.3466138852891163e-06,
      "learning_rate": 7.2474261794320635e-06,
      "loss": 0.0,
      "step": 6620
    },
    {
      "epoch": 2.028100183262065,
      "grad_norm": 2.5637582439230755e-06,
      "learning_rate": 7.20217219142437e-06,
      "loss": 0.0,
      "step": 6640
    },
    {
      "epoch": 2.034208918753818,
      "grad_norm": 7.01731005392503e-06,
      "learning_rate": 7.156918203416676e-06,
      "loss": 0.0,
      "step": 6660
    },
    {
      "epoch": 2.040317654245571,
      "grad_norm": 9.440771009394666e-07,
      "learning_rate": 7.1116642154089834e-06,
      "loss": 0.0,
      "step": 6680
    },
    {
      "epoch": 2.0464263897373245,
      "grad_norm": 9.00510567589663e-05,
      "learning_rate": 7.06641022740129e-06,
      "loss": 0.0,
      "step": 6700
    },
    {
      "epoch": 2.0525351252290776,
      "grad_norm": 2.4560026758990716e-06,
      "learning_rate": 7.0211562393935976e-06,
      "loss": 0.0,
      "step": 6720
    },
    {
      "epoch": 2.0586438607208306,
      "grad_norm": 6.463246972998604e-05,
      "learning_rate": 6.975902251385904e-06,
      "loss": 0.0,
      "step": 6740
    },
    {
      "epoch": 2.064752596212584,
      "grad_norm": 9.020945981319528e-06,
      "learning_rate": 6.930648263378212e-06,
      "loss": 0.0,
      "step": 6760
    },
    {
      "epoch": 2.070861331704337,
      "grad_norm": 1.7322137182418373e-06,
      "learning_rate": 6.8853942753705175e-06,
      "loss": 0.0,
      "step": 6780
    },
    {
      "epoch": 2.0769700671960902,
      "grad_norm": 3.46755696227774e-05,
      "learning_rate": 6.840140287362824e-06,
      "loss": 0.0,
      "step": 6800
    },
    {
      "epoch": 2.0830788026878437,
      "grad_norm": 3.965778432757361e-06,
      "learning_rate": 6.794886299355132e-06,
      "loss": 0.0,
      "step": 6820
    },
    {
      "epoch": 2.089187538179597,
      "grad_norm": 5.40213477506768e-06,
      "learning_rate": 6.749632311347438e-06,
      "loss": 0.0,
      "step": 6840
    },
    {
      "epoch": 2.09529627367135,
      "grad_norm": 8.362208632206602e-07,
      "learning_rate": 6.704378323339745e-06,
      "loss": 0.0,
      "step": 6860
    },
    {
      "epoch": 2.1014050091631034,
      "grad_norm": 1.4797893754803226e-06,
      "learning_rate": 6.6591243353320515e-06,
      "loss": 0.0,
      "step": 6880
    },
    {
      "epoch": 2.1075137446548564,
      "grad_norm": 6.988944278418785e-06,
      "learning_rate": 6.613870347324358e-06,
      "loss": 0.0,
      "step": 6900
    },
    {
      "epoch": 2.1136224801466095,
      "grad_norm": 3.7253578284435207e-06,
      "learning_rate": 6.568616359316665e-06,
      "loss": 0.0,
      "step": 6920
    },
    {
      "epoch": 2.119731215638363,
      "grad_norm": 1.503844941908028e-06,
      "learning_rate": 6.523362371308972e-06,
      "loss": 0.0,
      "step": 6940
    },
    {
      "epoch": 2.125839951130116,
      "grad_norm": 9.240543477062602e-06,
      "learning_rate": 6.478108383301279e-06,
      "loss": 0.0,
      "step": 6960
    },
    {
      "epoch": 2.131948686621869,
      "grad_norm": 2.7893404421774903e-06,
      "learning_rate": 6.432854395293586e-06,
      "loss": 0.0,
      "step": 6980
    },
    {
      "epoch": 2.1380574221136226,
      "grad_norm": 4.0316528611583635e-05,
      "learning_rate": 6.387600407285892e-06,
      "loss": 0.0,
      "step": 7000
    },
    {
      "epoch": 2.1441661576053757,
      "grad_norm": 3.0782493922743015e-06,
      "learning_rate": 6.342346419278199e-06,
      "loss": 0.0,
      "step": 7020
    },
    {
      "epoch": 2.1502748930971287,
      "grad_norm": 2.961083737318404e-06,
      "learning_rate": 6.297092431270506e-06,
      "loss": 0.0,
      "step": 7040
    },
    {
      "epoch": 2.156383628588882,
      "grad_norm": 4.217924470140133e-06,
      "learning_rate": 6.251838443262813e-06,
      "loss": 0.0,
      "step": 7060
    },
    {
      "epoch": 2.1624923640806353,
      "grad_norm": 2.099716766679194e-06,
      "learning_rate": 6.2065844552551204e-06,
      "loss": 0.0,
      "step": 7080
    },
    {
      "epoch": 2.1686010995723883,
      "grad_norm": 1.754075310600456e-05,
      "learning_rate": 6.161330467247427e-06,
      "loss": 0.0,
      "step": 7100
    },
    {
      "epoch": 2.174709835064142,
      "grad_norm": 1.3503688023774885e-05,
      "learning_rate": 6.116076479239733e-06,
      "loss": 0.0,
      "step": 7120
    },
    {
      "epoch": 2.180818570555895,
      "grad_norm": 2.090211182803614e-06,
      "learning_rate": 6.07082249123204e-06,
      "loss": 0.0,
      "step": 7140
    },
    {
      "epoch": 2.186927306047648,
      "grad_norm": 1.5966551245583105e-06,
      "learning_rate": 6.025568503224347e-06,
      "loss": 0.0,
      "step": 7160
    },
    {
      "epoch": 2.1930360415394015,
      "grad_norm": 2.7950279672950273e-06,
      "learning_rate": 5.9803145152166545e-06,
      "loss": 0.0,
      "step": 7180
    },
    {
      "epoch": 2.1991447770311545,
      "grad_norm": 1.9896208414138528e-06,
      "learning_rate": 5.935060527208961e-06,
      "loss": 0.0,
      "step": 7200
    },
    {
      "epoch": 2.2052535125229076,
      "grad_norm": 1.3668677638634108e-06,
      "learning_rate": 5.889806539201267e-06,
      "loss": 0.0,
      "step": 7220
    },
    {
      "epoch": 2.211362248014661,
      "grad_norm": 1.907333967210434e-06,
      "learning_rate": 5.844552551193574e-06,
      "loss": 0.0,
      "step": 7240
    },
    {
      "epoch": 2.217470983506414,
      "grad_norm": 4.946515218762215e-06,
      "learning_rate": 5.799298563185881e-06,
      "loss": 0.0,
      "step": 7260
    },
    {
      "epoch": 2.223579718998167,
      "grad_norm": 7.140559432627924e-07,
      "learning_rate": 5.7540445751781885e-06,
      "loss": 0.0,
      "step": 7280
    },
    {
      "epoch": 2.2296884544899207,
      "grad_norm": 7.195207672339166e-06,
      "learning_rate": 5.708790587170495e-06,
      "loss": 0.0,
      "step": 7300
    },
    {
      "epoch": 2.2357971899816738,
      "grad_norm": 2.8957050744793378e-05,
      "learning_rate": 5.663536599162802e-06,
      "loss": 0.0,
      "step": 7320
    },
    {
      "epoch": 2.241905925473427,
      "grad_norm": 4.6814102461212315e-07,
      "learning_rate": 5.6182826111551084e-06,
      "loss": 0.0,
      "step": 7340
    },
    {
      "epoch": 2.2480146609651803,
      "grad_norm": 1.5738910406071227e-06,
      "learning_rate": 5.573028623147415e-06,
      "loss": 0.0,
      "step": 7360
    },
    {
      "epoch": 2.2541233964569334,
      "grad_norm": 1.3046563935859012e-06,
      "learning_rate": 5.527774635139722e-06,
      "loss": 0.0,
      "step": 7380
    },
    {
      "epoch": 2.2602321319486864,
      "grad_norm": 6.461044677052996e-07,
      "learning_rate": 5.482520647132029e-06,
      "loss": 0.0,
      "step": 7400
    },
    {
      "epoch": 2.26634086744044,
      "grad_norm": 1.9278147647128208e-06,
      "learning_rate": 5.437266659124336e-06,
      "loss": 0.0,
      "step": 7420
    },
    {
      "epoch": 2.272449602932193,
      "grad_norm": 2.57066790254612e-06,
      "learning_rate": 5.392012671116642e-06,
      "loss": 0.0,
      "step": 7440
    },
    {
      "epoch": 2.278558338423946,
      "grad_norm": 1.1879101293743588e-06,
      "learning_rate": 5.346758683108949e-06,
      "loss": 0.0,
      "step": 7460
    },
    {
      "epoch": 2.2846670739156996,
      "grad_norm": 4.148773314227583e-06,
      "learning_rate": 5.301504695101256e-06,
      "loss": 0.0,
      "step": 7480
    },
    {
      "epoch": 2.2907758094074526,
      "grad_norm": 1.977812871700735e-06,
      "learning_rate": 5.256250707093563e-06,
      "loss": 0.0,
      "step": 7500
    },
    {
      "epoch": 2.2968845448992057,
      "grad_norm": 3.945009211747674e-06,
      "learning_rate": 5.21099671908587e-06,
      "loss": 0.0,
      "step": 7520
    },
    {
      "epoch": 2.302993280390959,
      "grad_norm": 4.25365760747809e-06,
      "learning_rate": 5.165742731078177e-06,
      "loss": 0.0,
      "step": 7540
    },
    {
      "epoch": 2.3091020158827122,
      "grad_norm": 2.429491132716066e-06,
      "learning_rate": 5.120488743070483e-06,
      "loss": 0.0,
      "step": 7560
    },
    {
      "epoch": 2.3152107513744653,
      "grad_norm": 0.0001123632537201047,
      "learning_rate": 5.07523475506279e-06,
      "loss": 0.0,
      "step": 7580
    },
    {
      "epoch": 2.321319486866219,
      "grad_norm": 3.4814238460967317e-06,
      "learning_rate": 5.029980767055097e-06,
      "loss": 0.0,
      "step": 7600
    },
    {
      "epoch": 2.327428222357972,
      "grad_norm": 2.2773383534513414e-06,
      "learning_rate": 4.984726779047404e-06,
      "loss": 0.0,
      "step": 7620
    },
    {
      "epoch": 2.333536957849725,
      "grad_norm": 1.3637271877087187e-05,
      "learning_rate": 4.9394727910397106e-06,
      "loss": 0.0,
      "step": 7640
    },
    {
      "epoch": 2.3396456933414784,
      "grad_norm": 1.2308122450122028e-06,
      "learning_rate": 4.894218803032017e-06,
      "loss": 0.0,
      "step": 7660
    },
    {
      "epoch": 2.3457544288332315,
      "grad_norm": 2.0681384285126114e-06,
      "learning_rate": 4.848964815024325e-06,
      "loss": 0.0,
      "step": 7680
    },
    {
      "epoch": 2.3518631643249845,
      "grad_norm": 1.0572202882030979e-06,
      "learning_rate": 4.803710827016631e-06,
      "loss": 0.0,
      "step": 7700
    },
    {
      "epoch": 2.357971899816738,
      "grad_norm": 5.348540526028955e-07,
      "learning_rate": 4.758456839008938e-06,
      "loss": 0.0,
      "step": 7720
    },
    {
      "epoch": 2.364080635308491,
      "grad_norm": 1.517774671810912e-05,
      "learning_rate": 4.7132028510012455e-06,
      "loss": 0.0,
      "step": 7740
    },
    {
      "epoch": 2.370189370800244,
      "grad_norm": 1.2356817933323327e-06,
      "learning_rate": 4.667948862993551e-06,
      "loss": 0.0,
      "step": 7760
    },
    {
      "epoch": 2.3762981062919977,
      "grad_norm": 7.4059598773601465e-06,
      "learning_rate": 4.622694874985859e-06,
      "loss": 0.0,
      "step": 7780
    },
    {
      "epoch": 2.3824068417837507,
      "grad_norm": 0.00018062297021970153,
      "learning_rate": 4.577440886978165e-06,
      "loss": 0.0,
      "step": 7800
    },
    {
      "epoch": 2.388515577275504,
      "grad_norm": 2.275574479426723e-05,
      "learning_rate": 4.532186898970472e-06,
      "loss": 0.0,
      "step": 7820
    },
    {
      "epoch": 2.3946243127672573,
      "grad_norm": 9.555476935929619e-06,
      "learning_rate": 4.486932910962779e-06,
      "loss": 0.0,
      "step": 7840
    },
    {
      "epoch": 2.4007330482590103,
      "grad_norm": 9.239186510967556e-06,
      "learning_rate": 4.441678922955085e-06,
      "loss": 0.0,
      "step": 7860
    },
    {
      "epoch": 2.4068417837507634,
      "grad_norm": 9.733005299494835e-07,
      "learning_rate": 4.396424934947393e-06,
      "loss": 0.0,
      "step": 7880
    },
    {
      "epoch": 2.412950519242517,
      "grad_norm": 5.188456384530582e-07,
      "learning_rate": 4.351170946939699e-06,
      "loss": 0.0,
      "step": 7900
    },
    {
      "epoch": 2.41905925473427,
      "grad_norm": 3.2904554245760664e-06,
      "learning_rate": 4.305916958932006e-06,
      "loss": 0.0,
      "step": 7920
    },
    {
      "epoch": 2.425167990226023,
      "grad_norm": 3.958948127547046e-06,
      "learning_rate": 4.260662970924313e-06,
      "loss": 0.0,
      "step": 7940
    },
    {
      "epoch": 2.4312767257177765,
      "grad_norm": 2.1953096620563883e-06,
      "learning_rate": 4.21540898291662e-06,
      "loss": 0.0,
      "step": 7960
    },
    {
      "epoch": 2.4373854612095296,
      "grad_norm": 2.262331690872088e-06,
      "learning_rate": 4.170154994908927e-06,
      "loss": 0.0,
      "step": 7980
    },
    {
      "epoch": 2.4434941967012827,
      "grad_norm": 1.7057590184776927e-06,
      "learning_rate": 4.1249010069012335e-06,
      "loss": 0.0,
      "step": 8000
    },
    {
      "epoch": 2.449602932193036,
      "grad_norm": 1.0535436558711808e-06,
      "learning_rate": 4.079647018893541e-06,
      "loss": 0.0,
      "step": 8020
    },
    {
      "epoch": 2.455711667684789,
      "grad_norm": 2.383057790211751e-06,
      "learning_rate": 4.034393030885847e-06,
      "loss": 0.0,
      "step": 8040
    },
    {
      "epoch": 2.4618204031765423,
      "grad_norm": 2.8914307677041506e-06,
      "learning_rate": 3.989139042878154e-06,
      "loss": 0.0,
      "step": 8060
    },
    {
      "epoch": 2.4679291386682958,
      "grad_norm": 8.508634437021101e-07,
      "learning_rate": 3.943885054870461e-06,
      "loss": 0.0,
      "step": 8080
    },
    {
      "epoch": 2.474037874160049,
      "grad_norm": 1.7495386828159099e-06,
      "learning_rate": 3.8986310668627675e-06,
      "loss": 0.0,
      "step": 8100
    },
    {
      "epoch": 2.480146609651802,
      "grad_norm": 1.3397582279139897e-06,
      "learning_rate": 3.853377078855074e-06,
      "loss": 0.0,
      "step": 8120
    },
    {
      "epoch": 2.4862553451435554,
      "grad_norm": 2.5518429538351484e-06,
      "learning_rate": 3.8081230908473808e-06,
      "loss": 0.0,
      "step": 8140
    },
    {
      "epoch": 2.4923640806353085,
      "grad_norm": 3.576857125153765e-06,
      "learning_rate": 3.762869102839688e-06,
      "loss": 0.0,
      "step": 8160
    },
    {
      "epoch": 2.4984728161270615,
      "grad_norm": 6.190366548253223e-07,
      "learning_rate": 3.717615114831995e-06,
      "loss": 0.0,
      "step": 8180
    },
    {
      "epoch": 2.504581551618815,
      "grad_norm": 1.5675182112317998e-06,
      "learning_rate": 3.6723611268243015e-06,
      "loss": 0.0,
      "step": 8200
    },
    {
      "epoch": 2.510690287110568,
      "grad_norm": 1.3662227047461784e-06,
      "learning_rate": 3.6271071388166086e-06,
      "loss": 0.0,
      "step": 8220
    },
    {
      "epoch": 2.5167990226023216,
      "grad_norm": 4.103495939489221e-06,
      "learning_rate": 3.5818531508089157e-06,
      "loss": 0.0,
      "step": 8240
    },
    {
      "epoch": 2.5229077580940746,
      "grad_norm": 9.592374226485845e-06,
      "learning_rate": 3.536599162801222e-06,
      "loss": 0.0,
      "step": 8260
    },
    {
      "epoch": 2.5290164935858277,
      "grad_norm": 2.6741743113234406e-06,
      "learning_rate": 3.491345174793529e-06,
      "loss": 0.0,
      "step": 8280
    },
    {
      "epoch": 2.5351252290775808,
      "grad_norm": 2.257472715427866e-06,
      "learning_rate": 3.446091186785836e-06,
      "loss": 0.0,
      "step": 8300
    },
    {
      "epoch": 2.5412339645693343,
      "grad_norm": 6.801205358897278e-07,
      "learning_rate": 3.4008371987781427e-06,
      "loss": 0.0,
      "step": 8320
    },
    {
      "epoch": 2.5473427000610873,
      "grad_norm": 1.4797996072957176e-06,
      "learning_rate": 3.3555832107704493e-06,
      "loss": 0.0,
      "step": 8340
    },
    {
      "epoch": 2.553451435552841,
      "grad_norm": 7.306908287318947e-07,
      "learning_rate": 3.3103292227627564e-06,
      "loss": 0.0,
      "step": 8360
    },
    {
      "epoch": 2.559560171044594,
      "grad_norm": 1.1305917269055499e-06,
      "learning_rate": 3.265075234755063e-06,
      "loss": 0.0,
      "step": 8380
    },
    {
      "epoch": 2.565668906536347,
      "grad_norm": 1.3962036291559343e-06,
      "learning_rate": 3.21982124674737e-06,
      "loss": 0.0,
      "step": 8400
    },
    {
      "epoch": 2.5717776420281,
      "grad_norm": 1.7279863868679968e-06,
      "learning_rate": 3.1745672587396763e-06,
      "loss": 0.0,
      "step": 8420
    },
    {
      "epoch": 2.5778863775198535,
      "grad_norm": 1.4467386790784076e-06,
      "learning_rate": 3.1293132707319833e-06,
      "loss": 0.0,
      "step": 8440
    },
    {
      "epoch": 2.5839951130116066,
      "grad_norm": 1.5240611901390366e-06,
      "learning_rate": 3.0840592827242904e-06,
      "loss": 0.0,
      "step": 8460
    },
    {
      "epoch": 2.59010384850336,
      "grad_norm": 4.256934698787518e-05,
      "learning_rate": 3.038805294716597e-06,
      "loss": 0.0,
      "step": 8480
    },
    {
      "epoch": 2.596212583995113,
      "grad_norm": 4.955268650519429e-06,
      "learning_rate": 2.993551306708904e-06,
      "loss": 0.0,
      "step": 8500
    },
    {
      "epoch": 2.602321319486866,
      "grad_norm": 8.355453246622346e-06,
      "learning_rate": 2.9482973187012107e-06,
      "loss": 0.0,
      "step": 8520
    },
    {
      "epoch": 2.6084300549786192,
      "grad_norm": 4.753914708999218e-06,
      "learning_rate": 2.9030433306935174e-06,
      "loss": 0.0,
      "step": 8540
    },
    {
      "epoch": 2.6145387904703727,
      "grad_norm": 6.6564448388817254e-06,
      "learning_rate": 2.8577893426858244e-06,
      "loss": 0.0,
      "step": 8560
    },
    {
      "epoch": 2.620647525962126,
      "grad_norm": 1.1730600135706482e-06,
      "learning_rate": 2.8125353546781315e-06,
      "loss": 0.0,
      "step": 8580
    },
    {
      "epoch": 2.6267562614538793,
      "grad_norm": 6.93333220169734e-07,
      "learning_rate": 2.7672813666704377e-06,
      "loss": 0.0,
      "step": 8600
    },
    {
      "epoch": 2.6328649969456324,
      "grad_norm": 2.1508592453756137e-06,
      "learning_rate": 2.7220273786627448e-06,
      "loss": 0.0,
      "step": 8620
    },
    {
      "epoch": 2.6389737324373854,
      "grad_norm": 1.3679693893209333e-06,
      "learning_rate": 2.676773390655052e-06,
      "loss": 0.0,
      "step": 8640
    },
    {
      "epoch": 2.6450824679291385,
      "grad_norm": 2.5139690933428938e-06,
      "learning_rate": 2.6315194026473585e-06,
      "loss": 0.0,
      "step": 8660
    },
    {
      "epoch": 2.651191203420892,
      "grad_norm": 1.1584402273001615e-06,
      "learning_rate": 2.5862654146396655e-06,
      "loss": 0.0,
      "step": 8680
    },
    {
      "epoch": 2.657299938912645,
      "grad_norm": 3.407262965993141e-06,
      "learning_rate": 2.5410114266319726e-06,
      "loss": 0.0,
      "step": 8700
    },
    {
      "epoch": 2.6634086744043985,
      "grad_norm": 8.191630513465498e-06,
      "learning_rate": 2.495757438624279e-06,
      "loss": 0.0,
      "step": 8720
    },
    {
      "epoch": 2.6695174098961516,
      "grad_norm": 3.715025286510354e-06,
      "learning_rate": 2.450503450616586e-06,
      "loss": 0.0,
      "step": 8740
    },
    {
      "epoch": 2.6756261453879047,
      "grad_norm": 3.520420068525709e-05,
      "learning_rate": 2.4052494626088925e-06,
      "loss": 0.0,
      "step": 8760
    },
    {
      "epoch": 2.6817348808796577,
      "grad_norm": 3.856341947994224e-07,
      "learning_rate": 2.3599954746011996e-06,
      "loss": 0.0,
      "step": 8780
    },
    {
      "epoch": 2.6878436163714112,
      "grad_norm": 1.297919425269356e-06,
      "learning_rate": 2.3147414865935062e-06,
      "loss": 0.0,
      "step": 8800
    },
    {
      "epoch": 2.6939523518631643,
      "grad_norm": 3.0343410344357835e-06,
      "learning_rate": 2.2694874985858133e-06,
      "loss": 0.0,
      "step": 8820
    },
    {
      "epoch": 2.700061087354918,
      "grad_norm": 1.1620489885899588e-06,
      "learning_rate": 2.22423351057812e-06,
      "loss": 0.0,
      "step": 8840
    },
    {
      "epoch": 2.706169822846671,
      "grad_norm": 5.256658369034994e-06,
      "learning_rate": 2.1789795225704266e-06,
      "loss": 0.0,
      "step": 8860
    },
    {
      "epoch": 2.712278558338424,
      "grad_norm": 9.732920034366543e-07,
      "learning_rate": 2.1337255345627336e-06,
      "loss": 0.0,
      "step": 8880
    },
    {
      "epoch": 2.718387293830177,
      "grad_norm": 6.3857969507807866e-06,
      "learning_rate": 2.0884715465550403e-06,
      "loss": 0.0,
      "step": 8900
    },
    {
      "epoch": 2.7244960293219305,
      "grad_norm": 5.584010409620532e-07,
      "learning_rate": 2.043217558547347e-06,
      "loss": 0.0,
      "step": 8920
    },
    {
      "epoch": 2.7306047648136835,
      "grad_norm": 6.740416438333341e-07,
      "learning_rate": 1.997963570539654e-06,
      "loss": 0.0,
      "step": 8940
    },
    {
      "epoch": 2.736713500305437,
      "grad_norm": 1.9007544324267656e-05,
      "learning_rate": 1.952709582531961e-06,
      "loss": 0.0,
      "step": 8960
    },
    {
      "epoch": 2.74282223579719,
      "grad_norm": 1.8574316982267192e-06,
      "learning_rate": 1.9074555945242677e-06,
      "loss": 0.0,
      "step": 8980
    },
    {
      "epoch": 2.748930971288943,
      "grad_norm": 5.502452950167935e-06,
      "learning_rate": 1.8622016065165743e-06,
      "loss": 0.0,
      "step": 9000
    },
    {
      "epoch": 2.755039706780696,
      "grad_norm": 1.4521473303830135e-06,
      "learning_rate": 1.8169476185088814e-06,
      "loss": 0.0,
      "step": 9020
    },
    {
      "epoch": 2.7611484422724497,
      "grad_norm": 8.666233952681068e-06,
      "learning_rate": 1.771693630501188e-06,
      "loss": 0.0,
      "step": 9040
    },
    {
      "epoch": 2.7672571777642028,
      "grad_norm": 4.636723588191671e-06,
      "learning_rate": 1.7264396424934949e-06,
      "loss": 0.0,
      "step": 9060
    },
    {
      "epoch": 2.7733659132559563,
      "grad_norm": 6.921368822077056e-06,
      "learning_rate": 1.6811856544858015e-06,
      "loss": 0.0,
      "step": 9080
    },
    {
      "epoch": 2.7794746487477093,
      "grad_norm": 2.4773203222139273e-06,
      "learning_rate": 1.6359316664781086e-06,
      "loss": 0.0,
      "step": 9100
    },
    {
      "epoch": 2.7855833842394624,
      "grad_norm": 3.128547405140125e-06,
      "learning_rate": 1.5906776784704154e-06,
      "loss": 0.0,
      "step": 9120
    },
    {
      "epoch": 2.7916921197312154,
      "grad_norm": 2.838292857632041e-06,
      "learning_rate": 1.545423690462722e-06,
      "loss": 0.0,
      "step": 9140
    },
    {
      "epoch": 2.797800855222969,
      "grad_norm": 1.4044095451026806e-06,
      "learning_rate": 1.5001697024550291e-06,
      "loss": 0.0,
      "step": 9160
    },
    {
      "epoch": 2.803909590714722,
      "grad_norm": 6.671018581982935e-07,
      "learning_rate": 1.4549157144473358e-06,
      "loss": 0.0,
      "step": 9180
    },
    {
      "epoch": 2.8100183262064755,
      "grad_norm": 9.942685892383452e-07,
      "learning_rate": 1.4096617264396426e-06,
      "loss": 0.0,
      "step": 9200
    },
    {
      "epoch": 2.8161270616982286,
      "grad_norm": 6.339269930322189e-06,
      "learning_rate": 1.3644077384319492e-06,
      "loss": 0.0,
      "step": 9220
    },
    {
      "epoch": 2.8222357971899816,
      "grad_norm": 3.0362416509888135e-06,
      "learning_rate": 1.3191537504242563e-06,
      "loss": 0.0,
      "step": 9240
    },
    {
      "epoch": 2.8283445326817347,
      "grad_norm": 1.0637349987518974e-06,
      "learning_rate": 1.273899762416563e-06,
      "loss": 0.0,
      "step": 9260
    },
    {
      "epoch": 2.834453268173488,
      "grad_norm": 1.0996607215929544e-06,
      "learning_rate": 1.22864577440887e-06,
      "loss": 0.0,
      "step": 9280
    },
    {
      "epoch": 2.8405620036652413,
      "grad_norm": 1.7504569314041873e-06,
      "learning_rate": 1.1833917864011766e-06,
      "loss": 0.0,
      "step": 9300
    },
    {
      "epoch": 2.8466707391569948,
      "grad_norm": 4.981192205377738e-07,
      "learning_rate": 1.1381377983934835e-06,
      "loss": 0.0,
      "step": 9320
    },
    {
      "epoch": 2.852779474648748,
      "grad_norm": 0.00016806881467346102,
      "learning_rate": 1.0928838103857903e-06,
      "loss": 0.0,
      "step": 9340
    },
    {
      "epoch": 2.858888210140501,
      "grad_norm": 1.8345529042562703e-06,
      "learning_rate": 1.0476298223780972e-06,
      "loss": 0.0,
      "step": 9360
    },
    {
      "epoch": 2.864996945632254,
      "grad_norm": 1.0717963050410617e-06,
      "learning_rate": 1.002375834370404e-06,
      "loss": 0.0,
      "step": 9380
    },
    {
      "epoch": 2.8711056811240074,
      "grad_norm": 0.00021357891091611236,
      "learning_rate": 9.571218463627107e-07,
      "loss": 0.0,
      "step": 9400
    },
    {
      "epoch": 2.8772144166157605,
      "grad_norm": 6.040717153155128e-07,
      "learning_rate": 9.118678583550176e-07,
      "loss": 0.0,
      "step": 9420
    },
    {
      "epoch": 2.883323152107514,
      "grad_norm": 9.462334674026351e-06,
      "learning_rate": 8.666138703473244e-07,
      "loss": 0.0,
      "step": 9440
    },
    {
      "epoch": 2.889431887599267,
      "grad_norm": 4.580816721500014e-07,
      "learning_rate": 8.213598823396312e-07,
      "loss": 0.0,
      "step": 9460
    },
    {
      "epoch": 2.89554062309102,
      "grad_norm": 4.454265763342846e-06,
      "learning_rate": 7.76105894331938e-07,
      "loss": 0.0,
      "step": 9480
    },
    {
      "epoch": 2.901649358582773,
      "grad_norm": 1.517142209195299e-06,
      "learning_rate": 7.308519063242448e-07,
      "loss": 0.0,
      "step": 9500
    },
    {
      "epoch": 2.9077580940745267,
      "grad_norm": 2.7797680104413303e-06,
      "learning_rate": 6.855979183165518e-07,
      "loss": 0.0,
      "step": 9520
    },
    {
      "epoch": 2.9138668295662797,
      "grad_norm": 2.1464090877998387e-06,
      "learning_rate": 6.403439303088585e-07,
      "loss": 0.0,
      "step": 9540
    },
    {
      "epoch": 2.9199755650580332,
      "grad_norm": 6.329666121018818e-06,
      "learning_rate": 5.950899423011653e-07,
      "loss": 0.0,
      "step": 9560
    },
    {
      "epoch": 2.9260843005497863,
      "grad_norm": 1.5546625945717096e-05,
      "learning_rate": 5.498359542934721e-07,
      "loss": 0.0,
      "step": 9580
    },
    {
      "epoch": 2.9321930360415394,
      "grad_norm": 1.63538697961485e-05,
      "learning_rate": 5.04581966285779e-07,
      "loss": 0.0,
      "step": 9600
    },
    {
      "epoch": 2.9383017715332924,
      "grad_norm": 3.853052930935519e-06,
      "learning_rate": 4.593279782780858e-07,
      "loss": 0.0,
      "step": 9620
    },
    {
      "epoch": 2.944410507025046,
      "grad_norm": 6.932991141184175e-07,
      "learning_rate": 4.140739902703926e-07,
      "loss": 0.0,
      "step": 9640
    },
    {
      "epoch": 2.950519242516799,
      "grad_norm": 3.3086682833527448e-06,
      "learning_rate": 3.6882000226269943e-07,
      "loss": 0.0,
      "step": 9660
    },
    {
      "epoch": 2.9566279780085525,
      "grad_norm": 3.5897639918403e-06,
      "learning_rate": 3.2356601425500623e-07,
      "loss": 0.0,
      "step": 9680
    },
    {
      "epoch": 2.9627367135003055,
      "grad_norm": 7.835479891582509e-07,
      "learning_rate": 2.783120262473131e-07,
      "loss": 0.0,
      "step": 9700
    },
    {
      "epoch": 2.9688454489920586,
      "grad_norm": 5.945988505118294e-06,
      "learning_rate": 2.3305803823961988e-07,
      "loss": 0.0,
      "step": 9720
    },
    {
      "epoch": 2.9749541844838117,
      "grad_norm": 6.34128525689448e-07,
      "learning_rate": 1.8780405023192673e-07,
      "loss": 0.0,
      "step": 9740
    },
    {
      "epoch": 2.981062919975565,
      "grad_norm": 5.601452812697971e-07,
      "learning_rate": 1.4255006222423353e-07,
      "loss": 0.0,
      "step": 9760
    },
    {
      "epoch": 2.987171655467318,
      "grad_norm": 1.9724699086509645e-05,
      "learning_rate": 9.729607421654035e-08,
      "loss": 0.0,
      "step": 9780
    },
    {
      "epoch": 2.9932803909590717,
      "grad_norm": 6.280458251239907e-07,
      "learning_rate": 5.2042086208847155e-08,
      "loss": 0.0,
      "step": 9800
    },
    {
      "epoch": 2.999389126450825,
      "grad_norm": 6.230082817637594e-06,
      "learning_rate": 6.7880982011539765e-09,
      "loss": 0.0,
      "step": 9820
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 1.0,
      "eval_loss": 1.2272836613647087e-07,
      "eval_runtime": 219.9781,
      "eval_samples_per_second": 59.533,
      "eval_steps_per_second": 7.442,
      "step": 9822
    }
  ],
  "logging_steps": 20,
  "max_steps": 9822,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.436305786953728e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
