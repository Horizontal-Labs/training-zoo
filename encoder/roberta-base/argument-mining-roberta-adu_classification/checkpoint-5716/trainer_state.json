{
  "best_global_step": 5716,
  "best_metric": 0.9562707543373108,
  "best_model_checkpoint": "./argument-mining-roberta-adu_classification/checkpoint-5716",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 5716,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006997900629811057,
      "grad_norm": 1.0699920654296875,
      "learning_rate": 4.4289044289044294e-07,
      "loss": 0.6937,
      "step": 20
    },
    {
      "epoch": 0.013995801259622114,
      "grad_norm": 2.0356810092926025,
      "learning_rate": 9.090909090909091e-07,
      "loss": 0.6961,
      "step": 40
    },
    {
      "epoch": 0.02099370188943317,
      "grad_norm": 0.8832467794418335,
      "learning_rate": 1.3752913752913755e-06,
      "loss": 0.6973,
      "step": 60
    },
    {
      "epoch": 0.02799160251924423,
      "grad_norm": 0.5744113326072693,
      "learning_rate": 1.8414918414918418e-06,
      "loss": 0.6954,
      "step": 80
    },
    {
      "epoch": 0.03498950314905528,
      "grad_norm": 2.5517475605010986,
      "learning_rate": 2.307692307692308e-06,
      "loss": 0.7021,
      "step": 100
    },
    {
      "epoch": 0.04198740377886634,
      "grad_norm": 2.1568899154663086,
      "learning_rate": 2.773892773892774e-06,
      "loss": 0.7017,
      "step": 120
    },
    {
      "epoch": 0.0489853044086774,
      "grad_norm": 0.7689735889434814,
      "learning_rate": 3.2400932400932407e-06,
      "loss": 0.6866,
      "step": 140
    },
    {
      "epoch": 0.05598320503848846,
      "grad_norm": 2.670238971710205,
      "learning_rate": 3.7062937062937064e-06,
      "loss": 0.6886,
      "step": 160
    },
    {
      "epoch": 0.06298110566829951,
      "grad_norm": 1.5657881498336792,
      "learning_rate": 4.172494172494173e-06,
      "loss": 0.6793,
      "step": 180
    },
    {
      "epoch": 0.06997900629811056,
      "grad_norm": 2.5175845623016357,
      "learning_rate": 4.638694638694639e-06,
      "loss": 0.684,
      "step": 200
    },
    {
      "epoch": 0.07697690692792163,
      "grad_norm": 0.861406683921814,
      "learning_rate": 5.1048951048951055e-06,
      "loss": 0.675,
      "step": 220
    },
    {
      "epoch": 0.08397480755773268,
      "grad_norm": 1.3630625009536743,
      "learning_rate": 5.571095571095572e-06,
      "loss": 0.6726,
      "step": 240
    },
    {
      "epoch": 0.09097270818754374,
      "grad_norm": 1.5473326444625854,
      "learning_rate": 6.037296037296038e-06,
      "loss": 0.6693,
      "step": 260
    },
    {
      "epoch": 0.0979706088173548,
      "grad_norm": 1.2517695426940918,
      "learning_rate": 6.503496503496504e-06,
      "loss": 0.6614,
      "step": 280
    },
    {
      "epoch": 0.10496850944716585,
      "grad_norm": 1.4393752813339233,
      "learning_rate": 6.969696969696971e-06,
      "loss": 0.6574,
      "step": 300
    },
    {
      "epoch": 0.11196641007697691,
      "grad_norm": 1.116328477859497,
      "learning_rate": 7.435897435897437e-06,
      "loss": 0.6429,
      "step": 320
    },
    {
      "epoch": 0.11896431070678797,
      "grad_norm": 1.4514564275741577,
      "learning_rate": 7.902097902097902e-06,
      "loss": 0.6313,
      "step": 340
    },
    {
      "epoch": 0.12596221133659902,
      "grad_norm": 1.2559013366699219,
      "learning_rate": 8.368298368298369e-06,
      "loss": 0.6019,
      "step": 360
    },
    {
      "epoch": 0.13296011196641008,
      "grad_norm": 1.5189212560653687,
      "learning_rate": 8.834498834498834e-06,
      "loss": 0.5937,
      "step": 380
    },
    {
      "epoch": 0.13995801259622112,
      "grad_norm": 1.8106095790863037,
      "learning_rate": 9.300699300699301e-06,
      "loss": 0.5598,
      "step": 400
    },
    {
      "epoch": 0.1469559132260322,
      "grad_norm": 2.2395365238189697,
      "learning_rate": 9.766899766899768e-06,
      "loss": 0.5207,
      "step": 420
    },
    {
      "epoch": 0.15395381385584325,
      "grad_norm": 1.393937110900879,
      "learning_rate": 1.0233100233100235e-05,
      "loss": 0.4684,
      "step": 440
    },
    {
      "epoch": 0.1609517144856543,
      "grad_norm": 3.464843511581421,
      "learning_rate": 1.06993006993007e-05,
      "loss": 0.4691,
      "step": 460
    },
    {
      "epoch": 0.16794961511546536,
      "grad_norm": 2.780496835708618,
      "learning_rate": 1.1165501165501167e-05,
      "loss": 0.4445,
      "step": 480
    },
    {
      "epoch": 0.17494751574527642,
      "grad_norm": 2.5187675952911377,
      "learning_rate": 1.1631701631701633e-05,
      "loss": 0.411,
      "step": 500
    },
    {
      "epoch": 0.1819454163750875,
      "grad_norm": 2.6124978065490723,
      "learning_rate": 1.20979020979021e-05,
      "loss": 0.374,
      "step": 520
    },
    {
      "epoch": 0.18894331700489853,
      "grad_norm": 2.601473808288574,
      "learning_rate": 1.2564102564102565e-05,
      "loss": 0.3841,
      "step": 540
    },
    {
      "epoch": 0.1959412176347096,
      "grad_norm": 3.4777615070343018,
      "learning_rate": 1.3030303030303032e-05,
      "loss": 0.3375,
      "step": 560
    },
    {
      "epoch": 0.20293911826452066,
      "grad_norm": 4.3205461502075195,
      "learning_rate": 1.3496503496503497e-05,
      "loss": 0.3208,
      "step": 580
    },
    {
      "epoch": 0.2099370188943317,
      "grad_norm": 3.2930002212524414,
      "learning_rate": 1.3962703962703962e-05,
      "loss": 0.3169,
      "step": 600
    },
    {
      "epoch": 0.21693491952414276,
      "grad_norm": 1.6456762552261353,
      "learning_rate": 1.4428904428904431e-05,
      "loss": 0.3023,
      "step": 620
    },
    {
      "epoch": 0.22393282015395383,
      "grad_norm": 4.534172058105469,
      "learning_rate": 1.4895104895104898e-05,
      "loss": 0.2935,
      "step": 640
    },
    {
      "epoch": 0.23093072078376486,
      "grad_norm": 4.787545680999756,
      "learning_rate": 1.5361305361305365e-05,
      "loss": 0.2922,
      "step": 660
    },
    {
      "epoch": 0.23792862141357593,
      "grad_norm": 5.0965070724487305,
      "learning_rate": 1.582750582750583e-05,
      "loss": 0.2211,
      "step": 680
    },
    {
      "epoch": 0.244926522043387,
      "grad_norm": 12.937518119812012,
      "learning_rate": 1.6293706293706295e-05,
      "loss": 0.2374,
      "step": 700
    },
    {
      "epoch": 0.25192442267319803,
      "grad_norm": 2.0994787216186523,
      "learning_rate": 1.675990675990676e-05,
      "loss": 0.2281,
      "step": 720
    },
    {
      "epoch": 0.25892232330300907,
      "grad_norm": 4.4627156257629395,
      "learning_rate": 1.7226107226107226e-05,
      "loss": 0.267,
      "step": 740
    },
    {
      "epoch": 0.26592022393282017,
      "grad_norm": 3.8808114528656006,
      "learning_rate": 1.7692307692307694e-05,
      "loss": 0.2342,
      "step": 760
    },
    {
      "epoch": 0.2729181245626312,
      "grad_norm": 7.900051116943359,
      "learning_rate": 1.815850815850816e-05,
      "loss": 0.1971,
      "step": 780
    },
    {
      "epoch": 0.27991602519244224,
      "grad_norm": 6.4369425773620605,
      "learning_rate": 1.8624708624708628e-05,
      "loss": 0.2137,
      "step": 800
    },
    {
      "epoch": 0.28691392582225334,
      "grad_norm": 6.930795192718506,
      "learning_rate": 1.9090909090909094e-05,
      "loss": 0.2519,
      "step": 820
    },
    {
      "epoch": 0.2939118264520644,
      "grad_norm": 4.7586541175842285,
      "learning_rate": 1.955710955710956e-05,
      "loss": 0.2092,
      "step": 840
    },
    {
      "epoch": 0.3009097270818754,
      "grad_norm": 2.137399673461914,
      "learning_rate": 1.9997407983411095e-05,
      "loss": 0.1865,
      "step": 860
    },
    {
      "epoch": 0.3079076277116865,
      "grad_norm": 6.707529544830322,
      "learning_rate": 1.994556765163297e-05,
      "loss": 0.18,
      "step": 880
    },
    {
      "epoch": 0.31490552834149754,
      "grad_norm": 6.223236560821533,
      "learning_rate": 1.989372731985485e-05,
      "loss": 0.2432,
      "step": 900
    },
    {
      "epoch": 0.3219034289713086,
      "grad_norm": 2.9147658348083496,
      "learning_rate": 1.9841886988076725e-05,
      "loss": 0.2141,
      "step": 920
    },
    {
      "epoch": 0.3289013296011197,
      "grad_norm": 5.755875110626221,
      "learning_rate": 1.97900466562986e-05,
      "loss": 0.1962,
      "step": 940
    },
    {
      "epoch": 0.3358992302309307,
      "grad_norm": 8.619071006774902,
      "learning_rate": 1.973820632452048e-05,
      "loss": 0.1605,
      "step": 960
    },
    {
      "epoch": 0.34289713086074175,
      "grad_norm": 9.459427833557129,
      "learning_rate": 1.9686365992742356e-05,
      "loss": 0.2,
      "step": 980
    },
    {
      "epoch": 0.34989503149055284,
      "grad_norm": 15.11817455291748,
      "learning_rate": 1.9634525660964232e-05,
      "loss": 0.1447,
      "step": 1000
    },
    {
      "epoch": 0.3568929321203639,
      "grad_norm": 8.044270515441895,
      "learning_rate": 1.9582685329186108e-05,
      "loss": 0.2836,
      "step": 1020
    },
    {
      "epoch": 0.363890832750175,
      "grad_norm": 7.124982833862305,
      "learning_rate": 1.9530844997407983e-05,
      "loss": 0.2308,
      "step": 1040
    },
    {
      "epoch": 0.370888733379986,
      "grad_norm": 18.92306137084961,
      "learning_rate": 1.9479004665629863e-05,
      "loss": 0.1844,
      "step": 1060
    },
    {
      "epoch": 0.37788663400979705,
      "grad_norm": 5.479839324951172,
      "learning_rate": 1.942716433385174e-05,
      "loss": 0.2013,
      "step": 1080
    },
    {
      "epoch": 0.38488453463960814,
      "grad_norm": 7.094984531402588,
      "learning_rate": 1.9375324002073614e-05,
      "loss": 0.1948,
      "step": 1100
    },
    {
      "epoch": 0.3918824352694192,
      "grad_norm": 10.146647453308105,
      "learning_rate": 1.932348367029549e-05,
      "loss": 0.2159,
      "step": 1120
    },
    {
      "epoch": 0.3988803358992302,
      "grad_norm": 12.435157775878906,
      "learning_rate": 1.9271643338517366e-05,
      "loss": 0.2198,
      "step": 1140
    },
    {
      "epoch": 0.4058782365290413,
      "grad_norm": 18.041332244873047,
      "learning_rate": 1.9219803006739245e-05,
      "loss": 0.1892,
      "step": 1160
    },
    {
      "epoch": 0.41287613715885235,
      "grad_norm": 9.007100105285645,
      "learning_rate": 1.916796267496112e-05,
      "loss": 0.1811,
      "step": 1180
    },
    {
      "epoch": 0.4198740377886634,
      "grad_norm": 3.3774683475494385,
      "learning_rate": 1.9116122343183e-05,
      "loss": 0.2124,
      "step": 1200
    },
    {
      "epoch": 0.4268719384184745,
      "grad_norm": 9.489131927490234,
      "learning_rate": 1.9064282011404876e-05,
      "loss": 0.2082,
      "step": 1220
    },
    {
      "epoch": 0.4338698390482855,
      "grad_norm": 9.885331153869629,
      "learning_rate": 1.901244167962675e-05,
      "loss": 0.1745,
      "step": 1240
    },
    {
      "epoch": 0.44086773967809656,
      "grad_norm": 2.476827621459961,
      "learning_rate": 1.8960601347848627e-05,
      "loss": 0.1556,
      "step": 1260
    },
    {
      "epoch": 0.44786564030790765,
      "grad_norm": 6.255945205688477,
      "learning_rate": 1.8908761016070506e-05,
      "loss": 0.2184,
      "step": 1280
    },
    {
      "epoch": 0.4548635409377187,
      "grad_norm": 3.8516199588775635,
      "learning_rate": 1.8856920684292382e-05,
      "loss": 0.1838,
      "step": 1300
    },
    {
      "epoch": 0.46186144156752973,
      "grad_norm": 2.005190372467041,
      "learning_rate": 1.8805080352514258e-05,
      "loss": 0.1934,
      "step": 1320
    },
    {
      "epoch": 0.4688593421973408,
      "grad_norm": 9.06604290008545,
      "learning_rate": 1.8753240020736134e-05,
      "loss": 0.1817,
      "step": 1340
    },
    {
      "epoch": 0.47585724282715186,
      "grad_norm": 12.706985473632812,
      "learning_rate": 1.870139968895801e-05,
      "loss": 0.1731,
      "step": 1360
    },
    {
      "epoch": 0.4828551434569629,
      "grad_norm": 4.184300422668457,
      "learning_rate": 1.864955935717989e-05,
      "loss": 0.1708,
      "step": 1380
    },
    {
      "epoch": 0.489853044086774,
      "grad_norm": 6.39127779006958,
      "learning_rate": 1.8597719025401764e-05,
      "loss": 0.1614,
      "step": 1400
    },
    {
      "epoch": 0.49685094471658503,
      "grad_norm": 5.673100471496582,
      "learning_rate": 1.854587869362364e-05,
      "loss": 0.1611,
      "step": 1420
    },
    {
      "epoch": 0.5038488453463961,
      "grad_norm": 8.440659523010254,
      "learning_rate": 1.8494038361845516e-05,
      "loss": 0.1401,
      "step": 1440
    },
    {
      "epoch": 0.5108467459762072,
      "grad_norm": 1.651258111000061,
      "learning_rate": 1.8442198030067392e-05,
      "loss": 0.141,
      "step": 1460
    },
    {
      "epoch": 0.5178446466060181,
      "grad_norm": 4.663486957550049,
      "learning_rate": 1.839035769828927e-05,
      "loss": 0.2158,
      "step": 1480
    },
    {
      "epoch": 0.5248425472358292,
      "grad_norm": 11.934609413146973,
      "learning_rate": 1.8338517366511147e-05,
      "loss": 0.218,
      "step": 1500
    },
    {
      "epoch": 0.5318404478656403,
      "grad_norm": 0.674187421798706,
      "learning_rate": 1.8286677034733026e-05,
      "loss": 0.0905,
      "step": 1520
    },
    {
      "epoch": 0.5388383484954513,
      "grad_norm": 15.126791954040527,
      "learning_rate": 1.82348367029549e-05,
      "loss": 0.1909,
      "step": 1540
    },
    {
      "epoch": 0.5458362491252624,
      "grad_norm": 19.97867202758789,
      "learning_rate": 1.8182996371176777e-05,
      "loss": 0.22,
      "step": 1560
    },
    {
      "epoch": 0.5528341497550735,
      "grad_norm": 11.776171684265137,
      "learning_rate": 1.8131156039398653e-05,
      "loss": 0.1193,
      "step": 1580
    },
    {
      "epoch": 0.5598320503848845,
      "grad_norm": 16.34076690673828,
      "learning_rate": 1.807931570762053e-05,
      "loss": 0.3036,
      "step": 1600
    },
    {
      "epoch": 0.5668299510146956,
      "grad_norm": 8.177658081054688,
      "learning_rate": 1.8027475375842408e-05,
      "loss": 0.1894,
      "step": 1620
    },
    {
      "epoch": 0.5738278516445067,
      "grad_norm": 18.536945343017578,
      "learning_rate": 1.7975635044064284e-05,
      "loss": 0.1702,
      "step": 1640
    },
    {
      "epoch": 0.5808257522743177,
      "grad_norm": 4.870700359344482,
      "learning_rate": 1.792379471228616e-05,
      "loss": 0.2518,
      "step": 1660
    },
    {
      "epoch": 0.5878236529041287,
      "grad_norm": 14.221237182617188,
      "learning_rate": 1.7871954380508035e-05,
      "loss": 0.1383,
      "step": 1680
    },
    {
      "epoch": 0.5948215535339398,
      "grad_norm": 12.564377784729004,
      "learning_rate": 1.7820114048729915e-05,
      "loss": 0.1439,
      "step": 1700
    },
    {
      "epoch": 0.6018194541637508,
      "grad_norm": 1.410294532775879,
      "learning_rate": 1.776827371695179e-05,
      "loss": 0.1718,
      "step": 1720
    },
    {
      "epoch": 0.6088173547935619,
      "grad_norm": 8.390228271484375,
      "learning_rate": 1.7716433385173666e-05,
      "loss": 0.2071,
      "step": 1740
    },
    {
      "epoch": 0.615815255423373,
      "grad_norm": 13.078325271606445,
      "learning_rate": 1.7664593053395542e-05,
      "loss": 0.1414,
      "step": 1760
    },
    {
      "epoch": 0.622813156053184,
      "grad_norm": 31.090749740600586,
      "learning_rate": 1.7612752721617418e-05,
      "loss": 0.1641,
      "step": 1780
    },
    {
      "epoch": 0.6298110566829951,
      "grad_norm": 6.030703067779541,
      "learning_rate": 1.7560912389839297e-05,
      "loss": 0.1893,
      "step": 1800
    },
    {
      "epoch": 0.6368089573128062,
      "grad_norm": 4.827314853668213,
      "learning_rate": 1.7509072058061173e-05,
      "loss": 0.1055,
      "step": 1820
    },
    {
      "epoch": 0.6438068579426172,
      "grad_norm": 0.2153771072626114,
      "learning_rate": 1.7457231726283052e-05,
      "loss": 0.2331,
      "step": 1840
    },
    {
      "epoch": 0.6508047585724283,
      "grad_norm": 12.149852752685547,
      "learning_rate": 1.7405391394504928e-05,
      "loss": 0.1661,
      "step": 1860
    },
    {
      "epoch": 0.6578026592022393,
      "grad_norm": 4.416481971740723,
      "learning_rate": 1.7353551062726803e-05,
      "loss": 0.1216,
      "step": 1880
    },
    {
      "epoch": 0.6648005598320503,
      "grad_norm": 18.349937438964844,
      "learning_rate": 1.730171073094868e-05,
      "loss": 0.1451,
      "step": 1900
    },
    {
      "epoch": 0.6717984604618614,
      "grad_norm": 6.502777576446533,
      "learning_rate": 1.7249870399170555e-05,
      "loss": 0.1167,
      "step": 1920
    },
    {
      "epoch": 0.6787963610916725,
      "grad_norm": 14.759590148925781,
      "learning_rate": 1.7198030067392434e-05,
      "loss": 0.1693,
      "step": 1940
    },
    {
      "epoch": 0.6857942617214835,
      "grad_norm": 0.4563232660293579,
      "learning_rate": 1.714618973561431e-05,
      "loss": 0.1894,
      "step": 1960
    },
    {
      "epoch": 0.6927921623512946,
      "grad_norm": 2.325502395629883,
      "learning_rate": 1.7094349403836186e-05,
      "loss": 0.1156,
      "step": 1980
    },
    {
      "epoch": 0.6997900629811057,
      "grad_norm": 19.734758377075195,
      "learning_rate": 1.704250907205806e-05,
      "loss": 0.1944,
      "step": 2000
    },
    {
      "epoch": 0.7067879636109167,
      "grad_norm": 19.977689743041992,
      "learning_rate": 1.6990668740279937e-05,
      "loss": 0.1588,
      "step": 2020
    },
    {
      "epoch": 0.7137858642407278,
      "grad_norm": 10.944806098937988,
      "learning_rate": 1.6938828408501816e-05,
      "loss": 0.1563,
      "step": 2040
    },
    {
      "epoch": 0.7207837648705389,
      "grad_norm": 6.32034969329834,
      "learning_rate": 1.6886988076723692e-05,
      "loss": 0.108,
      "step": 2060
    },
    {
      "epoch": 0.72778166550035,
      "grad_norm": 31.033191680908203,
      "learning_rate": 1.6835147744945568e-05,
      "loss": 0.1923,
      "step": 2080
    },
    {
      "epoch": 0.7347795661301609,
      "grad_norm": 1.8103444576263428,
      "learning_rate": 1.6783307413167447e-05,
      "loss": 0.1122,
      "step": 2100
    },
    {
      "epoch": 0.741777466759972,
      "grad_norm": 19.879592895507812,
      "learning_rate": 1.6731467081389323e-05,
      "loss": 0.1114,
      "step": 2120
    },
    {
      "epoch": 0.7487753673897831,
      "grad_norm": 14.573477745056152,
      "learning_rate": 1.66796267496112e-05,
      "loss": 0.0995,
      "step": 2140
    },
    {
      "epoch": 0.7557732680195941,
      "grad_norm": 20.025049209594727,
      "learning_rate": 1.6627786417833078e-05,
      "loss": 0.1431,
      "step": 2160
    },
    {
      "epoch": 0.7627711686494052,
      "grad_norm": 7.72123908996582,
      "learning_rate": 1.6575946086054953e-05,
      "loss": 0.1989,
      "step": 2180
    },
    {
      "epoch": 0.7697690692792163,
      "grad_norm": 12.724882125854492,
      "learning_rate": 1.652410575427683e-05,
      "loss": 0.191,
      "step": 2200
    },
    {
      "epoch": 0.7767669699090273,
      "grad_norm": 1.1043543815612793,
      "learning_rate": 1.6472265422498705e-05,
      "loss": 0.1635,
      "step": 2220
    },
    {
      "epoch": 0.7837648705388384,
      "grad_norm": 16.89756965637207,
      "learning_rate": 1.642042509072058e-05,
      "loss": 0.1964,
      "step": 2240
    },
    {
      "epoch": 0.7907627711686495,
      "grad_norm": 13.8502779006958,
      "learning_rate": 1.636858475894246e-05,
      "loss": 0.1343,
      "step": 2260
    },
    {
      "epoch": 0.7977606717984604,
      "grad_norm": 16.811586380004883,
      "learning_rate": 1.6316744427164336e-05,
      "loss": 0.1693,
      "step": 2280
    },
    {
      "epoch": 0.8047585724282715,
      "grad_norm": 8.967480659484863,
      "learning_rate": 1.626490409538621e-05,
      "loss": 0.2233,
      "step": 2300
    },
    {
      "epoch": 0.8117564730580826,
      "grad_norm": 5.430393695831299,
      "learning_rate": 1.6213063763608087e-05,
      "loss": 0.1396,
      "step": 2320
    },
    {
      "epoch": 0.8187543736878936,
      "grad_norm": 13.440084457397461,
      "learning_rate": 1.6161223431829963e-05,
      "loss": 0.1926,
      "step": 2340
    },
    {
      "epoch": 0.8257522743177047,
      "grad_norm": 2.3805229663848877,
      "learning_rate": 1.6109383100051842e-05,
      "loss": 0.1687,
      "step": 2360
    },
    {
      "epoch": 0.8327501749475158,
      "grad_norm": 13.563593864440918,
      "learning_rate": 1.6057542768273718e-05,
      "loss": 0.1899,
      "step": 2380
    },
    {
      "epoch": 0.8397480755773268,
      "grad_norm": 19.321029663085938,
      "learning_rate": 1.6005702436495597e-05,
      "loss": 0.1378,
      "step": 2400
    },
    {
      "epoch": 0.8467459762071379,
      "grad_norm": 20.864377975463867,
      "learning_rate": 1.5953862104717473e-05,
      "loss": 0.1738,
      "step": 2420
    },
    {
      "epoch": 0.853743876836949,
      "grad_norm": 0.22021742165088654,
      "learning_rate": 1.590202177293935e-05,
      "loss": 0.1985,
      "step": 2440
    },
    {
      "epoch": 0.86074177746676,
      "grad_norm": 30.348827362060547,
      "learning_rate": 1.5850181441161224e-05,
      "loss": 0.1547,
      "step": 2460
    },
    {
      "epoch": 0.867739678096571,
      "grad_norm": 19.908546447753906,
      "learning_rate": 1.57983411093831e-05,
      "loss": 0.1738,
      "step": 2480
    },
    {
      "epoch": 0.8747375787263821,
      "grad_norm": 1.0029786825180054,
      "learning_rate": 1.574650077760498e-05,
      "loss": 0.157,
      "step": 2500
    },
    {
      "epoch": 0.8817354793561931,
      "grad_norm": 0.4746267795562744,
      "learning_rate": 1.5694660445826855e-05,
      "loss": 0.1969,
      "step": 2520
    },
    {
      "epoch": 0.8887333799860042,
      "grad_norm": 32.43465042114258,
      "learning_rate": 1.564282011404873e-05,
      "loss": 0.1766,
      "step": 2540
    },
    {
      "epoch": 0.8957312806158153,
      "grad_norm": 6.453778266906738,
      "learning_rate": 1.5590979782270607e-05,
      "loss": 0.1989,
      "step": 2560
    },
    {
      "epoch": 0.9027291812456263,
      "grad_norm": 0.6443470120429993,
      "learning_rate": 1.5539139450492483e-05,
      "loss": 0.1897,
      "step": 2580
    },
    {
      "epoch": 0.9097270818754374,
      "grad_norm": 11.710348129272461,
      "learning_rate": 1.548729911871436e-05,
      "loss": 0.1689,
      "step": 2600
    },
    {
      "epoch": 0.9167249825052485,
      "grad_norm": 34.39108657836914,
      "learning_rate": 1.5435458786936237e-05,
      "loss": 0.1549,
      "step": 2620
    },
    {
      "epoch": 0.9237228831350595,
      "grad_norm": 0.21632182598114014,
      "learning_rate": 1.5383618455158113e-05,
      "loss": 0.1417,
      "step": 2640
    },
    {
      "epoch": 0.9307207837648706,
      "grad_norm": 0.4911329448223114,
      "learning_rate": 1.533177812337999e-05,
      "loss": 0.1702,
      "step": 2660
    },
    {
      "epoch": 0.9377186843946816,
      "grad_norm": 0.810604453086853,
      "learning_rate": 1.5279937791601868e-05,
      "loss": 0.1617,
      "step": 2680
    },
    {
      "epoch": 0.9447165850244926,
      "grad_norm": 3.814244270324707,
      "learning_rate": 1.5228097459823746e-05,
      "loss": 0.1744,
      "step": 2700
    },
    {
      "epoch": 0.9517144856543037,
      "grad_norm": 1.099714756011963,
      "learning_rate": 1.5176257128045621e-05,
      "loss": 0.2319,
      "step": 2720
    },
    {
      "epoch": 0.9587123862841148,
      "grad_norm": 6.469353199005127,
      "learning_rate": 1.5124416796267499e-05,
      "loss": 0.2277,
      "step": 2740
    },
    {
      "epoch": 0.9657102869139258,
      "grad_norm": 20.914880752563477,
      "learning_rate": 1.5072576464489375e-05,
      "loss": 0.1833,
      "step": 2760
    },
    {
      "epoch": 0.9727081875437369,
      "grad_norm": 5.591677188873291,
      "learning_rate": 1.502073613271125e-05,
      "loss": 0.1985,
      "step": 2780
    },
    {
      "epoch": 0.979706088173548,
      "grad_norm": 11.297385215759277,
      "learning_rate": 1.4968895800933128e-05,
      "loss": 0.1509,
      "step": 2800
    },
    {
      "epoch": 0.986703988803359,
      "grad_norm": 1.2592114210128784,
      "learning_rate": 1.4917055469155004e-05,
      "loss": 0.1031,
      "step": 2820
    },
    {
      "epoch": 0.9937018894331701,
      "grad_norm": 1.1531823873519897,
      "learning_rate": 1.4865215137376881e-05,
      "loss": 0.1508,
      "step": 2840
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9525100588798523,
      "eval_loss": 0.1815953552722931,
      "eval_runtime": 325.5147,
      "eval_samples_per_second": 35.126,
      "eval_steps_per_second": 4.393,
      "step": 2858
    },
    {
      "epoch": 1.000699790062981,
      "grad_norm": 2.8680593967437744,
      "learning_rate": 1.4813374805598757e-05,
      "loss": 0.1483,
      "step": 2860
    },
    {
      "epoch": 1.0076976906927921,
      "grad_norm": 0.3538874089717865,
      "learning_rate": 1.4761534473820633e-05,
      "loss": 0.127,
      "step": 2880
    },
    {
      "epoch": 1.0146955913226032,
      "grad_norm": 0.38270971179008484,
      "learning_rate": 1.470969414204251e-05,
      "loss": 0.1342,
      "step": 2900
    },
    {
      "epoch": 1.0216934919524143,
      "grad_norm": 4.237642288208008,
      "learning_rate": 1.4657853810264386e-05,
      "loss": 0.1639,
      "step": 2920
    },
    {
      "epoch": 1.0286913925822254,
      "grad_norm": 6.95197057723999,
      "learning_rate": 1.4606013478486263e-05,
      "loss": 0.1154,
      "step": 2940
    },
    {
      "epoch": 1.0356892932120363,
      "grad_norm": 15.683760643005371,
      "learning_rate": 1.455417314670814e-05,
      "loss": 0.2188,
      "step": 2960
    },
    {
      "epoch": 1.0426871938418474,
      "grad_norm": 0.5014979243278503,
      "learning_rate": 1.4502332814930015e-05,
      "loss": 0.1021,
      "step": 2980
    },
    {
      "epoch": 1.0496850944716585,
      "grad_norm": 2.407299041748047,
      "learning_rate": 1.4450492483151894e-05,
      "loss": 0.1675,
      "step": 3000
    },
    {
      "epoch": 1.0566829951014696,
      "grad_norm": 0.519110381603241,
      "learning_rate": 1.4398652151373772e-05,
      "loss": 0.1075,
      "step": 3020
    },
    {
      "epoch": 1.0636808957312807,
      "grad_norm": 6.809902667999268,
      "learning_rate": 1.4346811819595647e-05,
      "loss": 0.1901,
      "step": 3040
    },
    {
      "epoch": 1.0706787963610918,
      "grad_norm": 0.11458640545606613,
      "learning_rate": 1.4294971487817523e-05,
      "loss": 0.1412,
      "step": 3060
    },
    {
      "epoch": 1.0776766969909026,
      "grad_norm": 18.079423904418945,
      "learning_rate": 1.42431311560394e-05,
      "loss": 0.1339,
      "step": 3080
    },
    {
      "epoch": 1.0846745976207137,
      "grad_norm": 20.428007125854492,
      "learning_rate": 1.4191290824261276e-05,
      "loss": 0.1744,
      "step": 3100
    },
    {
      "epoch": 1.0916724982505248,
      "grad_norm": 5.683044910430908,
      "learning_rate": 1.4139450492483154e-05,
      "loss": 0.2138,
      "step": 3120
    },
    {
      "epoch": 1.098670398880336,
      "grad_norm": 0.37206733226776123,
      "learning_rate": 1.408761016070503e-05,
      "loss": 0.1202,
      "step": 3140
    },
    {
      "epoch": 1.105668299510147,
      "grad_norm": 11.490445137023926,
      "learning_rate": 1.4035769828926905e-05,
      "loss": 0.1399,
      "step": 3160
    },
    {
      "epoch": 1.112666200139958,
      "grad_norm": 1.6253314018249512,
      "learning_rate": 1.3983929497148783e-05,
      "loss": 0.1536,
      "step": 3180
    },
    {
      "epoch": 1.119664100769769,
      "grad_norm": 0.7167191505432129,
      "learning_rate": 1.3932089165370659e-05,
      "loss": 0.2614,
      "step": 3200
    },
    {
      "epoch": 1.12666200139958,
      "grad_norm": 0.5861446261405945,
      "learning_rate": 1.3880248833592536e-05,
      "loss": 0.1425,
      "step": 3220
    },
    {
      "epoch": 1.1336599020293912,
      "grad_norm": 5.1323628425598145,
      "learning_rate": 1.3828408501814412e-05,
      "loss": 0.1422,
      "step": 3240
    },
    {
      "epoch": 1.1406578026592022,
      "grad_norm": 11.16945743560791,
      "learning_rate": 1.377656817003629e-05,
      "loss": 0.1537,
      "step": 3260
    },
    {
      "epoch": 1.1476557032890133,
      "grad_norm": 11.230687141418457,
      "learning_rate": 1.3724727838258165e-05,
      "loss": 0.1676,
      "step": 3280
    },
    {
      "epoch": 1.1546536039188244,
      "grad_norm": 35.13652801513672,
      "learning_rate": 1.3672887506480041e-05,
      "loss": 0.1752,
      "step": 3300
    },
    {
      "epoch": 1.1616515045486353,
      "grad_norm": 4.2253522872924805,
      "learning_rate": 1.362104717470192e-05,
      "loss": 0.1441,
      "step": 3320
    },
    {
      "epoch": 1.1686494051784464,
      "grad_norm": 13.152667999267578,
      "learning_rate": 1.3569206842923796e-05,
      "loss": 0.2093,
      "step": 3340
    },
    {
      "epoch": 1.1756473058082575,
      "grad_norm": 12.176965713500977,
      "learning_rate": 1.3517366511145673e-05,
      "loss": 0.1604,
      "step": 3360
    },
    {
      "epoch": 1.1826452064380686,
      "grad_norm": 8.878214836120605,
      "learning_rate": 1.3465526179367549e-05,
      "loss": 0.2061,
      "step": 3380
    },
    {
      "epoch": 1.1896431070678797,
      "grad_norm": 17.34452247619629,
      "learning_rate": 1.3413685847589427e-05,
      "loss": 0.1506,
      "step": 3400
    },
    {
      "epoch": 1.1966410076976908,
      "grad_norm": 12.184616088867188,
      "learning_rate": 1.3361845515811302e-05,
      "loss": 0.1544,
      "step": 3420
    },
    {
      "epoch": 1.2036389083275019,
      "grad_norm": 4.691346168518066,
      "learning_rate": 1.331000518403318e-05,
      "loss": 0.177,
      "step": 3440
    },
    {
      "epoch": 1.2106368089573127,
      "grad_norm": 4.156075954437256,
      "learning_rate": 1.3258164852255056e-05,
      "loss": 0.1193,
      "step": 3460
    },
    {
      "epoch": 1.2176347095871238,
      "grad_norm": 27.520471572875977,
      "learning_rate": 1.3206324520476931e-05,
      "loss": 0.2483,
      "step": 3480
    },
    {
      "epoch": 1.224632610216935,
      "grad_norm": 3.0713541507720947,
      "learning_rate": 1.3154484188698809e-05,
      "loss": 0.1704,
      "step": 3500
    },
    {
      "epoch": 1.231630510846746,
      "grad_norm": 0.3894694447517395,
      "learning_rate": 1.3102643856920685e-05,
      "loss": 0.1698,
      "step": 3520
    },
    {
      "epoch": 1.2386284114765571,
      "grad_norm": 22.11724281311035,
      "learning_rate": 1.3050803525142562e-05,
      "loss": 0.1527,
      "step": 3540
    },
    {
      "epoch": 1.245626312106368,
      "grad_norm": 0.5743923187255859,
      "learning_rate": 1.2998963193364438e-05,
      "loss": 0.1848,
      "step": 3560
    },
    {
      "epoch": 1.252624212736179,
      "grad_norm": 1.7887647151947021,
      "learning_rate": 1.2947122861586314e-05,
      "loss": 0.1404,
      "step": 3580
    },
    {
      "epoch": 1.2596221133659902,
      "grad_norm": 0.4617433249950409,
      "learning_rate": 1.2895282529808191e-05,
      "loss": 0.1301,
      "step": 3600
    },
    {
      "epoch": 1.2666200139958013,
      "grad_norm": 9.21238899230957,
      "learning_rate": 1.284344219803007e-05,
      "loss": 0.1453,
      "step": 3620
    },
    {
      "epoch": 1.2736179146256124,
      "grad_norm": 2.218165636062622,
      "learning_rate": 1.2791601866251946e-05,
      "loss": 0.161,
      "step": 3640
    },
    {
      "epoch": 1.2806158152554235,
      "grad_norm": 12.357196807861328,
      "learning_rate": 1.2739761534473822e-05,
      "loss": 0.1556,
      "step": 3660
    },
    {
      "epoch": 1.2876137158852345,
      "grad_norm": 0.7368980050086975,
      "learning_rate": 1.26879212026957e-05,
      "loss": 0.1484,
      "step": 3680
    },
    {
      "epoch": 1.2946116165150454,
      "grad_norm": 12.972370147705078,
      "learning_rate": 1.2636080870917575e-05,
      "loss": 0.1056,
      "step": 3700
    },
    {
      "epoch": 1.3016095171448565,
      "grad_norm": 2.5973947048187256,
      "learning_rate": 1.2584240539139452e-05,
      "loss": 0.1126,
      "step": 3720
    },
    {
      "epoch": 1.3086074177746676,
      "grad_norm": 3.2424800395965576,
      "learning_rate": 1.2532400207361328e-05,
      "loss": 0.1093,
      "step": 3740
    },
    {
      "epoch": 1.3156053184044787,
      "grad_norm": 10.182071685791016,
      "learning_rate": 1.2480559875583204e-05,
      "loss": 0.2715,
      "step": 3760
    },
    {
      "epoch": 1.3226032190342898,
      "grad_norm": 23.647674560546875,
      "learning_rate": 1.2428719543805081e-05,
      "loss": 0.2149,
      "step": 3780
    },
    {
      "epoch": 1.3296011196641007,
      "grad_norm": 13.666464805603027,
      "learning_rate": 1.2376879212026957e-05,
      "loss": 0.1344,
      "step": 3800
    },
    {
      "epoch": 1.3365990202939118,
      "grad_norm": 5.300728797912598,
      "learning_rate": 1.2325038880248835e-05,
      "loss": 0.1592,
      "step": 3820
    },
    {
      "epoch": 1.3435969209237228,
      "grad_norm": 0.3131183087825775,
      "learning_rate": 1.227319854847071e-05,
      "loss": 0.1087,
      "step": 3840
    },
    {
      "epoch": 1.350594821553534,
      "grad_norm": 19.977638244628906,
      "learning_rate": 1.2221358216692586e-05,
      "loss": 0.1559,
      "step": 3860
    },
    {
      "epoch": 1.357592722183345,
      "grad_norm": 2.013030529022217,
      "learning_rate": 1.2169517884914464e-05,
      "loss": 0.1165,
      "step": 3880
    },
    {
      "epoch": 1.3645906228131561,
      "grad_norm": 2.821505308151245,
      "learning_rate": 1.211767755313634e-05,
      "loss": 0.1439,
      "step": 3900
    },
    {
      "epoch": 1.3715885234429672,
      "grad_norm": 0.1966608464717865,
      "learning_rate": 1.2065837221358219e-05,
      "loss": 0.0911,
      "step": 3920
    },
    {
      "epoch": 1.378586424072778,
      "grad_norm": 2.6239945888519287,
      "learning_rate": 1.2013996889580094e-05,
      "loss": 0.2209,
      "step": 3940
    },
    {
      "epoch": 1.3855843247025892,
      "grad_norm": 10.770101547241211,
      "learning_rate": 1.1962156557801972e-05,
      "loss": 0.1344,
      "step": 3960
    },
    {
      "epoch": 1.3925822253324003,
      "grad_norm": 0.22804106771945953,
      "learning_rate": 1.1910316226023848e-05,
      "loss": 0.153,
      "step": 3980
    },
    {
      "epoch": 1.3995801259622114,
      "grad_norm": 8.933354377746582,
      "learning_rate": 1.1858475894245725e-05,
      "loss": 0.2158,
      "step": 4000
    },
    {
      "epoch": 1.4065780265920225,
      "grad_norm": 29.12711524963379,
      "learning_rate": 1.1806635562467601e-05,
      "loss": 0.2264,
      "step": 4020
    },
    {
      "epoch": 1.4135759272218333,
      "grad_norm": 2.2960009574890137,
      "learning_rate": 1.1754795230689477e-05,
      "loss": 0.1485,
      "step": 4040
    },
    {
      "epoch": 1.4205738278516444,
      "grad_norm": 0.5582578182220459,
      "learning_rate": 1.1702954898911354e-05,
      "loss": 0.217,
      "step": 4060
    },
    {
      "epoch": 1.4275717284814555,
      "grad_norm": 7.312621593475342,
      "learning_rate": 1.165111456713323e-05,
      "loss": 0.1469,
      "step": 4080
    },
    {
      "epoch": 1.4345696291112666,
      "grad_norm": 11.522906303405762,
      "learning_rate": 1.1599274235355107e-05,
      "loss": 0.0983,
      "step": 4100
    },
    {
      "epoch": 1.4415675297410777,
      "grad_norm": 10.145390510559082,
      "learning_rate": 1.1547433903576983e-05,
      "loss": 0.1575,
      "step": 4120
    },
    {
      "epoch": 1.4485654303708888,
      "grad_norm": 7.715653419494629,
      "learning_rate": 1.1495593571798859e-05,
      "loss": 0.1844,
      "step": 4140
    },
    {
      "epoch": 1.4555633310007,
      "grad_norm": 13.943997383117676,
      "learning_rate": 1.1443753240020736e-05,
      "loss": 0.1316,
      "step": 4160
    },
    {
      "epoch": 1.4625612316305108,
      "grad_norm": 11.724087715148926,
      "learning_rate": 1.1391912908242612e-05,
      "loss": 0.1558,
      "step": 4180
    },
    {
      "epoch": 1.4695591322603219,
      "grad_norm": 20.483627319335938,
      "learning_rate": 1.134007257646449e-05,
      "loss": 0.1097,
      "step": 4200
    },
    {
      "epoch": 1.476557032890133,
      "grad_norm": 2.757611036300659,
      "learning_rate": 1.1288232244686367e-05,
      "loss": 0.1514,
      "step": 4220
    },
    {
      "epoch": 1.483554933519944,
      "grad_norm": 10.0653657913208,
      "learning_rate": 1.1236391912908245e-05,
      "loss": 0.1584,
      "step": 4240
    },
    {
      "epoch": 1.4905528341497551,
      "grad_norm": 3.005511522293091,
      "learning_rate": 1.118455158113012e-05,
      "loss": 0.1918,
      "step": 4260
    },
    {
      "epoch": 1.497550734779566,
      "grad_norm": 21.62517547607422,
      "learning_rate": 1.1132711249351998e-05,
      "loss": 0.1133,
      "step": 4280
    },
    {
      "epoch": 1.5045486354093773,
      "grad_norm": 2.8486897945404053,
      "learning_rate": 1.1080870917573874e-05,
      "loss": 0.1848,
      "step": 4300
    },
    {
      "epoch": 1.5115465360391882,
      "grad_norm": 3.1183242797851562,
      "learning_rate": 1.102903058579575e-05,
      "loss": 0.144,
      "step": 4320
    },
    {
      "epoch": 1.5185444366689993,
      "grad_norm": 5.301215171813965,
      "learning_rate": 1.0977190254017627e-05,
      "loss": 0.179,
      "step": 4340
    },
    {
      "epoch": 1.5255423372988104,
      "grad_norm": 5.408576965332031,
      "learning_rate": 1.0925349922239503e-05,
      "loss": 0.1838,
      "step": 4360
    },
    {
      "epoch": 1.5325402379286213,
      "grad_norm": 11.317399024963379,
      "learning_rate": 1.087350959046138e-05,
      "loss": 0.1085,
      "step": 4380
    },
    {
      "epoch": 1.5395381385584326,
      "grad_norm": 12.066366195678711,
      "learning_rate": 1.0821669258683256e-05,
      "loss": 0.2002,
      "step": 4400
    },
    {
      "epoch": 1.5465360391882434,
      "grad_norm": 21.9161434173584,
      "learning_rate": 1.0769828926905133e-05,
      "loss": 0.119,
      "step": 4420
    },
    {
      "epoch": 1.5535339398180545,
      "grad_norm": 2.609093189239502,
      "learning_rate": 1.0717988595127009e-05,
      "loss": 0.1521,
      "step": 4440
    },
    {
      "epoch": 1.5605318404478656,
      "grad_norm": 9.332383155822754,
      "learning_rate": 1.0666148263348885e-05,
      "loss": 0.2136,
      "step": 4460
    },
    {
      "epoch": 1.5675297410776767,
      "grad_norm": 7.340703964233398,
      "learning_rate": 1.0614307931570762e-05,
      "loss": 0.1515,
      "step": 4480
    },
    {
      "epoch": 1.5745276417074878,
      "grad_norm": 2.723055362701416,
      "learning_rate": 1.0562467599792638e-05,
      "loss": 0.1614,
      "step": 4500
    },
    {
      "epoch": 1.5815255423372987,
      "grad_norm": 0.43085604906082153,
      "learning_rate": 1.0510627268014517e-05,
      "loss": 0.2129,
      "step": 4520
    },
    {
      "epoch": 1.58852344296711,
      "grad_norm": 9.21927261352539,
      "learning_rate": 1.0458786936236393e-05,
      "loss": 0.1333,
      "step": 4540
    },
    {
      "epoch": 1.5955213435969209,
      "grad_norm": 29.243915557861328,
      "learning_rate": 1.040694660445827e-05,
      "loss": 0.1559,
      "step": 4560
    },
    {
      "epoch": 1.602519244226732,
      "grad_norm": 0.42422306537628174,
      "learning_rate": 1.0355106272680146e-05,
      "loss": 0.1064,
      "step": 4580
    },
    {
      "epoch": 1.609517144856543,
      "grad_norm": 23.320430755615234,
      "learning_rate": 1.0303265940902024e-05,
      "loss": 0.1238,
      "step": 4600
    },
    {
      "epoch": 1.616515045486354,
      "grad_norm": 14.062201499938965,
      "learning_rate": 1.02514256091239e-05,
      "loss": 0.1693,
      "step": 4620
    },
    {
      "epoch": 1.6235129461161653,
      "grad_norm": 23.812896728515625,
      "learning_rate": 1.0199585277345775e-05,
      "loss": 0.1626,
      "step": 4640
    },
    {
      "epoch": 1.6305108467459761,
      "grad_norm": 1.7186142206192017,
      "learning_rate": 1.0147744945567653e-05,
      "loss": 0.0783,
      "step": 4660
    },
    {
      "epoch": 1.6375087473757872,
      "grad_norm": 13.248358726501465,
      "learning_rate": 1.0095904613789529e-05,
      "loss": 0.1736,
      "step": 4680
    },
    {
      "epoch": 1.6445066480055983,
      "grad_norm": 18.04755210876465,
      "learning_rate": 1.0044064282011406e-05,
      "loss": 0.1244,
      "step": 4700
    },
    {
      "epoch": 1.6515045486354094,
      "grad_norm": 0.415685772895813,
      "learning_rate": 9.992223950233282e-06,
      "loss": 0.1431,
      "step": 4720
    },
    {
      "epoch": 1.6585024492652205,
      "grad_norm": 0.7237605452537537,
      "learning_rate": 9.94038361845516e-06,
      "loss": 0.2254,
      "step": 4740
    },
    {
      "epoch": 1.6655003498950314,
      "grad_norm": 0.3217107057571411,
      "learning_rate": 9.888543286677035e-06,
      "loss": 0.1737,
      "step": 4760
    },
    {
      "epoch": 1.6724982505248427,
      "grad_norm": 1.5014439821243286,
      "learning_rate": 9.836702954898913e-06,
      "loss": 0.1426,
      "step": 4780
    },
    {
      "epoch": 1.6794961511546536,
      "grad_norm": 1.1869341135025024,
      "learning_rate": 9.784862623120788e-06,
      "loss": 0.1512,
      "step": 4800
    },
    {
      "epoch": 1.6864940517844647,
      "grad_norm": 0.5198379755020142,
      "learning_rate": 9.733022291342666e-06,
      "loss": 0.0761,
      "step": 4820
    },
    {
      "epoch": 1.6934919524142757,
      "grad_norm": 9.499811172485352,
      "learning_rate": 9.681181959564542e-06,
      "loss": 0.2088,
      "step": 4840
    },
    {
      "epoch": 1.7004898530440866,
      "grad_norm": 2.1426072120666504,
      "learning_rate": 9.629341627786419e-06,
      "loss": 0.1494,
      "step": 4860
    },
    {
      "epoch": 1.707487753673898,
      "grad_norm": 12.297521591186523,
      "learning_rate": 9.577501296008295e-06,
      "loss": 0.1636,
      "step": 4880
    },
    {
      "epoch": 1.7144856543037088,
      "grad_norm": 0.33976948261260986,
      "learning_rate": 9.525660964230172e-06,
      "loss": 0.1558,
      "step": 4900
    },
    {
      "epoch": 1.72148355493352,
      "grad_norm": 2.5359413623809814,
      "learning_rate": 9.473820632452048e-06,
      "loss": 0.1614,
      "step": 4920
    },
    {
      "epoch": 1.728481455563331,
      "grad_norm": 4.814711570739746,
      "learning_rate": 9.421980300673926e-06,
      "loss": 0.256,
      "step": 4940
    },
    {
      "epoch": 1.735479356193142,
      "grad_norm": 4.841877460479736,
      "learning_rate": 9.370139968895801e-06,
      "loss": 0.1206,
      "step": 4960
    },
    {
      "epoch": 1.7424772568229532,
      "grad_norm": 6.254624366760254,
      "learning_rate": 9.318299637117679e-06,
      "loss": 0.1513,
      "step": 4980
    },
    {
      "epoch": 1.749475157452764,
      "grad_norm": 0.20065951347351074,
      "learning_rate": 9.266459305339555e-06,
      "loss": 0.1598,
      "step": 5000
    },
    {
      "epoch": 1.7564730580825754,
      "grad_norm": 0.8495408892631531,
      "learning_rate": 9.21461897356143e-06,
      "loss": 0.1437,
      "step": 5020
    },
    {
      "epoch": 1.7634709587123862,
      "grad_norm": 0.6085213422775269,
      "learning_rate": 9.16277864178331e-06,
      "loss": 0.1384,
      "step": 5040
    },
    {
      "epoch": 1.7704688593421973,
      "grad_norm": 8.978588104248047,
      "learning_rate": 9.110938310005185e-06,
      "loss": 0.1323,
      "step": 5060
    },
    {
      "epoch": 1.7774667599720084,
      "grad_norm": 11.94104290008545,
      "learning_rate": 9.059097978227061e-06,
      "loss": 0.1883,
      "step": 5080
    },
    {
      "epoch": 1.7844646606018193,
      "grad_norm": 4.736470699310303,
      "learning_rate": 9.007257646448939e-06,
      "loss": 0.1459,
      "step": 5100
    },
    {
      "epoch": 1.7914625612316306,
      "grad_norm": 1.893441081047058,
      "learning_rate": 8.955417314670814e-06,
      "loss": 0.1708,
      "step": 5120
    },
    {
      "epoch": 1.7984604618614415,
      "grad_norm": 2.4016735553741455,
      "learning_rate": 8.903576982892692e-06,
      "loss": 0.1689,
      "step": 5140
    },
    {
      "epoch": 1.8054583624912526,
      "grad_norm": 1.2555721998214722,
      "learning_rate": 8.851736651114568e-06,
      "loss": 0.0789,
      "step": 5160
    },
    {
      "epoch": 1.8124562631210637,
      "grad_norm": 13.381016731262207,
      "learning_rate": 8.799896319336443e-06,
      "loss": 0.1597,
      "step": 5180
    },
    {
      "epoch": 1.8194541637508748,
      "grad_norm": 1.8971374034881592,
      "learning_rate": 8.74805598755832e-06,
      "loss": 0.1731,
      "step": 5200
    },
    {
      "epoch": 1.8264520643806859,
      "grad_norm": 11.243080139160156,
      "learning_rate": 8.696215655780198e-06,
      "loss": 0.1183,
      "step": 5220
    },
    {
      "epoch": 1.8334499650104967,
      "grad_norm": 0.9463576674461365,
      "learning_rate": 8.644375324002074e-06,
      "loss": 0.0872,
      "step": 5240
    },
    {
      "epoch": 1.840447865640308,
      "grad_norm": 8.454293251037598,
      "learning_rate": 8.592534992223951e-06,
      "loss": 0.1569,
      "step": 5260
    },
    {
      "epoch": 1.847445766270119,
      "grad_norm": 5.065561771392822,
      "learning_rate": 8.540694660445827e-06,
      "loss": 0.2262,
      "step": 5280
    },
    {
      "epoch": 1.85444366689993,
      "grad_norm": 1.1759428977966309,
      "learning_rate": 8.488854328667705e-06,
      "loss": 0.1178,
      "step": 5300
    },
    {
      "epoch": 1.861441567529741,
      "grad_norm": 14.404620170593262,
      "learning_rate": 8.43701399688958e-06,
      "loss": 0.1694,
      "step": 5320
    },
    {
      "epoch": 1.868439468159552,
      "grad_norm": 9.639191627502441,
      "learning_rate": 8.385173665111458e-06,
      "loss": 0.1447,
      "step": 5340
    },
    {
      "epoch": 1.8754373687893633,
      "grad_norm": 6.243618965148926,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.1747,
      "step": 5360
    },
    {
      "epoch": 1.8824352694191742,
      "grad_norm": 6.96998929977417,
      "learning_rate": 8.281493001555211e-06,
      "loss": 0.1085,
      "step": 5380
    },
    {
      "epoch": 1.8894331700489853,
      "grad_norm": 4.0180768966674805,
      "learning_rate": 8.229652669777087e-06,
      "loss": 0.1306,
      "step": 5400
    },
    {
      "epoch": 1.8964310706787963,
      "grad_norm": 13.246012687683105,
      "learning_rate": 8.177812337998964e-06,
      "loss": 0.1604,
      "step": 5420
    },
    {
      "epoch": 1.9034289713086074,
      "grad_norm": 25.087392807006836,
      "learning_rate": 8.12597200622084e-06,
      "loss": 0.1758,
      "step": 5440
    },
    {
      "epoch": 1.9104268719384185,
      "grad_norm": 0.6777850985527039,
      "learning_rate": 8.074131674442716e-06,
      "loss": 0.0825,
      "step": 5460
    },
    {
      "epoch": 1.9174247725682294,
      "grad_norm": 4.333261013031006,
      "learning_rate": 8.022291342664593e-06,
      "loss": 0.2079,
      "step": 5480
    },
    {
      "epoch": 1.9244226731980407,
      "grad_norm": 1.945832371711731,
      "learning_rate": 7.970451010886471e-06,
      "loss": 0.2033,
      "step": 5500
    },
    {
      "epoch": 1.9314205738278516,
      "grad_norm": 4.743330955505371,
      "learning_rate": 7.918610679108347e-06,
      "loss": 0.1393,
      "step": 5520
    },
    {
      "epoch": 1.9384184744576627,
      "grad_norm": 14.971356391906738,
      "learning_rate": 7.866770347330224e-06,
      "loss": 0.1315,
      "step": 5540
    },
    {
      "epoch": 1.9454163750874738,
      "grad_norm": 8.21345329284668,
      "learning_rate": 7.8149300155521e-06,
      "loss": 0.1419,
      "step": 5560
    },
    {
      "epoch": 1.9524142757172847,
      "grad_norm": 1.544834017753601,
      "learning_rate": 7.763089683773977e-06,
      "loss": 0.0792,
      "step": 5580
    },
    {
      "epoch": 1.959412176347096,
      "grad_norm": 9.668373107910156,
      "learning_rate": 7.711249351995853e-06,
      "loss": 0.1075,
      "step": 5600
    },
    {
      "epoch": 1.9664100769769068,
      "grad_norm": 0.45989543199539185,
      "learning_rate": 7.659409020217729e-06,
      "loss": 0.1237,
      "step": 5620
    },
    {
      "epoch": 1.973407977606718,
      "grad_norm": 3.6780779361724854,
      "learning_rate": 7.607568688439607e-06,
      "loss": 0.209,
      "step": 5640
    },
    {
      "epoch": 1.980405878236529,
      "grad_norm": 11.793036460876465,
      "learning_rate": 7.555728356661484e-06,
      "loss": 0.0709,
      "step": 5660
    },
    {
      "epoch": 1.9874037788663401,
      "grad_norm": 0.32175976037979126,
      "learning_rate": 7.5038880248833605e-06,
      "loss": 0.1462,
      "step": 5680
    },
    {
      "epoch": 1.9944016794961512,
      "grad_norm": 16.945777893066406,
      "learning_rate": 7.452047693105236e-06,
      "loss": 0.1642,
      "step": 5700
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9562707543373108,
      "eval_loss": 0.16273510456085205,
      "eval_runtime": 324.9422,
      "eval_samples_per_second": 35.188,
      "eval_steps_per_second": 4.401,
      "step": 5716
    }
  ],
  "logging_steps": 20,
  "max_steps": 8574,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.4353729821802496e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
